{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"source/favicon.ico","path":"favicon.ico","modified":1,"renderable":0},{"_id":"source/img/life/avatar.gif","path":"img/life/avatar.gif","modified":1,"renderable":0},{"_id":"source/img/bak/hxh_s.jpg","path":"img/bak/hxh_s.jpg","modified":1,"renderable":0},{"_id":"source/img/life/favicon.ico","path":"img/life/favicon.ico","modified":1,"renderable":0},{"_id":"source/img/work/14853239880359.jpg","path":"img/work/14853239880359.jpg","modified":1,"renderable":0},{"_id":"source/img/work/Buffer-clear-20170212.png","path":"img/work/Buffer-clear-20170212.png","modified":1,"renderable":0},{"_id":"source/img/work/Buffer-flip-20170212.png","path":"img/work/Buffer-flip-20170212.png","modified":1,"renderable":0},{"_id":"source/img/work/Buffer-process-20170212.jpeg","path":"img/work/Buffer-process-20170212.jpeg","modified":1,"renderable":0},{"_id":"source/img/work/Buffer-get-20170212.png","path":"img/work/Buffer-get-20170212.png","modified":1,"renderable":0},{"_id":"source/img/work/Buffer-put-20170212.png","path":"img/work/Buffer-put-20170212.png","modified":1,"renderable":0},{"_id":"source/img/work/Threadlife_20170208.jpg","path":"img/work/Threadlife_20170208.jpg","modified":1,"renderable":0},{"_id":"source/img/work/channels-buffers-20170212.png","path":"img/work/channels-buffers-20170212.png","modified":1,"renderable":0},{"_id":"source/img/work/kafka-producer-20170213.png.png","path":"img/work/kafka-producer-20170213.png.png","modified":1,"renderable":0},{"_id":"source/img/work/kafka_log_anatomy_20170213.png","path":"img/work/kafka_log_anatomy_20170213.png","modified":1,"renderable":0},{"_id":"source/img/work/rpc-20170302.jpg","path":"img/work/rpc-20170302.jpg","modified":1,"renderable":0},{"_id":"source/img/work/selectors-20170212.png","path":"img/work/selectors-20170212.png","modified":1,"renderable":0},{"_id":"source/img/work/sparkRdd_20170207.jpg","path":"img/work/sparkRdd_20170207.jpg","modified":1,"renderable":0},{"_id":"source/img/work/yarn-structure-20170216.png","path":"img/work/yarn-structure-20170216.png","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"source/img/life/njupt-20170228.jpg","path":"img/life/njupt-20170228.jpg","modified":1,"renderable":0},{"_id":"source/img/work/yarn-progress-20170216.png","path":"img/work/yarn-progress-20170216.png","modified":1,"renderable":0},{"_id":"source/img/work/catalog_20170204.png","path":"img/work/catalog_20170204.png","modified":1,"renderable":0},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"source/img/bak/hxh_n.jpg","path":"img/bak/hxh_n.jpg","modified":1,"renderable":0},{"_id":"source/img/work/kafka-tupe-20170213.png","path":"img/work/kafka-tupe-20170213.png","modified":1,"renderable":0},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"source/img/work/shuffle-write-no-consolidation_20170206.png","path":"img/work/shuffle-write-no-consolidation_20170206.png","modified":1,"renderable":0},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"source/img/life/天池20170228.jpg","path":"img/life/天池20170228.jpg","modified":1,"renderable":0}],"Cache":[{"_id":"source/.DS_Store","hash":"ef30f3593c5cc80910ae4cf6ebd887a3c7e6f3f4","modified":1538275882896},{"_id":"source/CNAME","hash":"358fdaf656a4c65e3b90cc318c7933d36cbda17a","modified":1535977786714},{"_id":"source/favicon.ico","hash":"dbf6bc9779822c62ba9ba55428b88f69aff93958","modified":1535977786722},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1538211325063},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1538211325064},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1538211325081},{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1538211325073},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1538211324940},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1538211325061},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1538211325062},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1538211325082},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1538211325120},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1538211324907},{"_id":"themes/next/README.cn.md","hash":"2c766b3369ed477bce134a5450dab45bef161504","modified":1538211324907},{"_id":"themes/next/README.md","hash":"8ce60ce578963eb4e1eb5e33e1efc2fc4779af9c","modified":1538211325072},{"_id":"themes/next/_config.yml","hash":"5d9f2e0830c356bac4023c91697671c4922e1dc2","modified":1538214222291},{"_id":"themes/next/bower.json","hash":"0674f11d3d514e087a176da0e1d85c2286aa5fba","modified":1538211325062},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1538211324940},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1538211325073},{"_id":"source/_posts/Java-NIO-ByteBuffer概述.md","hash":"4ff79b026674ad4d73091d989d8b45ad6b49cafe","modified":1535977786714},{"_id":"source/_posts/Java-NIO简述.md","hash":"800544a653a076e32c809f4f90f0dede85ca3188","modified":1535977786715},{"_id":"source/_posts/Java-Thread概述.md","hash":"40e427e0e08054915446a23e239eab37cd63d9ca","modified":1535977786715},{"_id":"source/_posts/Kafka-概述.md","hash":"a5bb703e7868a3fbfe91b4976a6a2eecec2f6fb7","modified":1535977786716},{"_id":"source/_posts/RPC原理-概述.md","hash":"aac95a0373575f2a96e77cae171a9310d91a7527","modified":1535977786716},{"_id":"source/_posts/Spark-RDD详解.md","hash":"d90ff4e64eae1741a27f5f6bb16a655c1ce042d3","modified":1535977786717},{"_id":"source/_posts/Spark-Shuffle基础.md","hash":"d4894c4694f78d8a61cc9870656b64659a2dbd3d","modified":1535977786717},{"_id":"source/_posts/SparkStream-函数详解-Transformations.md","hash":"b685bc6e6fc6989f31dd25c214fdcde8452645d3","modified":1535977786718},{"_id":"source/_posts/Spring-Boot-入门学习.md","hash":"e46b77e72d48c8a4fd30281d32f46a0d7792a1a0","modified":1535977786718},{"_id":"source/_posts/Spring-boot-MyBatis配置-1.md","hash":"e4f928aea74d9cb1eef04132bb940ed83fa9309b","modified":1535977786719},{"_id":"source/_posts/Spring-boot-MyBatis配置-2.md","hash":"11d8591b81b173172a44242a91f0914790520a7c","modified":1535977786719},{"_id":"source/_posts/Tensorflow 入门-1.md","hash":"b8bcdeb036c92058cc4bdac9dbc4dbe4d9d66d80","modified":1538215114775},{"_id":"source/_posts/Yarn-概述.md","hash":"b239e5475c49ef2697c5658099c3b41e3c986e7d","modified":1535977786720},{"_id":"source/_posts/go-ethereum-简单搭建私有链.md","hash":"4662c4c0637eed717d7c23ea7e9b29e7912623ab","modified":1535977786721},{"_id":"source/about/index.md","hash":"b29831930eacd43a267a4cb2f6b1d3a21389a8b3","modified":1535977786721},{"_id":"source/categories/index.md","hash":"2b17edd31de71c4666e55d343a5e8e6db7478e73","modified":1538216108363},{"_id":"source/img/.DS_Store","hash":"46fb2335568899da32dca002de40fa5c5b01e0a7","modified":1538212934933},{"_id":"source/_posts/.DS_Store","hash":"a1cb9e058916e32f4a83cef0e54c6686bf9100a4","modified":1538275985358},{"_id":"source/tags/index.md","hash":"f66208f9d7965b40cdedfa200e132158e2321e2e","modified":1538216609780},{"_id":"themes/next/.git/FETCH_HEAD","hash":"778b51a21e3c53e17a5b722a6329f3f7c0eb829f","modified":1538211325120},{"_id":"themes/next/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1538211325107},{"_id":"themes/next/.git/ORIG_HEAD","hash":"7999da428ebb87e5a2b27315d8d5123c1ccdfaa5","modified":1538211325082},{"_id":"themes/next/.git/config","hash":"bf7d1df65cf34d0f25a7184a58c37a09f72e4be7","modified":1538211325083},{"_id":"themes/next/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1538211325112},{"_id":"themes/next/.git/index","hash":"499d35d30951e6e1ed6de76bef04496a09dc4ebf","modified":1538211325119},{"_id":"themes/next/.git/packed-refs","hash":"8e36811256ee380c2c65692f1b8f8e77c5bc33c9","modified":1538211325119},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1538211325081},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"50d48c47162817a3810a9d9ad51104e83947419a","modified":1538211325081},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1538211325080},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1538211325080},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1538211325067},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1538211325064},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1538211325069},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1538211325071},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1538211325066},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1538211325068},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1538211325069},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1538211325066},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1538211325068},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1538211325065},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1538211325067},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1538211325071},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1538211325072},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1538211325065},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1538211325070},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1538211325071},{"_id":"themes/next/layout/_layout.swig","hash":"da0929166674ea637e0ad454f85ad0d7bac4aff2","modified":1538211324912},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1538211324924},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1538211324912},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1538211324917},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1538211324916},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1538211324916},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1538211324910},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1538211324910},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1538211325075},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1538211325075},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1538211324908},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1538211324909},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1538211324908},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1538211325061},{"_id":"source/img/bak/.DS_Store","hash":"6119a8666cdb76c254507eb563698b8f60842831","modified":1485326684000},{"_id":"source/img/life/avatar.gif","hash":"53c664c7e2569f0e57abce2e357a04c19ce66122","modified":1535977786726},{"_id":"source/img/bak/hxh_s.jpg","hash":"53c664c7e2569f0e57abce2e357a04c19ce66122","modified":1535977786726},{"_id":"source/img/life/favicon.ico","hash":"53c664c7e2569f0e57abce2e357a04c19ce66122","modified":1535977786726},{"_id":"source/img/work/.DS_Store","hash":"60c0442149a43dd7d48acf95d59a311cd2830cf6","modified":1487247704000},{"_id":"source/img/work/14853239880359.jpg","hash":"8ba6fcca9fc03ee5b99ec646b8d0d1ba61cc10dd","modified":1535977786739},{"_id":"source/img/work/Buffer-clear-20170212.png","hash":"cafb60b7e6a7516dd18dc38c1676f47572d034ff","modified":1535977786740},{"_id":"source/img/work/Buffer-flip-20170212.png","hash":"d710f9be2e24d076190ada8280be3b2d419d94e2","modified":1535977786742},{"_id":"source/img/work/Buffer-process-20170212.jpeg","hash":"2610f8916944b59c7859aabf4df981007d42c2ef","modified":1535977786743},{"_id":"source/img/work/Buffer-get-20170212.png","hash":"f44111acd754300cc53329926190d5129648c4af","modified":1535977786742},{"_id":"source/img/work/Buffer-put-20170212.png","hash":"177eadfa459694390c3d4accffa40e0304755243","modified":1535977786743},{"_id":"source/img/work/Threadlife_20170208.jpg","hash":"27b8beef46f4b98e2913ae7c1196da40230763a3","modified":1535977786745},{"_id":"source/img/work/channels-buffers-20170212.png","hash":"91767a1f3c322cf4ff1936c24143724195b54fc9","modified":1535977786747},{"_id":"source/img/work/kafka-producer-20170213.png.png","hash":"d418cb89944102d0875ce7d0aaf1068ad616a651","modified":1535977786748},{"_id":"source/img/work/kafka_log_anatomy_20170213.png","hash":"7d387eec0de1ebfbcd98a3b0c87aa008b2dbe476","modified":1535977786750},{"_id":"source/img/work/rpc-20170302.jpg","hash":"aa10f59910b269e4a0de75a828befb00a8f37ea7","modified":1535977786751},{"_id":"source/img/work/selectors-20170212.png","hash":"d2019fc0847fad5488c199d4f6bb07a3dceba7ce","modified":1535977786751},{"_id":"source/img/work/sparkRdd_20170207.jpg","hash":"356667fdad339020fb9c94358ee46fe11deec498","modified":1535977786755},{"_id":"source/img/work/yarn-structure-20170216.png","hash":"811a3c06fe189b16a269b0cfc1236e9af6452748","modified":1535977786758},{"_id":"themes/next/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1538211325114},{"_id":"themes/next/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1538211325113},{"_id":"themes/next/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1538211325115},{"_id":"themes/next/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1538211325116},{"_id":"themes/next/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1538211325114},{"_id":"themes/next/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1538211325116},{"_id":"themes/next/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1538211325113},{"_id":"themes/next/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1538211325115},{"_id":"themes/next/.git/hooks/update.sample","hash":"39355a075977d05708ef74e1b66d09a36e486df1","modified":1538211325116},{"_id":"themes/next/.git/info/exclude","hash":"bb5a85730dcf100facee799c05cc4f6affec0745","modified":1538211325109},{"_id":"themes/next/.git/logs/HEAD","hash":"20e56869d23df2a692072f7f69d93c98e3fa7488","modified":1538211325109},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1538211324911},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1538211324911},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1538211324939},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1538211324939},{"_id":"themes/next/layout/_macro/post.swig","hash":"446a35a2cd389f8cfc3aa38973a9b44ad0740134","modified":1538211324938},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1538211324939},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1538211324938},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1538211324938},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1538211324920},{"_id":"themes/next/layout/_partials/footer.swig","hash":"c4d6181f5d3db5365e622f78714af8cc58d7a45e","modified":1538211324920},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1538211324921},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1538211324921},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1538211324922},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1538211324917},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1538211324920},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1538211324914},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1538211324915},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1538211324915},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1538211324931},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1538211324928},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1538211324928},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1538211324931},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1538211324932},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1538211324927},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1538211324928},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1538211325077},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1538211325076},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1538211325079},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1538211325078},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1538211325079},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1538211325078},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1538211325076},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1538211325077},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1538211325077},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1538211324972},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1538211324987},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1538211324992},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1538211324985},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1538211324996},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1538211324990},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1538211324986},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1538211324985},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1538211324994},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1538211324989},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1538211324995},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1538211324993},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1538211324992},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1538211324991},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1538211324996},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1538211324984},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1538211324991},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1538211324994},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1538211324987},{"_id":"source/img/life/njupt-20170228.jpg","hash":"1ddcbb410ae2b1b8e0f9946927671fccd2bd3103","modified":1535977786728},{"_id":"source/img/work/yarn-progress-20170216.png","hash":"2b5cc0b246b24e89a224a9fa2b5abdd1968a6847","modified":1535977786757},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1538211324914},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1538211324914},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1538211324983},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1538211324984},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1538211324982},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1538211324972},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1538211324971},{"_id":"source/img/work/catalog_20170204.png","hash":"af1d55a452c12677971ae42b643000d453e3804f","modified":1535977786747},{"_id":"themes/next/.git/refs/heads/master","hash":"7999da428ebb87e5a2b27315d8d5123c1ccdfaa5","modified":1538211325117},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1538211324919},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1538211324919},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1538211324919},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1538211324918},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1538211324918},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1538211324923},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1538211324922},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1538211324922},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1538211324923},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1538211324916},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1538211324913},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1538211324914},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1538211324935},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1538211324936},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1538211324933},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1538211324933},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1538211324937},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1538211324935},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1538211324936},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1538211324933},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1538211324934},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1538211324937},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1538211324935},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1538211324936},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1538211324932},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1538211324925},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1538211324927},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1538211324926},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1538211324925},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1538211324925},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1538211324926},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1538211324927},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1538211324925},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1538211324926},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1538211324930},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1538211324929},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1538211324929},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1538211324932},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1538211324941},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1538211324983},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1538211324984},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1538211324983},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1538211324971},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1538211324971},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1538211324972},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1538211324971},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1538211325003},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1538211325001},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1538211324999},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1538211325003},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1538211324998},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1538211325001},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1538211325002},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1538211325001},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1538211325000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1538211324999},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1538211325002},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1538211325014},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1538211325029},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1538211325014},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1538211325022},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1538211325022},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1538211325007},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1538211325005},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1538211325006},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1538211325006},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1538211325052},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1538211325052},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1538211325049},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1538211325053},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1538211325051},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1538211325023},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1538211325041},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1538211325041},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1538211325040},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1538211325040},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1538211325042},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1538211325039},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1538211325010},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1538211325010},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1538211325009},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1538211325027},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1538211325025},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1538211325027},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1538211325025},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1538211325028},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1538211325027},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1538211325028},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1538211325024},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1538211325026},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1538211325026},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1538211325025},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1538211325029},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1538211325026},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1538211325024},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1538211325033},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1538211325037},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1538211325034},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1538211325031},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1538211325030},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1538211325030},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1538211325030},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1538211325031},{"_id":"source/img/bak/hxh_n.jpg","hash":"251a9630d76739e2ef3489f3c9d2b4d922278f72","modified":1535977786724},{"_id":"source/img/work/kafka-tupe-20170213.png","hash":"24d5b6c8a7e0ecd183f6225a8038846aa8e3efaf","modified":1535977786750},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1538211325023},{"_id":"themes/next/.git/logs/refs/heads/master","hash":"20e56869d23df2a692072f7f69d93c98e3fa7488","modified":1538211325110},{"_id":"themes/next/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1538211325118},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1538211324930},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1538211324930},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1538211324956},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1538211324962},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1538211324956},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1538211324957},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1538211324944},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1538211324956},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1538211324960},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1538211324970},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1538211324943},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1538211324942},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1538211324944},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1538211324943},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1538211324944},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1538211324943},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1538211324980},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1538211324976},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1538211324981},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1538211324982},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1538211324982},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1538211324980},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1538211324981},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1538211324980},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1538211324974},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1538211324975},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"4aac01962520d60b03b23022ab601ad4bd19c08c","modified":1538211324976},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1538211324975},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1538211324974},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1538211324978},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1538211324977},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1538211324979},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1538211324977},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1538211324978},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1538211324978},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1538211324998},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1538211325048},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1538211325043},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1538211325018},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1538211325019},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1538211325017},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1538211325018},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1538211325016},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1538211325018},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1538211325016},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1538211325017},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1538211325015},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1538211325008},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1538211325008},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1538211325050},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1538211325051},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1538211325050},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1538211325038},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1538211325038},{"_id":"source/img/work/shuffle-write-no-consolidation_20170206.png","hash":"6dd2872aa672f77e9b7e762f71f1733934e825cc","modified":1535977786754},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1538211325043},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1538211325044},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1538211325057},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1538211325060},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1538211325032},{"_id":"themes/next/.git/logs/refs/remotes/origin/HEAD","hash":"20e56869d23df2a692072f7f69d93c98e3fa7488","modified":1538211325111},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1538211324949},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1538211324969},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1538211324969},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1538211324968},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1538211324968},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1538211324969},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1538211324956},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1538211324955},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1538211324955},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1538211324967},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1538211324967},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1538211324967},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1538211324966},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1538211324966},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1538211324953},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1538211324954},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1538211324953},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1538211324953},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1538211324954},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1538211324952},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1538211324951},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1538211324951},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1538211324950},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1538211324950},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1538211324952},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1538211324951},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1538211324952},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1538211324954},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1538211324950},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1538211324945},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1538211324947},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1538211324946},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1538211324948},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1538211324946},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1538211324946},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1538211324947},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1538211324948},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1538211324948},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1538211324947},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1538211324960},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1538211324958},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1538211324957},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1538211324959},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1538211324959},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1538211324959},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1538211324960},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1538211324958},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1538211324958},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1538211324965},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1538211324963},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1538211324963},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1538211324962},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1538211324964},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1538211324966},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1538211324963},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1538211324965},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1538211324965},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1538211324964},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1538211324981},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1538211324979},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1538211324974},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1538211325045},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1538211325045},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1538211325047},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1538211325048},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1538211325046},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1538211325019},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1538211325021},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1538211325021},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1538211325020},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1538211325021},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1538211325020},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1538211325056},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1538211325060},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1538211325058},{"_id":"themes/next/.git/objects/pack/pack-09df78575dd506cafcb2c517908ed591431fdc71.idx","hash":"be430c584ec6e1499b87f9e416e72d0fbc2e3a26","modified":1538211325106},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1538211325012},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1538211325035},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1538211325054},{"_id":"source/img/life/天池20170228.jpg","hash":"b18d8b0e72d86d4516582549a832d9deb9e8285e","modified":1535977786736},{"_id":"themes/next/.git/objects/pack/pack-09df78575dd506cafcb2c517908ed591431fdc71.pack","hash":"eee901eb2f4a4df31eaa41634f4e9de643c3fb4e","modified":1538211325099},{"_id":"public/about/index.html","hash":"909ce57bbf27305e34fc543f3f8046240e2156fe","modified":1538276066005},{"_id":"public/categories/index.html","hash":"473446fa7a32dd56b801955fd5cb271b93e3419a","modified":1538276066005},{"_id":"public/tags/index.html","hash":"876425d9082ea42d014563be7df747ce6d95ff49","modified":1538276066005},{"_id":"public/archives/page/2/index.html","hash":"08af19959189c60a373e73a998afb36117066c01","modified":1538276066005},{"_id":"public/archives/2017/page/2/index.html","hash":"eda6d285fcaf4d84b71ce0601ba8bd69e8959617","modified":1538276066005},{"_id":"public/archives/2017/01/index.html","hash":"7928e1eeaa8ddb9b9767edcf5be8aeeed1438ddd","modified":1538276066005},{"_id":"public/archives/2017/03/index.html","hash":"024c506d1e0bcd2ff0e9754d2b949f42f9ee6e19","modified":1538276066005},{"_id":"public/archives/2017/12/index.html","hash":"4e08335e62e7c9a142544c237baaa96f3ce45b9b","modified":1538276066005},{"_id":"public/archives/2018/index.html","hash":"4c0d527c32b4c156457995489b5f35abf7525b67","modified":1538276066005},{"_id":"public/archives/2018/09/index.html","hash":"946b20953f83a0860ba49f422ac42278f36d03f0","modified":1538276066005},{"_id":"public/categories/java/index.html","hash":"ab48a01904a7f568b923c0d39fe4e409fc3ffbf8","modified":1538276066005},{"_id":"public/categories/kafka/index.html","hash":"d36a63f0df5d9fd9b554d44ab15bd6daa30f3617","modified":1538276066005},{"_id":"public/categories/spark/index.html","hash":"8fdf83be59d95338d7a9d48c21172bf63cf62fc0","modified":1538276066006},{"_id":"public/categories/tensorflow/index.html","hash":"d12fb254c808901b075cc4c679b060152c2ed3ba","modified":1538276066006},{"_id":"public/categories/Big-data/index.html","hash":"95f1db38f9a3798b91b7687d753ae16ac2d2a4b5","modified":1538276066006},{"_id":"public/categories/区块链/index.html","hash":"afe67f149459a931348b49886f4fa531ad98fea1","modified":1538276066006},{"_id":"public/tags/java-nio/index.html","hash":"361db9ff5790384d7895b7d15611451845771b01","modified":1538276066006},{"_id":"public/tags/java/index.html","hash":"818803523b96f31b4bc0aa140763656ab905d585","modified":1538276066006},{"_id":"public/tags/thread/index.html","hash":"4ef10997c66ad54805178256d6f2f933b466dd30","modified":1538276066006},{"_id":"public/tags/kafka/index.html","hash":"fd0cf492d584296030d8fcd168be9692ed8de3c5","modified":1538276066006},{"_id":"public/tags/rpc/index.html","hash":"6e0495eb6d042d002c82c08f44e56839bd0c8032","modified":1538276066006},{"_id":"public/tags/spark/index.html","hash":"00bb5e656fd4bbbca13f475e5deb8c202ce05473","modified":1538276066006},{"_id":"public/tags/sparkstream/index.html","hash":"3003a022749cf274cdf3d410740aad1d101cd2e7","modified":1538276066006},{"_id":"public/tags/spring-boot/index.html","hash":"df5ce78165e890ee204d8a532df0bc291a8915b9","modified":1538276066006},{"_id":"public/tags/spring/index.html","hash":"add124dccdd3301f996182d04da910debe3eecf7","modified":1538276066006},{"_id":"public/tags/tensorflow/index.html","hash":"197d0b16a51de6200d49b3ad014f3e3cc5402588","modified":1538276066006},{"_id":"public/tags/yarn/index.html","hash":"4fd6edb275ae1b26f0798af3cfa0ae7a96cbcbc9","modified":1538276066006},{"_id":"public/tags/hadoop/index.html","hash":"2f19342701c6078416ee80c1754369ae43ec634c","modified":1538276066006},{"_id":"public/tags/以太坊/index.html","hash":"9455143d064e34c7229a9c2f8ef5708401eade0c","modified":1538276066006},{"_id":"public/tags/区块链/index.html","hash":"9519b085ec1b73db3bed6e3a20296669277fe66d","modified":1538276066006},{"_id":"public/2018/09/03/Tensorflow 入门-1/index.html","hash":"ea64b5df936ec831d8f8917e4d75d2aede58ad8a","modified":1538276066006},{"_id":"public/2017/12/05/go-ethereum-简单搭建私有链/index.html","hash":"1fe5497e5f3541fc85ac5f26e8b15b584e000785","modified":1538276066007},{"_id":"public/2017/03/08/Java-Thread概述/index.html","hash":"3fc0cd696fed8ee4222e595f8fd759791cd6a284","modified":1538276066007},{"_id":"public/2017/03/02/RPC原理-概述/index.html","hash":"9669d887422dd80b140dbb8234bdd3fd5d5be43a","modified":1538276066007},{"_id":"public/2017/02/16/Yarn-概述/index.html","hash":"f6e1d1edea8357c4c8759da8f7e16bb046040e37","modified":1538276066007},{"_id":"public/2017/02/13/Kafka-概述/index.html","hash":"59b6bc906a6f21898900bd02b1e47119619bf813","modified":1538276066007},{"_id":"public/2017/02/12/Java-NIO-ByteBuffer概述/index.html","hash":"42c89276313b3e64affff56c3b870453345776fd","modified":1538276066007},{"_id":"public/2017/02/12/Java-NIO简述/index.html","hash":"e2aece36bdc94e79cab9f20bad8d6fff781701f1","modified":1538276066007},{"_id":"public/2017/02/07/Spark-RDD详解/index.html","hash":"97e684c226290c003dda9fe0cc56d2eedab4be51","modified":1538276066007},{"_id":"public/2017/02/06/Spark-Shuffle基础/index.html","hash":"3b8a7633a80e3cc9f40cdfc3454201495403626a","modified":1538276066007},{"_id":"public/2017/02/05/SparkStream-函数详解-Transformations/index.html","hash":"cd060d9f055fe9154cd83ac651622a5d359cee5a","modified":1538276066007},{"_id":"public/2017/02/04/Spring-boot-MyBatis配置-2/index.html","hash":"16e2bec0402b5ec6a627e74029b6c0ac37d8a7ea","modified":1538276066007},{"_id":"public/2017/02/04/Spring-boot-MyBatis配置-1/index.html","hash":"ac709a4351a310cd12a6001d0e9b7c06c27cd6c1","modified":1538276066007},{"_id":"public/2017/01/25/Spring-Boot-入门学习/index.html","hash":"f5d1d86c6a084792d11cb5c6e51aae6c4f5e6f37","modified":1538276066007},{"_id":"public/archives/index.html","hash":"2484f3b1e8eaf4d6b169f4ff25f2fc194b2fb641","modified":1538276066007},{"_id":"public/archives/2017/index.html","hash":"a8e374e1e8d68f311ef22a5e72c4bef7012fb6dc","modified":1538276066007},{"_id":"public/archives/2017/02/index.html","hash":"b877ace25751cccf304646c19638b5dcbdaf24d7","modified":1538276066007},{"_id":"public/index.html","hash":"5a1be8c2dd32b925734c03ebe4931fa02dcae8fe","modified":1538276066007},{"_id":"public/page/2/index.html","hash":"10f61db7193d2c107daae5a3869a6761e32642ff","modified":1538276066007},{"_id":"public/CNAME","hash":"358fdaf656a4c65e3b90cc318c7933d36cbda17a","modified":1538276066019},{"_id":"public/favicon.ico","hash":"dbf6bc9779822c62ba9ba55428b88f69aff93958","modified":1538276066019},{"_id":"public/img/life/avatar.gif","hash":"53c664c7e2569f0e57abce2e357a04c19ce66122","modified":1538276066019},{"_id":"public/img/bak/hxh_s.jpg","hash":"53c664c7e2569f0e57abce2e357a04c19ce66122","modified":1538276066019},{"_id":"public/img/life/favicon.ico","hash":"53c664c7e2569f0e57abce2e357a04c19ce66122","modified":1538276066019},{"_id":"public/img/work/14853239880359.jpg","hash":"8ba6fcca9fc03ee5b99ec646b8d0d1ba61cc10dd","modified":1538276066019},{"_id":"public/img/work/Buffer-clear-20170212.png","hash":"cafb60b7e6a7516dd18dc38c1676f47572d034ff","modified":1538276066019},{"_id":"public/img/work/Buffer-flip-20170212.png","hash":"d710f9be2e24d076190ada8280be3b2d419d94e2","modified":1538276066019},{"_id":"public/img/work/Buffer-process-20170212.jpeg","hash":"2610f8916944b59c7859aabf4df981007d42c2ef","modified":1538276066019},{"_id":"public/img/work/Buffer-get-20170212.png","hash":"f44111acd754300cc53329926190d5129648c4af","modified":1538276066019},{"_id":"public/img/work/Buffer-put-20170212.png","hash":"177eadfa459694390c3d4accffa40e0304755243","modified":1538276066019},{"_id":"public/img/work/Threadlife_20170208.jpg","hash":"27b8beef46f4b98e2913ae7c1196da40230763a3","modified":1538276066019},{"_id":"public/img/work/channels-buffers-20170212.png","hash":"91767a1f3c322cf4ff1936c24143724195b54fc9","modified":1538276066020},{"_id":"public/img/work/kafka-producer-20170213.png.png","hash":"d418cb89944102d0875ce7d0aaf1068ad616a651","modified":1538276066020},{"_id":"public/img/work/kafka_log_anatomy_20170213.png","hash":"7d387eec0de1ebfbcd98a3b0c87aa008b2dbe476","modified":1538276066020},{"_id":"public/img/work/rpc-20170302.jpg","hash":"aa10f59910b269e4a0de75a828befb00a8f37ea7","modified":1538276066020},{"_id":"public/img/work/selectors-20170212.png","hash":"d2019fc0847fad5488c199d4f6bb07a3dceba7ce","modified":1538276066020},{"_id":"public/img/work/sparkRdd_20170207.jpg","hash":"356667fdad339020fb9c94358ee46fe11deec498","modified":1538276066020},{"_id":"public/img/work/yarn-structure-20170216.png","hash":"811a3c06fe189b16a269b0cfc1236e9af6452748","modified":1538276066020},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1538276066020},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1538276066020},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1538276066020},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1538276066020},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1538276066020},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1538276066020},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1538276066020},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1538276066020},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1538276066020},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1538276066020},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1538276066021},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1538276066021},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1538276066021},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1538276066021},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1538276066021},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1538276066021},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1538276066021},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1538276066021},{"_id":"public/img/life/njupt-20170228.jpg","hash":"1ddcbb410ae2b1b8e0f9946927671fccd2bd3103","modified":1538276066021},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1538276066021},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1538276066021},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1538276066021},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1538276066021},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1538276066021},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1538276066021},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1538276066021},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1538276066021},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1538276066021},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1538276066022},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1538276066022},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1538276066022},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1538276066022},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1538276066022},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1538276066022},{"_id":"public/img/work/yarn-progress-20170216.png","hash":"2b5cc0b246b24e89a224a9fa2b5abdd1968a6847","modified":1538276066414},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1538276066415},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1538276066416},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1538276066424},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1538276066424},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1538276066425},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1538276066425},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1538276066425},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1538276066425},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1538276066425},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1538276066425},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1538276066425},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1538276066425},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1538276066425},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1538276066425},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1538276066425},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1538276066425},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1538276066425},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1538276066425},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1538276066425},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1538276066425},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1538276066425},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1538276066426},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1538276066426},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1538276066426},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1538276066426},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1538276066426},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1538276066426},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1538276066426},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1538276066426},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1538276066426},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1538276066426},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1538276066426},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1538276066426},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1538276066426},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1538276066426},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1538276066426},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1538276066426},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1538276066426},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1538276066426},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1538276066426},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1538276066426},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1538276066426},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1538276066426},{"_id":"public/css/main.css","hash":"ad3f17c2d7a27cbe3c8cd9b14868ad9e1cd1035b","modified":1538276066426},{"_id":"public/img/bak/hxh_n.jpg","hash":"251a9630d76739e2ef3489f3c9d2b4d922278f72","modified":1538276066426},{"_id":"public/img/work/kafka-tupe-20170213.png","hash":"24d5b6c8a7e0ecd183f6225a8038846aa8e3efaf","modified":1538276066427},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1538276066427},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1538276066427},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1538276066427},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1538276066432},{"_id":"public/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1538276066432},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1538276066433},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1538276066433},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1538276066433},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1538276066433},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1538276066433},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1538276066433},{"_id":"public/img/work/catalog_20170204.png","hash":"af1d55a452c12677971ae42b643000d453e3804f","modified":1538276066433},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1538276066438},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1538276066439},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1538276066443},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1538276066444},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1538276066450},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1538276066450},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1538276066451},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1538276066451},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1538276066451},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1538276066451},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1538276066451},{"_id":"public/img/work/shuffle-write-no-consolidation_20170206.png","hash":"6dd2872aa672f77e9b7e762f71f1733934e825cc","modified":1538276066451},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1538276066458},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1538276066458},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1538276066459},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1538276066484},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1538276066484},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1538276066498},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1538276066499},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1538276066505},{"_id":"public/img/life/天池20170228.jpg","hash":"b18d8b0e72d86d4516582549a832d9deb9e8285e","modified":1538276066507},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1538276066518},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1538276066521}],"Category":[{"name":"java","_id":"cjmo9un2r00049q0vkjf4sqtx"},{"name":"kafka","_id":"cjmo9un36000k9q0vzc3t51jb"},{"name":"spark","_id":"cjmo9un3c000q9q0v13fly64j"},{"name":"tensorflow","_id":"cjmo9un3f00149q0v42gps8rd"},{"name":"Big data","_id":"cjmo9un3g00199q0vvecg67po"},{"name":"区块链","_id":"cjmo9un3g001d9q0vy4jjr9z3"}],"Data":[],"Page":[{"title":"","date":"2017-01-10T01:43:37.000Z","_content":"> 人生每一步都是选择\n\n## 严勇\nyany8060@gmail.com\n目前是一个北漂的程序员，生活比较自由。买自己想买的东西，去自己想去的地方；学自己想学的，做自己想做的。不需要太多的考虑，毕竟我还是单身🐶  ，一人吃饱全家不饿。\n\n喜欢去到处走走，目前北上路线已经完成：\n南京出发=》沈阳、漠河、北极村、哈尔滨、长春、长白山、沈阳\n![天池20170228.jpg](http://upload-images.jianshu.io/upload_images/1419542-03c951bc8de1b8de.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/500)\n\n### 母校\n南京邮电大学  软件学院— 本科，2011~2015\n大学唯一的遗憾就是单身汪过了四年，想想自己当年too yang too simple\n![njupt-20170228.jpg](http://upload-images.jianshu.io/upload_images/1419542-4d946d673cd5ebe4.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/500)\n\n\n### 技术栈（熟悉程度不一）：\njava，scala\nspringmvc，MyBatis\nhadoop，hbase，hive，impala，spark，kafka\n\n目前正在从事大数据的相关开发","source":"about/index.md","raw":"---\ntitle: \ndate: 2017-01-10 09:43:37\n---\n> 人生每一步都是选择\n\n## 严勇\nyany8060@gmail.com\n目前是一个北漂的程序员，生活比较自由。买自己想买的东西，去自己想去的地方；学自己想学的，做自己想做的。不需要太多的考虑，毕竟我还是单身🐶  ，一人吃饱全家不饿。\n\n喜欢去到处走走，目前北上路线已经完成：\n南京出发=》沈阳、漠河、北极村、哈尔滨、长春、长白山、沈阳\n![天池20170228.jpg](http://upload-images.jianshu.io/upload_images/1419542-03c951bc8de1b8de.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/500)\n\n### 母校\n南京邮电大学  软件学院— 本科，2011~2015\n大学唯一的遗憾就是单身汪过了四年，想想自己当年too yang too simple\n![njupt-20170228.jpg](http://upload-images.jianshu.io/upload_images/1419542-4d946d673cd5ebe4.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/500)\n\n\n### 技术栈（熟悉程度不一）：\njava，scala\nspringmvc，MyBatis\nhadoop，hbase，hive，impala，spark，kafka\n\n目前正在从事大数据的相关开发","updated":"2018-09-03T12:29:46.721Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjmo9un2n00019q0vlnu2hvqm","content":"<blockquote>\n<p>人生每一步都是选择</p>\n</blockquote>\n<h2 id=\"严勇\"><a href=\"#严勇\" class=\"headerlink\" title=\"严勇\"></a>严勇</h2><p><a href=\"mailto:yany8060@gmail.com\" target=\"_blank\" rel=\"noopener\">yany8060@gmail.com</a><br>目前是一个北漂的程序员，生活比较自由。买自己想买的东西，去自己想去的地方；学自己想学的，做自己想做的。不需要太多的考虑，毕竟我还是单身🐶  ，一人吃饱全家不饿。</p>\n<p>喜欢去到处走走，目前北上路线已经完成：<br>南京出发=》沈阳、漠河、北极村、哈尔滨、长春、长白山、沈阳<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-03c951bc8de1b8de.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/500\" alt=\"天池20170228.jpg\"></p>\n<h3 id=\"母校\"><a href=\"#母校\" class=\"headerlink\" title=\"母校\"></a>母校</h3><p>南京邮电大学  软件学院— 本科，2011~2015<br>大学唯一的遗憾就是单身汪过了四年，想想自己当年too yang too simple<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-4d946d673cd5ebe4.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/500\" alt=\"njupt-20170228.jpg\"></p>\n<h3 id=\"技术栈（熟悉程度不一）：\"><a href=\"#技术栈（熟悉程度不一）：\" class=\"headerlink\" title=\"技术栈（熟悉程度不一）：\"></a>技术栈（熟悉程度不一）：</h3><p>java，scala<br>springmvc，MyBatis<br>hadoop，hbase，hive，impala，spark，kafka</p>\n<p>目前正在从事大数据的相关开发</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>人生每一步都是选择</p>\n</blockquote>\n<h2 id=\"严勇\"><a href=\"#严勇\" class=\"headerlink\" title=\"严勇\"></a>严勇</h2><p><a href=\"mailto:yany8060@gmail.com\" target=\"_blank\" rel=\"noopener\">yany8060@gmail.com</a><br>目前是一个北漂的程序员，生活比较自由。买自己想买的东西，去自己想去的地方；学自己想学的，做自己想做的。不需要太多的考虑，毕竟我还是单身🐶  ，一人吃饱全家不饿。</p>\n<p>喜欢去到处走走，目前北上路线已经完成：<br>南京出发=》沈阳、漠河、北极村、哈尔滨、长春、长白山、沈阳<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-03c951bc8de1b8de.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/500\" alt=\"天池20170228.jpg\"></p>\n<h3 id=\"母校\"><a href=\"#母校\" class=\"headerlink\" title=\"母校\"></a>母校</h3><p>南京邮电大学  软件学院— 本科，2011~2015<br>大学唯一的遗憾就是单身汪过了四年，想想自己当年too yang too simple<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-4d946d673cd5ebe4.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/500\" alt=\"njupt-20170228.jpg\"></p>\n<h3 id=\"技术栈（熟悉程度不一）：\"><a href=\"#技术栈（熟悉程度不一）：\" class=\"headerlink\" title=\"技术栈（熟悉程度不一）：\"></a>技术栈（熟悉程度不一）：</h3><p>java，scala<br>springmvc，MyBatis<br>hadoop，hbase，hive，impala，spark，kafka</p>\n<p>目前正在从事大数据的相关开发</p>\n"},{"title":"categories","date":"2018-09-29T09:07:39.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2018-09-29 17:07:39\ntype: \"categories\"\nlayout: \"categories\"\n---\n","updated":"2018-09-29T10:15:08.363Z","path":"categories/index.html","comments":1,"_id":"cjmo9un2q00039q0vl5ii652m","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2018-09-29T10:22:35.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2018-09-29 18:22:35\ntype: \"tags\"\nlayout: \"tags\"\n---\n","updated":"2018-09-29T10:23:29.780Z","path":"tags/index.html","comments":1,"_id":"cjmo9un7y001y9q0v63tbf9li","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Java NIO ByteBuffer概述","date":"2017-02-12T09:29:27.000Z","_content":"### Buffer的基本用法\n使用Buffer读写数据一般遵循以下四个步骤：\n1、分配空间\n2、写入数据到Buffer\n3、调用flip()方法\n4、从Buffer中读取数据\n5、调用clear()方法或者compact()方法\n当向buffer写入数据时，buffer会记录下写了多少数据。一旦要读取数据，需要通过`flip()`方法`将Buffer从写模式切换到读模式`。在读模式下，可以读取之前写入到buffer的所有数据。\n一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。有两种方式能清空缓冲区：调用clear()或compact()方法。`clear()方法会清空整个缓冲区`。`compact()方法只会清除已经读过的数据`。任何未读的数据都被移到缓冲区的起始处，新写入的数据将放到缓冲区未读数据的后面。\n\n![Buffer-process.jpeg](http://upload-images.jianshu.io/upload_images/1419542-d832d71903ddb1e1.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n### 四个主要属性：\n* capacity：作为一个内存块，Buffer有一个固定的大小值，也叫“capacity”.你只能往里写capacity个byte、long，char等类型。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。\n* position：\n  * 当你写数据到Buffer中时，position表示当前的位置。初始的position值为0.当一个byte、long等数据写到Buffer后， position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1。\n  * 当读取数据时，也是从某个特定位置读。当将Buffer从写模式切换到读模式，position会被重置为0。 当从Buffer的position处读取数据时，position向前移动到下一个可读的位置。\n* limit：\n  * 在写模式下，Buffer的limit表示你最多能往Buffer里写多少数据。 写模式下，limit等于Buffer的capacity。\n  * 当切换Buffer到读模式时， limit表示你最多能读到多少数据。因此，当切换Buffer到读模式时，limit会被设置成写模式下的position值。换句话说，你能读到之前写入的所有数据（limit被设置成已写数据的数量，这个值在写模式下就是position）\n* mark：为某一读过的位置做标记，便于某些时候回退到该位置。\n\n### Buffer基本函数\n#### Buffer的分配\n```\nByteBuffer buf = ByteBuffer.allocate(48);\n```\n\n#### 向Buffer中写数据\n从Channel写到Buffer的例子\n```\nint bytesRead = inChannel.read(buf); //read into buffer.\n```\n通过put方法写Buffer\n```\nbuf.put(127);\n```\n\n#### 从Buffer中读取数据\n从Buffer读取数据到Channel的例子：\n```\n//read from buffer into channel.\nint bytesWritten = inChannel.write(buf);\n```\n使用get()方法从Buffer中读取数据的例子\n```\nbyte aByte = buf.get();\n```\n#### flip()方法\nflip方法将Buffer从写模式切换到读模式。调用flip()方法会将position设回0，并将limit设置成之前position的值。\n换句话说，position现在用于标记读的位置，limit表示之前写进了多少个byte、char等 —— 现在能读取多少个byte、char等。\n#### clear()与compact()方法\n一旦读完Buffer中的数据，需要让Buffer准备好再次被写入。可以通过clear()或compact()方法来完成。\n如果调用的是clear()方法，position将被设回0，limit被设置成 capacity的值。换句话说，Buffer 被清空了。Buffer中的数据并未清除，只是这些标记告诉我们可以从哪里开始往Buffer里写数据。\n如果Buffer中有一些未读的数据，调用clear()方法，数据将“被遗忘”，意味着不再有任何标记会告诉你哪些数据被读过，哪些还没有。\n如果Buffer中仍有未读的数据，且后续还需要这些数据，但是此时想要先先写些数据，那么使用compact()方法。\ncompact()方法将所有未读的数据拷贝到Buffer起始处。然后将position设到最后一个未读元素正后面。limit属性依然像clear()方法一样，设置成capacity。现在Buffer准备好写数据了，但是不会覆盖未读的数据。\n\n### 图解ByteBuffer函数过程\n#### put\nWrites the given byte into this buffer at the current position, and then increments the position. \n写模式下，往buffer里写一个字节，并把postion移动一位。写模式下，一般limit与capacity相等。 \n![Buffer-put.png](http://upload-images.jianshu.io/upload_images/1419542-ae958aab995c9963.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n#### flip\nFlips this buffer.  The limit is set to the current position and then the position is set to zero.  If the mark is defined then it is discarded.\nAfter a sequence of channel-read or `put` operations, invoke this method to prepare for a sequence of channel-write or relative  `get` operations.（即读写模型切换）\n写完数据，需要开始读的时候，将postion复位到0，并将limit设为当前postion\n```\npublic final Buffer flip() {\n        limit = position;\n        position = 0;\n        mark = -1;\n        return this;\n }\n```\n![Buffer-flip.png](http://upload-images.jianshu.io/upload_images/1419542-804ddf879bbc2cdd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n#### get\nReads the byte at this buffer's current position, and then increments the position.\n从buffer里读一个字节，并把postion移动一位。上限是limit，即写入数据的最后位置\n![Buffer-get.png](http://upload-images.jianshu.io/upload_images/1419542-2bbde49b79b2f805.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n#### clear\nClears this buffer.  The position is set to zero, the limit is set to the capacity, and the mark is discarded.\nInvoke this method before using a sequence of channel-read or `put` operations to fill this buffer.\n将position置为0，并不清除buffer内容。\n```java\n    public final Buffer clear() {\n        position = 0;\n        limit = capacity;\n        mark = -1;\n        return this;\n    }\n```\n![Buffer-clear.png](http://upload-images.jianshu.io/upload_images/1419542-9a36d39cd8787e83.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n参考：\nhttp://ifeve.com/buffers/\n博客：\nhttp://yany8060.xyz/","source":"_posts/Java-NIO-ByteBuffer概述.md","raw":"---\ntitle: Java NIO ByteBuffer概述\ndate: 2017-02-12 17:29:27\ntags: [java-nio]\ncategories: [java]\n---\n### Buffer的基本用法\n使用Buffer读写数据一般遵循以下四个步骤：\n1、分配空间\n2、写入数据到Buffer\n3、调用flip()方法\n4、从Buffer中读取数据\n5、调用clear()方法或者compact()方法\n当向buffer写入数据时，buffer会记录下写了多少数据。一旦要读取数据，需要通过`flip()`方法`将Buffer从写模式切换到读模式`。在读模式下，可以读取之前写入到buffer的所有数据。\n一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。有两种方式能清空缓冲区：调用clear()或compact()方法。`clear()方法会清空整个缓冲区`。`compact()方法只会清除已经读过的数据`。任何未读的数据都被移到缓冲区的起始处，新写入的数据将放到缓冲区未读数据的后面。\n\n![Buffer-process.jpeg](http://upload-images.jianshu.io/upload_images/1419542-d832d71903ddb1e1.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n### 四个主要属性：\n* capacity：作为一个内存块，Buffer有一个固定的大小值，也叫“capacity”.你只能往里写capacity个byte、long，char等类型。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。\n* position：\n  * 当你写数据到Buffer中时，position表示当前的位置。初始的position值为0.当一个byte、long等数据写到Buffer后， position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1。\n  * 当读取数据时，也是从某个特定位置读。当将Buffer从写模式切换到读模式，position会被重置为0。 当从Buffer的position处读取数据时，position向前移动到下一个可读的位置。\n* limit：\n  * 在写模式下，Buffer的limit表示你最多能往Buffer里写多少数据。 写模式下，limit等于Buffer的capacity。\n  * 当切换Buffer到读模式时， limit表示你最多能读到多少数据。因此，当切换Buffer到读模式时，limit会被设置成写模式下的position值。换句话说，你能读到之前写入的所有数据（limit被设置成已写数据的数量，这个值在写模式下就是position）\n* mark：为某一读过的位置做标记，便于某些时候回退到该位置。\n\n### Buffer基本函数\n#### Buffer的分配\n```\nByteBuffer buf = ByteBuffer.allocate(48);\n```\n\n#### 向Buffer中写数据\n从Channel写到Buffer的例子\n```\nint bytesRead = inChannel.read(buf); //read into buffer.\n```\n通过put方法写Buffer\n```\nbuf.put(127);\n```\n\n#### 从Buffer中读取数据\n从Buffer读取数据到Channel的例子：\n```\n//read from buffer into channel.\nint bytesWritten = inChannel.write(buf);\n```\n使用get()方法从Buffer中读取数据的例子\n```\nbyte aByte = buf.get();\n```\n#### flip()方法\nflip方法将Buffer从写模式切换到读模式。调用flip()方法会将position设回0，并将limit设置成之前position的值。\n换句话说，position现在用于标记读的位置，limit表示之前写进了多少个byte、char等 —— 现在能读取多少个byte、char等。\n#### clear()与compact()方法\n一旦读完Buffer中的数据，需要让Buffer准备好再次被写入。可以通过clear()或compact()方法来完成。\n如果调用的是clear()方法，position将被设回0，limit被设置成 capacity的值。换句话说，Buffer 被清空了。Buffer中的数据并未清除，只是这些标记告诉我们可以从哪里开始往Buffer里写数据。\n如果Buffer中有一些未读的数据，调用clear()方法，数据将“被遗忘”，意味着不再有任何标记会告诉你哪些数据被读过，哪些还没有。\n如果Buffer中仍有未读的数据，且后续还需要这些数据，但是此时想要先先写些数据，那么使用compact()方法。\ncompact()方法将所有未读的数据拷贝到Buffer起始处。然后将position设到最后一个未读元素正后面。limit属性依然像clear()方法一样，设置成capacity。现在Buffer准备好写数据了，但是不会覆盖未读的数据。\n\n### 图解ByteBuffer函数过程\n#### put\nWrites the given byte into this buffer at the current position, and then increments the position. \n写模式下，往buffer里写一个字节，并把postion移动一位。写模式下，一般limit与capacity相等。 \n![Buffer-put.png](http://upload-images.jianshu.io/upload_images/1419542-ae958aab995c9963.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n#### flip\nFlips this buffer.  The limit is set to the current position and then the position is set to zero.  If the mark is defined then it is discarded.\nAfter a sequence of channel-read or `put` operations, invoke this method to prepare for a sequence of channel-write or relative  `get` operations.（即读写模型切换）\n写完数据，需要开始读的时候，将postion复位到0，并将limit设为当前postion\n```\npublic final Buffer flip() {\n        limit = position;\n        position = 0;\n        mark = -1;\n        return this;\n }\n```\n![Buffer-flip.png](http://upload-images.jianshu.io/upload_images/1419542-804ddf879bbc2cdd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n#### get\nReads the byte at this buffer's current position, and then increments the position.\n从buffer里读一个字节，并把postion移动一位。上限是limit，即写入数据的最后位置\n![Buffer-get.png](http://upload-images.jianshu.io/upload_images/1419542-2bbde49b79b2f805.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n#### clear\nClears this buffer.  The position is set to zero, the limit is set to the capacity, and the mark is discarded.\nInvoke this method before using a sequence of channel-read or `put` operations to fill this buffer.\n将position置为0，并不清除buffer内容。\n```java\n    public final Buffer clear() {\n        position = 0;\n        limit = capacity;\n        mark = -1;\n        return this;\n    }\n```\n![Buffer-clear.png](http://upload-images.jianshu.io/upload_images/1419542-9a36d39cd8787e83.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n参考：\nhttp://ifeve.com/buffers/\n博客：\nhttp://yany8060.xyz/","slug":"Java-NIO-ByteBuffer概述","published":1,"updated":"2018-09-03T12:29:46.714Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmo9un2k00009q0v9xlyzc9n","content":"<h3 id=\"Buffer的基本用法\"><a href=\"#Buffer的基本用法\" class=\"headerlink\" title=\"Buffer的基本用法\"></a>Buffer的基本用法</h3><p>使用Buffer读写数据一般遵循以下四个步骤：<br>1、分配空间<br>2、写入数据到Buffer<br>3、调用flip()方法<br>4、从Buffer中读取数据<br>5、调用clear()方法或者compact()方法<br>当向buffer写入数据时，buffer会记录下写了多少数据。一旦要读取数据，需要通过<code>flip()</code>方法<code>将Buffer从写模式切换到读模式</code>。在读模式下，可以读取之前写入到buffer的所有数据。<br>一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。有两种方式能清空缓冲区：调用clear()或compact()方法。<code>clear()方法会清空整个缓冲区</code>。<code>compact()方法只会清除已经读过的数据</code>。任何未读的数据都被移到缓冲区的起始处，新写入的数据将放到缓冲区未读数据的后面。</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-d832d71903ddb1e1.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"Buffer-process.jpeg\"></p>\n<h3 id=\"四个主要属性：\"><a href=\"#四个主要属性：\" class=\"headerlink\" title=\"四个主要属性：\"></a>四个主要属性：</h3><ul>\n<li>capacity：作为一个内存块，Buffer有一个固定的大小值，也叫“capacity”.你只能往里写capacity个byte、long，char等类型。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。</li>\n<li>position：<ul>\n<li>当你写数据到Buffer中时，position表示当前的位置。初始的position值为0.当一个byte、long等数据写到Buffer后， position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1。</li>\n<li>当读取数据时，也是从某个特定位置读。当将Buffer从写模式切换到读模式，position会被重置为0。 当从Buffer的position处读取数据时，position向前移动到下一个可读的位置。</li>\n</ul>\n</li>\n<li>limit：<ul>\n<li>在写模式下，Buffer的limit表示你最多能往Buffer里写多少数据。 写模式下，limit等于Buffer的capacity。</li>\n<li>当切换Buffer到读模式时， limit表示你最多能读到多少数据。因此，当切换Buffer到读模式时，limit会被设置成写模式下的position值。换句话说，你能读到之前写入的所有数据（limit被设置成已写数据的数量，这个值在写模式下就是position）</li>\n</ul>\n</li>\n<li>mark：为某一读过的位置做标记，便于某些时候回退到该位置。</li>\n</ul>\n<h3 id=\"Buffer基本函数\"><a href=\"#Buffer基本函数\" class=\"headerlink\" title=\"Buffer基本函数\"></a>Buffer基本函数</h3><h4 id=\"Buffer的分配\"><a href=\"#Buffer的分配\" class=\"headerlink\" title=\"Buffer的分配\"></a>Buffer的分配</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ByteBuffer buf = ByteBuffer.allocate(48);</span><br></pre></td></tr></table></figure>\n<h4 id=\"向Buffer中写数据\"><a href=\"#向Buffer中写数据\" class=\"headerlink\" title=\"向Buffer中写数据\"></a>向Buffer中写数据</h4><p>从Channel写到Buffer的例子<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int bytesRead = inChannel.read(buf); //read into buffer.</span><br></pre></td></tr></table></figure></p>\n<p>通过put方法写Buffer<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">buf.put(127);</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"从Buffer中读取数据\"><a href=\"#从Buffer中读取数据\" class=\"headerlink\" title=\"从Buffer中读取数据\"></a>从Buffer中读取数据</h4><p>从Buffer读取数据到Channel的例子：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//read from buffer into channel.</span><br><span class=\"line\">int bytesWritten = inChannel.write(buf);</span><br></pre></td></tr></table></figure></p>\n<p>使用get()方法从Buffer中读取数据的例子<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">byte aByte = buf.get();</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"flip-方法\"><a href=\"#flip-方法\" class=\"headerlink\" title=\"flip()方法\"></a>flip()方法</h4><p>flip方法将Buffer从写模式切换到读模式。调用flip()方法会将position设回0，并将limit设置成之前position的值。<br>换句话说，position现在用于标记读的位置，limit表示之前写进了多少个byte、char等 —— 现在能读取多少个byte、char等。</p>\n<h4 id=\"clear-与compact-方法\"><a href=\"#clear-与compact-方法\" class=\"headerlink\" title=\"clear()与compact()方法\"></a>clear()与compact()方法</h4><p>一旦读完Buffer中的数据，需要让Buffer准备好再次被写入。可以通过clear()或compact()方法来完成。<br>如果调用的是clear()方法，position将被设回0，limit被设置成 capacity的值。换句话说，Buffer 被清空了。Buffer中的数据并未清除，只是这些标记告诉我们可以从哪里开始往Buffer里写数据。<br>如果Buffer中有一些未读的数据，调用clear()方法，数据将“被遗忘”，意味着不再有任何标记会告诉你哪些数据被读过，哪些还没有。<br>如果Buffer中仍有未读的数据，且后续还需要这些数据，但是此时想要先先写些数据，那么使用compact()方法。<br>compact()方法将所有未读的数据拷贝到Buffer起始处。然后将position设到最后一个未读元素正后面。limit属性依然像clear()方法一样，设置成capacity。现在Buffer准备好写数据了，但是不会覆盖未读的数据。</p>\n<h3 id=\"图解ByteBuffer函数过程\"><a href=\"#图解ByteBuffer函数过程\" class=\"headerlink\" title=\"图解ByteBuffer函数过程\"></a>图解ByteBuffer函数过程</h3><h4 id=\"put\"><a href=\"#put\" class=\"headerlink\" title=\"put\"></a>put</h4><p>Writes the given byte into this buffer at the current position, and then increments the position.<br>写模式下，往buffer里写一个字节，并把postion移动一位。写模式下，一般limit与capacity相等。<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-ae958aab995c9963.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"Buffer-put.png\"></p>\n<h4 id=\"flip\"><a href=\"#flip\" class=\"headerlink\" title=\"flip\"></a>flip</h4><p>Flips this buffer.  The limit is set to the current position and then the position is set to zero.  If the mark is defined then it is discarded.<br>After a sequence of channel-read or <code>put</code> operations, invoke this method to prepare for a sequence of channel-write or relative  <code>get</code> operations.（即读写模型切换）<br>写完数据，需要开始读的时候，将postion复位到0，并将limit设为当前postion<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public final Buffer flip() &#123;</span><br><span class=\"line\">        limit = position;</span><br><span class=\"line\">        position = 0;</span><br><span class=\"line\">        mark = -1;</span><br><span class=\"line\">        return this;</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-804ddf879bbc2cdd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"Buffer-flip.png\"></p>\n<h4 id=\"get\"><a href=\"#get\" class=\"headerlink\" title=\"get\"></a>get</h4><p>Reads the byte at this buffer’s current position, and then increments the position.<br>从buffer里读一个字节，并把postion移动一位。上限是limit，即写入数据的最后位置<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-2bbde49b79b2f805.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"Buffer-get.png\"></p>\n<h4 id=\"clear\"><a href=\"#clear\" class=\"headerlink\" title=\"clear\"></a>clear</h4><p>Clears this buffer.  The position is set to zero, the limit is set to the capacity, and the mark is discarded.<br>Invoke this method before using a sequence of channel-read or <code>put</code> operations to fill this buffer.<br>将position置为0，并不清除buffer内容。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> Buffer <span class=\"title\">clear</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    position = <span class=\"number\">0</span>;</span><br><span class=\"line\">    limit = capacity;</span><br><span class=\"line\">    mark = -<span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-9a36d39cd8787e83.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"Buffer-clear.png\"></p>\n<p>参考：<br><a href=\"http://ifeve.com/buffers/\" target=\"_blank\" rel=\"noopener\">http://ifeve.com/buffers/</a><br>博客：<br><a href=\"http://yany8060.xyz/\" target=\"_blank\" rel=\"noopener\">http://yany8060.xyz/</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Buffer的基本用法\"><a href=\"#Buffer的基本用法\" class=\"headerlink\" title=\"Buffer的基本用法\"></a>Buffer的基本用法</h3><p>使用Buffer读写数据一般遵循以下四个步骤：<br>1、分配空间<br>2、写入数据到Buffer<br>3、调用flip()方法<br>4、从Buffer中读取数据<br>5、调用clear()方法或者compact()方法<br>当向buffer写入数据时，buffer会记录下写了多少数据。一旦要读取数据，需要通过<code>flip()</code>方法<code>将Buffer从写模式切换到读模式</code>。在读模式下，可以读取之前写入到buffer的所有数据。<br>一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。有两种方式能清空缓冲区：调用clear()或compact()方法。<code>clear()方法会清空整个缓冲区</code>。<code>compact()方法只会清除已经读过的数据</code>。任何未读的数据都被移到缓冲区的起始处，新写入的数据将放到缓冲区未读数据的后面。</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-d832d71903ddb1e1.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"Buffer-process.jpeg\"></p>\n<h3 id=\"四个主要属性：\"><a href=\"#四个主要属性：\" class=\"headerlink\" title=\"四个主要属性：\"></a>四个主要属性：</h3><ul>\n<li>capacity：作为一个内存块，Buffer有一个固定的大小值，也叫“capacity”.你只能往里写capacity个byte、long，char等类型。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。</li>\n<li>position：<ul>\n<li>当你写数据到Buffer中时，position表示当前的位置。初始的position值为0.当一个byte、long等数据写到Buffer后， position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1。</li>\n<li>当读取数据时，也是从某个特定位置读。当将Buffer从写模式切换到读模式，position会被重置为0。 当从Buffer的position处读取数据时，position向前移动到下一个可读的位置。</li>\n</ul>\n</li>\n<li>limit：<ul>\n<li>在写模式下，Buffer的limit表示你最多能往Buffer里写多少数据。 写模式下，limit等于Buffer的capacity。</li>\n<li>当切换Buffer到读模式时， limit表示你最多能读到多少数据。因此，当切换Buffer到读模式时，limit会被设置成写模式下的position值。换句话说，你能读到之前写入的所有数据（limit被设置成已写数据的数量，这个值在写模式下就是position）</li>\n</ul>\n</li>\n<li>mark：为某一读过的位置做标记，便于某些时候回退到该位置。</li>\n</ul>\n<h3 id=\"Buffer基本函数\"><a href=\"#Buffer基本函数\" class=\"headerlink\" title=\"Buffer基本函数\"></a>Buffer基本函数</h3><h4 id=\"Buffer的分配\"><a href=\"#Buffer的分配\" class=\"headerlink\" title=\"Buffer的分配\"></a>Buffer的分配</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ByteBuffer buf = ByteBuffer.allocate(48);</span><br></pre></td></tr></table></figure>\n<h4 id=\"向Buffer中写数据\"><a href=\"#向Buffer中写数据\" class=\"headerlink\" title=\"向Buffer中写数据\"></a>向Buffer中写数据</h4><p>从Channel写到Buffer的例子<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int bytesRead = inChannel.read(buf); //read into buffer.</span><br></pre></td></tr></table></figure></p>\n<p>通过put方法写Buffer<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">buf.put(127);</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"从Buffer中读取数据\"><a href=\"#从Buffer中读取数据\" class=\"headerlink\" title=\"从Buffer中读取数据\"></a>从Buffer中读取数据</h4><p>从Buffer读取数据到Channel的例子：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//read from buffer into channel.</span><br><span class=\"line\">int bytesWritten = inChannel.write(buf);</span><br></pre></td></tr></table></figure></p>\n<p>使用get()方法从Buffer中读取数据的例子<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">byte aByte = buf.get();</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"flip-方法\"><a href=\"#flip-方法\" class=\"headerlink\" title=\"flip()方法\"></a>flip()方法</h4><p>flip方法将Buffer从写模式切换到读模式。调用flip()方法会将position设回0，并将limit设置成之前position的值。<br>换句话说，position现在用于标记读的位置，limit表示之前写进了多少个byte、char等 —— 现在能读取多少个byte、char等。</p>\n<h4 id=\"clear-与compact-方法\"><a href=\"#clear-与compact-方法\" class=\"headerlink\" title=\"clear()与compact()方法\"></a>clear()与compact()方法</h4><p>一旦读完Buffer中的数据，需要让Buffer准备好再次被写入。可以通过clear()或compact()方法来完成。<br>如果调用的是clear()方法，position将被设回0，limit被设置成 capacity的值。换句话说，Buffer 被清空了。Buffer中的数据并未清除，只是这些标记告诉我们可以从哪里开始往Buffer里写数据。<br>如果Buffer中有一些未读的数据，调用clear()方法，数据将“被遗忘”，意味着不再有任何标记会告诉你哪些数据被读过，哪些还没有。<br>如果Buffer中仍有未读的数据，且后续还需要这些数据，但是此时想要先先写些数据，那么使用compact()方法。<br>compact()方法将所有未读的数据拷贝到Buffer起始处。然后将position设到最后一个未读元素正后面。limit属性依然像clear()方法一样，设置成capacity。现在Buffer准备好写数据了，但是不会覆盖未读的数据。</p>\n<h3 id=\"图解ByteBuffer函数过程\"><a href=\"#图解ByteBuffer函数过程\" class=\"headerlink\" title=\"图解ByteBuffer函数过程\"></a>图解ByteBuffer函数过程</h3><h4 id=\"put\"><a href=\"#put\" class=\"headerlink\" title=\"put\"></a>put</h4><p>Writes the given byte into this buffer at the current position, and then increments the position.<br>写模式下，往buffer里写一个字节，并把postion移动一位。写模式下，一般limit与capacity相等。<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-ae958aab995c9963.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"Buffer-put.png\"></p>\n<h4 id=\"flip\"><a href=\"#flip\" class=\"headerlink\" title=\"flip\"></a>flip</h4><p>Flips this buffer.  The limit is set to the current position and then the position is set to zero.  If the mark is defined then it is discarded.<br>After a sequence of channel-read or <code>put</code> operations, invoke this method to prepare for a sequence of channel-write or relative  <code>get</code> operations.（即读写模型切换）<br>写完数据，需要开始读的时候，将postion复位到0，并将limit设为当前postion<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public final Buffer flip() &#123;</span><br><span class=\"line\">        limit = position;</span><br><span class=\"line\">        position = 0;</span><br><span class=\"line\">        mark = -1;</span><br><span class=\"line\">        return this;</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-804ddf879bbc2cdd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"Buffer-flip.png\"></p>\n<h4 id=\"get\"><a href=\"#get\" class=\"headerlink\" title=\"get\"></a>get</h4><p>Reads the byte at this buffer’s current position, and then increments the position.<br>从buffer里读一个字节，并把postion移动一位。上限是limit，即写入数据的最后位置<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-2bbde49b79b2f805.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"Buffer-get.png\"></p>\n<h4 id=\"clear\"><a href=\"#clear\" class=\"headerlink\" title=\"clear\"></a>clear</h4><p>Clears this buffer.  The position is set to zero, the limit is set to the capacity, and the mark is discarded.<br>Invoke this method before using a sequence of channel-read or <code>put</code> operations to fill this buffer.<br>将position置为0，并不清除buffer内容。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> Buffer <span class=\"title\">clear</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    position = <span class=\"number\">0</span>;</span><br><span class=\"line\">    limit = capacity;</span><br><span class=\"line\">    mark = -<span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-9a36d39cd8787e83.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"Buffer-clear.png\"></p>\n<p>参考：<br><a href=\"http://ifeve.com/buffers/\" target=\"_blank\" rel=\"noopener\">http://ifeve.com/buffers/</a><br>博客：<br><a href=\"http://yany8060.xyz/\" target=\"_blank\" rel=\"noopener\">http://yany8060.xyz/</a></p>\n"},{"title":"Java NIO简述","date":"2017-02-12T08:45:16.000Z","_content":"### 概述\nJava NIO(New IO)是一个可以替代标准Java IO API的IO API（从Java 1.4开始)，Java NIO提供了与标准IO不同的IO工作方式。\n\n### I/O模型\n* 同步阻塞IO：在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。JAVA传统的IO模型属于此种方式！\n* 同步非阻塞IO：在此种方式下，用户进程发起一个IO操作以后边可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。其中目前JAVA的NIO就属于同步非阻塞IO。\n* 异步阻塞IO：此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问IO是否完成，那么为什么说是阻塞的呢？因为此时是通过select系统调用来完成的，而select函数本身的实现方式是阻塞的，而采用select函数有个好处就是它可以同时监听多个文件句柄，从而提高系统的并发性！\n* 异步非阻塞IO：在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。目前Java中还没有支持此种IO模型。 \n\n### BIO、NIO、AIO\n* Java BIO ： __同步并阻塞__，服务器实现模式为__一个连接一个线程__，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。\n* Java NIO：__同步非阻塞__，服务器实现模式为__一个请求一个线程__，即客户端发送的连接请求都会注册到多路复用器上，多路复用器__轮询__到连接有I/O请求时才启动一个线程进行处理。\n* Java AIO：__异步非阻塞__，服务器实现模式为__一个有效请求一个线程__，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理。\n\n### Java NIO由以下几个核心部分组成：\n* Channel（通道）\n* Buffer（缓冲区）\n* Selector（选择器）\n\n#### channel\nJava NIO的通道类似流，但又有些不同：\n* 既可以从通道中读取数据，又可以写数据到通道。但流的读写通常是单向的。\n* 通道可以异步地读写。\n* 通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入\n![overview-channels-buffers.png](http://upload-images.jianshu.io/upload_images/1419542-75f7966a4f4478ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\nChannel的实现\n* `FileChannel` 从文件中读写数据\n* `DatagramChannel`能通过UDP读写网络中的数据\n* `SocketChannel` 能通过TCP读写网络中的数据\n* `ServerSocketChannel` 可以监听新进来的TCP连接，像Web服务器那样，对每一个新进来的连接都创建一个SocketChannel。\n\n#### Buffer\nJava NIO中的Buffer用于和NIO通道进行交互。如你所知，数据是从通道读入缓冲区，从缓冲区写入到通道中的。\n缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。\n\n#### Selector\nSelector是Java NIO中能够检测一到多个NIO通道，并能够知晓通道是否为诸如读写事件做好准备的组件。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。\n![selectors.png](http://upload-images.jianshu.io/upload_images/1419542-683c996697d33078.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n要使用Selector，得向Selector注册Channel，然后调用它的select()方法。这个方法会一直阻塞到某个注册的通道有事件就绪。一旦这个方法返回，线程就可以处理这些事件，事件的例子有如新连接进来，数据接收等。\n\n\nSelector的创建\n```\nSelector selector = Selector.open();\n```\n向Selector注册通道\n```\n// 与Selector一起使用时，Channel必须处于非阻塞模式下\nchannel.configureBlocking(false);\nSelectionKey key = channel.register(selector,Selectionkey.OP_READ);\n```\n通过Selector选择通道：一旦向Selector注册了一或多个通道，就可以调用几个重载的select()方法。这些方法返回你所感兴趣的事件（如连接、接受、读或写）已经准备就绪的那些通道\n```\nint select() //阻塞到至少有一个通道在你注册的事件上就绪了\nint select(long timeout) //和select()一样，除了最长会阻塞timeout毫秒(参数)\nint selectNow()  //不会阻塞，不管什么通道就绪都立刻返回\n```","source":"_posts/Java-NIO简述.md","raw":"---\ntitle: Java NIO简述\ndate: 2017-02-12 16:45:16\ntags: [java-nio]\ncategories: [java]\n---\n### 概述\nJava NIO(New IO)是一个可以替代标准Java IO API的IO API（从Java 1.4开始)，Java NIO提供了与标准IO不同的IO工作方式。\n\n### I/O模型\n* 同步阻塞IO：在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。JAVA传统的IO模型属于此种方式！\n* 同步非阻塞IO：在此种方式下，用户进程发起一个IO操作以后边可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。其中目前JAVA的NIO就属于同步非阻塞IO。\n* 异步阻塞IO：此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问IO是否完成，那么为什么说是阻塞的呢？因为此时是通过select系统调用来完成的，而select函数本身的实现方式是阻塞的，而采用select函数有个好处就是它可以同时监听多个文件句柄，从而提高系统的并发性！\n* 异步非阻塞IO：在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。目前Java中还没有支持此种IO模型。 \n\n### BIO、NIO、AIO\n* Java BIO ： __同步并阻塞__，服务器实现模式为__一个连接一个线程__，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。\n* Java NIO：__同步非阻塞__，服务器实现模式为__一个请求一个线程__，即客户端发送的连接请求都会注册到多路复用器上，多路复用器__轮询__到连接有I/O请求时才启动一个线程进行处理。\n* Java AIO：__异步非阻塞__，服务器实现模式为__一个有效请求一个线程__，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理。\n\n### Java NIO由以下几个核心部分组成：\n* Channel（通道）\n* Buffer（缓冲区）\n* Selector（选择器）\n\n#### channel\nJava NIO的通道类似流，但又有些不同：\n* 既可以从通道中读取数据，又可以写数据到通道。但流的读写通常是单向的。\n* 通道可以异步地读写。\n* 通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入\n![overview-channels-buffers.png](http://upload-images.jianshu.io/upload_images/1419542-75f7966a4f4478ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\nChannel的实现\n* `FileChannel` 从文件中读写数据\n* `DatagramChannel`能通过UDP读写网络中的数据\n* `SocketChannel` 能通过TCP读写网络中的数据\n* `ServerSocketChannel` 可以监听新进来的TCP连接，像Web服务器那样，对每一个新进来的连接都创建一个SocketChannel。\n\n#### Buffer\nJava NIO中的Buffer用于和NIO通道进行交互。如你所知，数据是从通道读入缓冲区，从缓冲区写入到通道中的。\n缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。\n\n#### Selector\nSelector是Java NIO中能够检测一到多个NIO通道，并能够知晓通道是否为诸如读写事件做好准备的组件。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。\n![selectors.png](http://upload-images.jianshu.io/upload_images/1419542-683c996697d33078.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n要使用Selector，得向Selector注册Channel，然后调用它的select()方法。这个方法会一直阻塞到某个注册的通道有事件就绪。一旦这个方法返回，线程就可以处理这些事件，事件的例子有如新连接进来，数据接收等。\n\n\nSelector的创建\n```\nSelector selector = Selector.open();\n```\n向Selector注册通道\n```\n// 与Selector一起使用时，Channel必须处于非阻塞模式下\nchannel.configureBlocking(false);\nSelectionKey key = channel.register(selector,Selectionkey.OP_READ);\n```\n通过Selector选择通道：一旦向Selector注册了一或多个通道，就可以调用几个重载的select()方法。这些方法返回你所感兴趣的事件（如连接、接受、读或写）已经准备就绪的那些通道\n```\nint select() //阻塞到至少有一个通道在你注册的事件上就绪了\nint select(long timeout) //和select()一样，除了最长会阻塞timeout毫秒(参数)\nint selectNow()  //不会阻塞，不管什么通道就绪都立刻返回\n```","slug":"Java-NIO简述","published":1,"updated":"2018-09-03T12:29:46.715Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmo9un2o00029q0vs1ijco55","content":"<h3 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h3><p>Java NIO(New IO)是一个可以替代标准Java IO API的IO API（从Java 1.4开始)，Java NIO提供了与标准IO不同的IO工作方式。</p>\n<h3 id=\"I-O模型\"><a href=\"#I-O模型\" class=\"headerlink\" title=\"I/O模型\"></a>I/O模型</h3><ul>\n<li>同步阻塞IO：在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。JAVA传统的IO模型属于此种方式！</li>\n<li>同步非阻塞IO：在此种方式下，用户进程发起一个IO操作以后边可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。其中目前JAVA的NIO就属于同步非阻塞IO。</li>\n<li>异步阻塞IO：此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问IO是否完成，那么为什么说是阻塞的呢？因为此时是通过select系统调用来完成的，而select函数本身的实现方式是阻塞的，而采用select函数有个好处就是它可以同时监听多个文件句柄，从而提高系统的并发性！</li>\n<li>异步非阻塞IO：在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。目前Java中还没有支持此种IO模型。 </li>\n</ul>\n<h3 id=\"BIO、NIO、AIO\"><a href=\"#BIO、NIO、AIO\" class=\"headerlink\" title=\"BIO、NIO、AIO\"></a>BIO、NIO、AIO</h3><ul>\n<li>Java BIO ： <strong>同步并阻塞</strong>，服务器实现模式为<strong>一个连接一个线程</strong>，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。</li>\n<li>Java NIO：<strong>同步非阻塞</strong>，服务器实现模式为<strong>一个请求一个线程</strong>，即客户端发送的连接请求都会注册到多路复用器上，多路复用器<strong>轮询</strong>到连接有I/O请求时才启动一个线程进行处理。</li>\n<li>Java AIO：<strong>异步非阻塞</strong>，服务器实现模式为<strong>一个有效请求一个线程</strong>，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理。</li>\n</ul>\n<h3 id=\"Java-NIO由以下几个核心部分组成：\"><a href=\"#Java-NIO由以下几个核心部分组成：\" class=\"headerlink\" title=\"Java NIO由以下几个核心部分组成：\"></a>Java NIO由以下几个核心部分组成：</h3><ul>\n<li>Channel（通道）</li>\n<li>Buffer（缓冲区）</li>\n<li>Selector（选择器）</li>\n</ul>\n<h4 id=\"channel\"><a href=\"#channel\" class=\"headerlink\" title=\"channel\"></a>channel</h4><p>Java NIO的通道类似流，但又有些不同：</p>\n<ul>\n<li>既可以从通道中读取数据，又可以写数据到通道。但流的读写通常是单向的。</li>\n<li>通道可以异步地读写。</li>\n<li>通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-75f7966a4f4478ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"overview-channels-buffers.png\"></li>\n</ul>\n<p>Channel的实现</p>\n<ul>\n<li><code>FileChannel</code> 从文件中读写数据</li>\n<li><code>DatagramChannel</code>能通过UDP读写网络中的数据</li>\n<li><code>SocketChannel</code> 能通过TCP读写网络中的数据</li>\n<li><code>ServerSocketChannel</code> 可以监听新进来的TCP连接，像Web服务器那样，对每一个新进来的连接都创建一个SocketChannel。</li>\n</ul>\n<h4 id=\"Buffer\"><a href=\"#Buffer\" class=\"headerlink\" title=\"Buffer\"></a>Buffer</h4><p>Java NIO中的Buffer用于和NIO通道进行交互。如你所知，数据是从通道读入缓冲区，从缓冲区写入到通道中的。<br>缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。</p>\n<h4 id=\"Selector\"><a href=\"#Selector\" class=\"headerlink\" title=\"Selector\"></a>Selector</h4><p>Selector是Java NIO中能够检测一到多个NIO通道，并能够知晓通道是否为诸如读写事件做好准备的组件。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-683c996697d33078.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"selectors.png\"><br>要使用Selector，得向Selector注册Channel，然后调用它的select()方法。这个方法会一直阻塞到某个注册的通道有事件就绪。一旦这个方法返回，线程就可以处理这些事件，事件的例子有如新连接进来，数据接收等。</p>\n<p>Selector的创建<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Selector selector = Selector.open();</span><br></pre></td></tr></table></figure></p>\n<p>向Selector注册通道<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 与Selector一起使用时，Channel必须处于非阻塞模式下</span><br><span class=\"line\">channel.configureBlocking(false);</span><br><span class=\"line\">SelectionKey key = channel.register(selector,Selectionkey.OP_READ);</span><br></pre></td></tr></table></figure></p>\n<p>通过Selector选择通道：一旦向Selector注册了一或多个通道，就可以调用几个重载的select()方法。这些方法返回你所感兴趣的事件（如连接、接受、读或写）已经准备就绪的那些通道<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int select() //阻塞到至少有一个通道在你注册的事件上就绪了</span><br><span class=\"line\">int select(long timeout) //和select()一样，除了最长会阻塞timeout毫秒(参数)</span><br><span class=\"line\">int selectNow()  //不会阻塞，不管什么通道就绪都立刻返回</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h3><p>Java NIO(New IO)是一个可以替代标准Java IO API的IO API（从Java 1.4开始)，Java NIO提供了与标准IO不同的IO工作方式。</p>\n<h3 id=\"I-O模型\"><a href=\"#I-O模型\" class=\"headerlink\" title=\"I/O模型\"></a>I/O模型</h3><ul>\n<li>同步阻塞IO：在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。JAVA传统的IO模型属于此种方式！</li>\n<li>同步非阻塞IO：在此种方式下，用户进程发起一个IO操作以后边可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。其中目前JAVA的NIO就属于同步非阻塞IO。</li>\n<li>异步阻塞IO：此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问IO是否完成，那么为什么说是阻塞的呢？因为此时是通过select系统调用来完成的，而select函数本身的实现方式是阻塞的，而采用select函数有个好处就是它可以同时监听多个文件句柄，从而提高系统的并发性！</li>\n<li>异步非阻塞IO：在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。目前Java中还没有支持此种IO模型。 </li>\n</ul>\n<h3 id=\"BIO、NIO、AIO\"><a href=\"#BIO、NIO、AIO\" class=\"headerlink\" title=\"BIO、NIO、AIO\"></a>BIO、NIO、AIO</h3><ul>\n<li>Java BIO ： <strong>同步并阻塞</strong>，服务器实现模式为<strong>一个连接一个线程</strong>，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。</li>\n<li>Java NIO：<strong>同步非阻塞</strong>，服务器实现模式为<strong>一个请求一个线程</strong>，即客户端发送的连接请求都会注册到多路复用器上，多路复用器<strong>轮询</strong>到连接有I/O请求时才启动一个线程进行处理。</li>\n<li>Java AIO：<strong>异步非阻塞</strong>，服务器实现模式为<strong>一个有效请求一个线程</strong>，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理。</li>\n</ul>\n<h3 id=\"Java-NIO由以下几个核心部分组成：\"><a href=\"#Java-NIO由以下几个核心部分组成：\" class=\"headerlink\" title=\"Java NIO由以下几个核心部分组成：\"></a>Java NIO由以下几个核心部分组成：</h3><ul>\n<li>Channel（通道）</li>\n<li>Buffer（缓冲区）</li>\n<li>Selector（选择器）</li>\n</ul>\n<h4 id=\"channel\"><a href=\"#channel\" class=\"headerlink\" title=\"channel\"></a>channel</h4><p>Java NIO的通道类似流，但又有些不同：</p>\n<ul>\n<li>既可以从通道中读取数据，又可以写数据到通道。但流的读写通常是单向的。</li>\n<li>通道可以异步地读写。</li>\n<li>通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-75f7966a4f4478ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"overview-channels-buffers.png\"></li>\n</ul>\n<p>Channel的实现</p>\n<ul>\n<li><code>FileChannel</code> 从文件中读写数据</li>\n<li><code>DatagramChannel</code>能通过UDP读写网络中的数据</li>\n<li><code>SocketChannel</code> 能通过TCP读写网络中的数据</li>\n<li><code>ServerSocketChannel</code> 可以监听新进来的TCP连接，像Web服务器那样，对每一个新进来的连接都创建一个SocketChannel。</li>\n</ul>\n<h4 id=\"Buffer\"><a href=\"#Buffer\" class=\"headerlink\" title=\"Buffer\"></a>Buffer</h4><p>Java NIO中的Buffer用于和NIO通道进行交互。如你所知，数据是从通道读入缓冲区，从缓冲区写入到通道中的。<br>缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。</p>\n<h4 id=\"Selector\"><a href=\"#Selector\" class=\"headerlink\" title=\"Selector\"></a>Selector</h4><p>Selector是Java NIO中能够检测一到多个NIO通道，并能够知晓通道是否为诸如读写事件做好准备的组件。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-683c996697d33078.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"selectors.png\"><br>要使用Selector，得向Selector注册Channel，然后调用它的select()方法。这个方法会一直阻塞到某个注册的通道有事件就绪。一旦这个方法返回，线程就可以处理这些事件，事件的例子有如新连接进来，数据接收等。</p>\n<p>Selector的创建<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Selector selector = Selector.open();</span><br></pre></td></tr></table></figure></p>\n<p>向Selector注册通道<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 与Selector一起使用时，Channel必须处于非阻塞模式下</span><br><span class=\"line\">channel.configureBlocking(false);</span><br><span class=\"line\">SelectionKey key = channel.register(selector,Selectionkey.OP_READ);</span><br></pre></td></tr></table></figure></p>\n<p>通过Selector选择通道：一旦向Selector注册了一或多个通道，就可以调用几个重载的select()方法。这些方法返回你所感兴趣的事件（如连接、接受、读或写）已经准备就绪的那些通道<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int select() //阻塞到至少有一个通道在你注册的事件上就绪了</span><br><span class=\"line\">int select(long timeout) //和select()一样，除了最长会阻塞timeout毫秒(参数)</span><br><span class=\"line\">int selectNow()  //不会阻塞，不管什么通道就绪都立刻返回</span><br></pre></td></tr></table></figure></p>\n"},{"title":"Java Thread概述","date":"2017-03-08T11:33:39.000Z","_content":"### 线程生命周期\n\n![Threadlife_20170208.jpg](http://upload-images.jianshu.io/upload_images/1419542-7b0fe1fa20076f52.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/620)\n线程状态：\n* 新建状态：使用new关键字和Thread类或其子类建立一个线程对象后\n* 就绪状态：当线程对象调用了start()方法之后，该线程进入就绪状态\n* 运行状态：如果就绪状态的线程获取CPU资源，就可以执行run()\n* 阻塞状态：\n  * 等待阻塞：运行状态中的线程执行wait()方法\n  * 同步阻塞：线程在获取 synchronized 同步锁失败\n  * 其他阻塞：通过调用线程的sleep()或join()发出I/O请求时\n* 死亡状态：一个运行状态的线程完成人文或者其他终止条件发送\n\n### 创建线程\n1、继承Thread类\n```java\nclass ThreadDemo extends Thread\n```\n2、实现Runable接口\n```java\npublic class RunTest implements Runnable\n   \nThread thread1 = new Thread(new RunTest());\n```\n3、通过Callable、Future、FutureTask创建线程\n```\n// 继承实现Callable接口，声明返回类型\nclass CallTest implements Callable<Long> \n    \nFutureTask<Long> futureTask = new FutureTask<Long>(new CallTest(searchVo));\n```\n\n### 线程内置方法\n1、sleep：使当前线程（即调用该方法的线程）暂停执行一段时间，让其它线程有机会继续执行，但它不会释放对象锁。\n2、yield：__暂停__当前正在执行的线程对象，并执行其他线程。yield的目的是让相同优先级的线程之间能适当的__轮转执行__\n3、join：把指定的线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行的线程。比如线程B中调用了线程A的JOIN()方法，直到线程A执行完毕后，才会继续执行线程B。\n```\n    //主线程等待子线程thread执行结束才会输出结果\n    public static void main(String[] args) throws InterruptedException {\n        Thread thread = new Thread(new JoinTest());\n        thread.start();\n        thread.join(); //加入join()\n        System.out.println(\"主线程结束\");\n    }\n```\n4、setDaemon：\nJava中线程分为两种类型：用户线程和守护线程。通过Thread.setDaemon(false)设置为用户线程；通过Thread.setDaemon(true)设置为守护线程。如果不设置次属性，默认为用户线程。\n```java\n  public class DaemonTest extends Thread {\n    public void run() {            //永真循环线程\n        for (int i = 0; ; i++) {\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException ex) {\n            }\n            System.out.println(i);\n        }\n    }\n\n    public static void main(String[] args) {\n        Thread daemonTest = new DaemonTest();\n        daemonTest.setDaemon(true);    //调试时可以设置为false，那么这个程序是个死循环，没有退出条件。设置为true，即可主线程结束，test线程也结束。\n        daemonTest.start();\n        System.out.println(\"isDaemon = \" + daemonTest.isDaemon());\n        try {\n            System.in.read();   // 接受输入，使程序在此停顿，一旦接收到用户输入，main线程结束，守护线程自动结束\n        } catch (IOException ex) {\n        }\n    }\n}\n```\n如果线程设置为Thread.setDaemon(true)，则主线程结束该程序不会结束，必须等待子线程执行结束整个程序才能结束；如果线程设置为Thread.setDaemon(false)，则主线程结束整个程序就结束。\n\n5、wait、notify、notifyAll\n当一个线程进入wait之后，就必须等待其他线程notify/notifyAll，使用notifyAll可以唤醒所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。\nnotify被唤醒的线程是随机的，所以通常是没办法指定是谁被唤醒。\n\n### 线程关键字\n* volatile\n可见性：对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入\n原子性：对任意单个volatile变量的读/写具有原子性，但是类似于volatile++这种复合操作不具有原子性\n* synchronized\n当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。然而，当一个线程访问object的一个synchronized(this)同步代码块时，另一个线程仍然可以访问该object中的非synchronized(this)同步代码块。\nsynchronized 关键字，它包括两种用法：synchronized 方法和 synchronized 块。  \n\t* synchronized 方法：通过在方法声明中加入 synchronized关键字来声明 synchronized 方法\n```java\npublic synchronized void accessVal(int newVal);  \n```\n\t* synchronized 块：通过 synchronized关键字来声明synchronized 块\n```java\nsynchronized(syncObject) {  \n//允许访问控制的代码  \n}  \n```\n\n### ThreadLocal\nThreadLocal是一个关于创建线程局部变量的类。通常情况下，我们创建的变量是可以被任何一个线程访问修改的。而使用ThreadLocal创建的变量只能被当前线程访问，其他线程无法访问和修改。\n> 在Java中，栈内存归属于单个线程，每个线程都会有一个栈内存，其存储的变量只能在其所属线程中可见，即栈内存可以理解成线程的私有内存。而堆内存中的对象对所有线程可见。堆内存中的对象可以被所有线程访问。\n\nThreadLocal并不是存放在栈上。ThreadLocal实例实际上也是被其创建的类持有（更顶端应该是被线程持有）。而ThreadLocal的值其实也是被线程实例持有。它们都是位于堆上，只是通过一些技巧将可见性修改成线程可见。\n```java\n//使用ThreadLocal保存Connection变量 \nThreadLocal<Connection> connThreadLocal = new ThreadLocal<Connection>(); \n//保存到线程本地变量中\nconnThreadLocal.set(conn);  \n// 直接返回线程本地变量  \nconnThreadLocal.get();\n\n```","source":"_posts/Java-Thread概述.md","raw":"---\ntitle: Java Thread概述\ndate: 2017-03-08 19:33:39\ntags: [java,thread]\ncategories: [java]\n---\n### 线程生命周期\n\n![Threadlife_20170208.jpg](http://upload-images.jianshu.io/upload_images/1419542-7b0fe1fa20076f52.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/620)\n线程状态：\n* 新建状态：使用new关键字和Thread类或其子类建立一个线程对象后\n* 就绪状态：当线程对象调用了start()方法之后，该线程进入就绪状态\n* 运行状态：如果就绪状态的线程获取CPU资源，就可以执行run()\n* 阻塞状态：\n  * 等待阻塞：运行状态中的线程执行wait()方法\n  * 同步阻塞：线程在获取 synchronized 同步锁失败\n  * 其他阻塞：通过调用线程的sleep()或join()发出I/O请求时\n* 死亡状态：一个运行状态的线程完成人文或者其他终止条件发送\n\n### 创建线程\n1、继承Thread类\n```java\nclass ThreadDemo extends Thread\n```\n2、实现Runable接口\n```java\npublic class RunTest implements Runnable\n   \nThread thread1 = new Thread(new RunTest());\n```\n3、通过Callable、Future、FutureTask创建线程\n```\n// 继承实现Callable接口，声明返回类型\nclass CallTest implements Callable<Long> \n    \nFutureTask<Long> futureTask = new FutureTask<Long>(new CallTest(searchVo));\n```\n\n### 线程内置方法\n1、sleep：使当前线程（即调用该方法的线程）暂停执行一段时间，让其它线程有机会继续执行，但它不会释放对象锁。\n2、yield：__暂停__当前正在执行的线程对象，并执行其他线程。yield的目的是让相同优先级的线程之间能适当的__轮转执行__\n3、join：把指定的线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行的线程。比如线程B中调用了线程A的JOIN()方法，直到线程A执行完毕后，才会继续执行线程B。\n```\n    //主线程等待子线程thread执行结束才会输出结果\n    public static void main(String[] args) throws InterruptedException {\n        Thread thread = new Thread(new JoinTest());\n        thread.start();\n        thread.join(); //加入join()\n        System.out.println(\"主线程结束\");\n    }\n```\n4、setDaemon：\nJava中线程分为两种类型：用户线程和守护线程。通过Thread.setDaemon(false)设置为用户线程；通过Thread.setDaemon(true)设置为守护线程。如果不设置次属性，默认为用户线程。\n```java\n  public class DaemonTest extends Thread {\n    public void run() {            //永真循环线程\n        for (int i = 0; ; i++) {\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException ex) {\n            }\n            System.out.println(i);\n        }\n    }\n\n    public static void main(String[] args) {\n        Thread daemonTest = new DaemonTest();\n        daemonTest.setDaemon(true);    //调试时可以设置为false，那么这个程序是个死循环，没有退出条件。设置为true，即可主线程结束，test线程也结束。\n        daemonTest.start();\n        System.out.println(\"isDaemon = \" + daemonTest.isDaemon());\n        try {\n            System.in.read();   // 接受输入，使程序在此停顿，一旦接收到用户输入，main线程结束，守护线程自动结束\n        } catch (IOException ex) {\n        }\n    }\n}\n```\n如果线程设置为Thread.setDaemon(true)，则主线程结束该程序不会结束，必须等待子线程执行结束整个程序才能结束；如果线程设置为Thread.setDaemon(false)，则主线程结束整个程序就结束。\n\n5、wait、notify、notifyAll\n当一个线程进入wait之后，就必须等待其他线程notify/notifyAll，使用notifyAll可以唤醒所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。\nnotify被唤醒的线程是随机的，所以通常是没办法指定是谁被唤醒。\n\n### 线程关键字\n* volatile\n可见性：对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入\n原子性：对任意单个volatile变量的读/写具有原子性，但是类似于volatile++这种复合操作不具有原子性\n* synchronized\n当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。然而，当一个线程访问object的一个synchronized(this)同步代码块时，另一个线程仍然可以访问该object中的非synchronized(this)同步代码块。\nsynchronized 关键字，它包括两种用法：synchronized 方法和 synchronized 块。  \n\t* synchronized 方法：通过在方法声明中加入 synchronized关键字来声明 synchronized 方法\n```java\npublic synchronized void accessVal(int newVal);  \n```\n\t* synchronized 块：通过 synchronized关键字来声明synchronized 块\n```java\nsynchronized(syncObject) {  \n//允许访问控制的代码  \n}  \n```\n\n### ThreadLocal\nThreadLocal是一个关于创建线程局部变量的类。通常情况下，我们创建的变量是可以被任何一个线程访问修改的。而使用ThreadLocal创建的变量只能被当前线程访问，其他线程无法访问和修改。\n> 在Java中，栈内存归属于单个线程，每个线程都会有一个栈内存，其存储的变量只能在其所属线程中可见，即栈内存可以理解成线程的私有内存。而堆内存中的对象对所有线程可见。堆内存中的对象可以被所有线程访问。\n\nThreadLocal并不是存放在栈上。ThreadLocal实例实际上也是被其创建的类持有（更顶端应该是被线程持有）。而ThreadLocal的值其实也是被线程实例持有。它们都是位于堆上，只是通过一些技巧将可见性修改成线程可见。\n```java\n//使用ThreadLocal保存Connection变量 \nThreadLocal<Connection> connThreadLocal = new ThreadLocal<Connection>(); \n//保存到线程本地变量中\nconnThreadLocal.set(conn);  \n// 直接返回线程本地变量  \nconnThreadLocal.get();\n\n```","slug":"Java-Thread概述","published":1,"updated":"2018-09-03T12:29:46.715Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmo9un2t00069q0v917hd7kl","content":"<h3 id=\"线程生命周期\"><a href=\"#线程生命周期\" class=\"headerlink\" title=\"线程生命周期\"></a>线程生命周期</h3><p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-7b0fe1fa20076f52.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/620\" alt=\"Threadlife_20170208.jpg\"><br>线程状态：</p>\n<ul>\n<li>新建状态：使用new关键字和Thread类或其子类建立一个线程对象后</li>\n<li>就绪状态：当线程对象调用了start()方法之后，该线程进入就绪状态</li>\n<li>运行状态：如果就绪状态的线程获取CPU资源，就可以执行run()</li>\n<li>阻塞状态：<ul>\n<li>等待阻塞：运行状态中的线程执行wait()方法</li>\n<li>同步阻塞：线程在获取 synchronized 同步锁失败</li>\n<li>其他阻塞：通过调用线程的sleep()或join()发出I/O请求时</li>\n</ul>\n</li>\n<li>死亡状态：一个运行状态的线程完成人文或者其他终止条件发送</li>\n</ul>\n<h3 id=\"创建线程\"><a href=\"#创建线程\" class=\"headerlink\" title=\"创建线程\"></a>创建线程</h3><p>1、继承Thread类<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ThreadDemo</span> <span class=\"keyword\">extends</span> <span class=\"title\">Thread</span></span></span><br></pre></td></tr></table></figure></p>\n<p>2、实现Runable接口<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">RunTest</span> <span class=\"keyword\">implements</span> <span class=\"title\">Runnable</span></span></span><br><span class=\"line\"><span class=\"class\">   </span></span><br><span class=\"line\"><span class=\"class\"><span class=\"title\">Thread</span> <span class=\"title\">thread1</span> </span>= <span class=\"keyword\">new</span> Thread(<span class=\"keyword\">new</span> RunTest());</span><br></pre></td></tr></table></figure></p>\n<p>3、通过Callable、Future、FutureTask创建线程<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 继承实现Callable接口，声明返回类型</span><br><span class=\"line\">class CallTest implements Callable&lt;Long&gt; </span><br><span class=\"line\">    </span><br><span class=\"line\">FutureTask&lt;Long&gt; futureTask = new FutureTask&lt;Long&gt;(new CallTest(searchVo));</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"线程内置方法\"><a href=\"#线程内置方法\" class=\"headerlink\" title=\"线程内置方法\"></a>线程内置方法</h3><p>1、sleep：使当前线程（即调用该方法的线程）暂停执行一段时间，让其它线程有机会继续执行，但它不会释放对象锁。<br>2、yield：<strong>暂停</strong>当前正在执行的线程对象，并执行其他线程。yield的目的是让相同优先级的线程之间能适当的<strong>轮转执行</strong><br>3、join：把指定的线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行的线程。比如线程B中调用了线程A的JOIN()方法，直到线程A执行完毕后，才会继续执行线程B。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//主线程等待子线程thread执行结束才会输出结果</span><br><span class=\"line\">public static void main(String[] args) throws InterruptedException &#123;</span><br><span class=\"line\">    Thread thread = new Thread(new JoinTest());</span><br><span class=\"line\">    thread.start();</span><br><span class=\"line\">    thread.join(); //加入join()</span><br><span class=\"line\">    System.out.println(&quot;主线程结束&quot;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>4、setDaemon：<br>Java中线程分为两种类型：用户线程和守护线程。通过Thread.setDaemon(false)设置为用户线程；通过Thread.setDaemon(true)设置为守护线程。如果不设置次属性，默认为用户线程。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  <span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DaemonTest</span> <span class=\"keyword\">extends</span> <span class=\"title\">Thread</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;            <span class=\"comment\">//永真循环线程</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; ; i++) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                Thread.sleep(<span class=\"number\">1000</span>);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">catch</span> (InterruptedException ex) &#123;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            System.out.println(i);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        Thread daemonTest = <span class=\"keyword\">new</span> DaemonTest();</span><br><span class=\"line\">        daemonTest.setDaemon(<span class=\"keyword\">true</span>);    <span class=\"comment\">//调试时可以设置为false，那么这个程序是个死循环，没有退出条件。设置为true，即可主线程结束，test线程也结束。</span></span><br><span class=\"line\">        daemonTest.start();</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"isDaemon = \"</span> + daemonTest.isDaemon());</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            System.in.read();   <span class=\"comment\">// 接受输入，使程序在此停顿，一旦接收到用户输入，main线程结束，守护线程自动结束</span></span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (IOException ex) &#123;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>如果线程设置为Thread.setDaemon(true)，则主线程结束该程序不会结束，必须等待子线程执行结束整个程序才能结束；如果线程设置为Thread.setDaemon(false)，则主线程结束整个程序就结束。</p>\n<p>5、wait、notify、notifyAll<br>当一个线程进入wait之后，就必须等待其他线程notify/notifyAll，使用notifyAll可以唤醒所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。<br>notify被唤醒的线程是随机的，所以通常是没办法指定是谁被唤醒。</p>\n<h3 id=\"线程关键字\"><a href=\"#线程关键字\" class=\"headerlink\" title=\"线程关键字\"></a>线程关键字</h3><ul>\n<li>volatile<br>可见性：对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入<br>原子性：对任意单个volatile变量的读/写具有原子性，但是类似于volatile++这种复合操作不具有原子性</li>\n<li><p>synchronized<br>当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。然而，当一个线程访问object的一个synchronized(this)同步代码块时，另一个线程仍然可以访问该object中的非synchronized(this)同步代码块。<br>synchronized 关键字，它包括两种用法：synchronized 方法和 synchronized 块。  </p>\n<ul>\n<li><p>synchronized 方法：通过在方法声明中加入 synchronized关键字来声明 synchronized 方法</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">synchronized</span> <span class=\"keyword\">void</span> <span class=\"title\">accessVal</span><span class=\"params\">(<span class=\"keyword\">int</span> newVal)</span></span>;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>synchronized 块：通过 synchronized关键字来声明synchronized 块</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">synchronized</span>(syncObject) &#123;  </span><br><span class=\"line\"><span class=\"comment\">//允许访问控制的代码  </span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"ThreadLocal\"><a href=\"#ThreadLocal\" class=\"headerlink\" title=\"ThreadLocal\"></a>ThreadLocal</h3><p>ThreadLocal是一个关于创建线程局部变量的类。通常情况下，我们创建的变量是可以被任何一个线程访问修改的。而使用ThreadLocal创建的变量只能被当前线程访问，其他线程无法访问和修改。</p>\n<blockquote>\n<p>在Java中，栈内存归属于单个线程，每个线程都会有一个栈内存，其存储的变量只能在其所属线程中可见，即栈内存可以理解成线程的私有内存。而堆内存中的对象对所有线程可见。堆内存中的对象可以被所有线程访问。</p>\n</blockquote>\n<p>ThreadLocal并不是存放在栈上。ThreadLocal实例实际上也是被其创建的类持有（更顶端应该是被线程持有）。而ThreadLocal的值其实也是被线程实例持有。它们都是位于堆上，只是通过一些技巧将可见性修改成线程可见。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//使用ThreadLocal保存Connection变量 </span></span><br><span class=\"line\">ThreadLocal&lt;Connection&gt; connThreadLocal = <span class=\"keyword\">new</span> ThreadLocal&lt;Connection&gt;(); </span><br><span class=\"line\"><span class=\"comment\">//保存到线程本地变量中</span></span><br><span class=\"line\">connThreadLocal.set(conn);  </span><br><span class=\"line\"><span class=\"comment\">// 直接返回线程本地变量  </span></span><br><span class=\"line\">connThreadLocal.get();</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"线程生命周期\"><a href=\"#线程生命周期\" class=\"headerlink\" title=\"线程生命周期\"></a>线程生命周期</h3><p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-7b0fe1fa20076f52.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/620\" alt=\"Threadlife_20170208.jpg\"><br>线程状态：</p>\n<ul>\n<li>新建状态：使用new关键字和Thread类或其子类建立一个线程对象后</li>\n<li>就绪状态：当线程对象调用了start()方法之后，该线程进入就绪状态</li>\n<li>运行状态：如果就绪状态的线程获取CPU资源，就可以执行run()</li>\n<li>阻塞状态：<ul>\n<li>等待阻塞：运行状态中的线程执行wait()方法</li>\n<li>同步阻塞：线程在获取 synchronized 同步锁失败</li>\n<li>其他阻塞：通过调用线程的sleep()或join()发出I/O请求时</li>\n</ul>\n</li>\n<li>死亡状态：一个运行状态的线程完成人文或者其他终止条件发送</li>\n</ul>\n<h3 id=\"创建线程\"><a href=\"#创建线程\" class=\"headerlink\" title=\"创建线程\"></a>创建线程</h3><p>1、继承Thread类<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ThreadDemo</span> <span class=\"keyword\">extends</span> <span class=\"title\">Thread</span></span></span><br></pre></td></tr></table></figure></p>\n<p>2、实现Runable接口<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">RunTest</span> <span class=\"keyword\">implements</span> <span class=\"title\">Runnable</span></span></span><br><span class=\"line\"><span class=\"class\">   </span></span><br><span class=\"line\"><span class=\"class\"><span class=\"title\">Thread</span> <span class=\"title\">thread1</span> </span>= <span class=\"keyword\">new</span> Thread(<span class=\"keyword\">new</span> RunTest());</span><br></pre></td></tr></table></figure></p>\n<p>3、通过Callable、Future、FutureTask创建线程<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 继承实现Callable接口，声明返回类型</span><br><span class=\"line\">class CallTest implements Callable&lt;Long&gt; </span><br><span class=\"line\">    </span><br><span class=\"line\">FutureTask&lt;Long&gt; futureTask = new FutureTask&lt;Long&gt;(new CallTest(searchVo));</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"线程内置方法\"><a href=\"#线程内置方法\" class=\"headerlink\" title=\"线程内置方法\"></a>线程内置方法</h3><p>1、sleep：使当前线程（即调用该方法的线程）暂停执行一段时间，让其它线程有机会继续执行，但它不会释放对象锁。<br>2、yield：<strong>暂停</strong>当前正在执行的线程对象，并执行其他线程。yield的目的是让相同优先级的线程之间能适当的<strong>轮转执行</strong><br>3、join：把指定的线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行的线程。比如线程B中调用了线程A的JOIN()方法，直到线程A执行完毕后，才会继续执行线程B。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//主线程等待子线程thread执行结束才会输出结果</span><br><span class=\"line\">public static void main(String[] args) throws InterruptedException &#123;</span><br><span class=\"line\">    Thread thread = new Thread(new JoinTest());</span><br><span class=\"line\">    thread.start();</span><br><span class=\"line\">    thread.join(); //加入join()</span><br><span class=\"line\">    System.out.println(&quot;主线程结束&quot;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>4、setDaemon：<br>Java中线程分为两种类型：用户线程和守护线程。通过Thread.setDaemon(false)设置为用户线程；通过Thread.setDaemon(true)设置为守护线程。如果不设置次属性，默认为用户线程。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  <span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DaemonTest</span> <span class=\"keyword\">extends</span> <span class=\"title\">Thread</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;            <span class=\"comment\">//永真循环线程</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; ; i++) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                Thread.sleep(<span class=\"number\">1000</span>);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">catch</span> (InterruptedException ex) &#123;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            System.out.println(i);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        Thread daemonTest = <span class=\"keyword\">new</span> DaemonTest();</span><br><span class=\"line\">        daemonTest.setDaemon(<span class=\"keyword\">true</span>);    <span class=\"comment\">//调试时可以设置为false，那么这个程序是个死循环，没有退出条件。设置为true，即可主线程结束，test线程也结束。</span></span><br><span class=\"line\">        daemonTest.start();</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"isDaemon = \"</span> + daemonTest.isDaemon());</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            System.in.read();   <span class=\"comment\">// 接受输入，使程序在此停顿，一旦接收到用户输入，main线程结束，守护线程自动结束</span></span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (IOException ex) &#123;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>如果线程设置为Thread.setDaemon(true)，则主线程结束该程序不会结束，必须等待子线程执行结束整个程序才能结束；如果线程设置为Thread.setDaemon(false)，则主线程结束整个程序就结束。</p>\n<p>5、wait、notify、notifyAll<br>当一个线程进入wait之后，就必须等待其他线程notify/notifyAll，使用notifyAll可以唤醒所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。<br>notify被唤醒的线程是随机的，所以通常是没办法指定是谁被唤醒。</p>\n<h3 id=\"线程关键字\"><a href=\"#线程关键字\" class=\"headerlink\" title=\"线程关键字\"></a>线程关键字</h3><ul>\n<li>volatile<br>可见性：对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入<br>原子性：对任意单个volatile变量的读/写具有原子性，但是类似于volatile++这种复合操作不具有原子性</li>\n<li><p>synchronized<br>当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。然而，当一个线程访问object的一个synchronized(this)同步代码块时，另一个线程仍然可以访问该object中的非synchronized(this)同步代码块。<br>synchronized 关键字，它包括两种用法：synchronized 方法和 synchronized 块。  </p>\n<ul>\n<li><p>synchronized 方法：通过在方法声明中加入 synchronized关键字来声明 synchronized 方法</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">synchronized</span> <span class=\"keyword\">void</span> <span class=\"title\">accessVal</span><span class=\"params\">(<span class=\"keyword\">int</span> newVal)</span></span>;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>synchronized 块：通过 synchronized关键字来声明synchronized 块</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">synchronized</span>(syncObject) &#123;  </span><br><span class=\"line\"><span class=\"comment\">//允许访问控制的代码  </span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"ThreadLocal\"><a href=\"#ThreadLocal\" class=\"headerlink\" title=\"ThreadLocal\"></a>ThreadLocal</h3><p>ThreadLocal是一个关于创建线程局部变量的类。通常情况下，我们创建的变量是可以被任何一个线程访问修改的。而使用ThreadLocal创建的变量只能被当前线程访问，其他线程无法访问和修改。</p>\n<blockquote>\n<p>在Java中，栈内存归属于单个线程，每个线程都会有一个栈内存，其存储的变量只能在其所属线程中可见，即栈内存可以理解成线程的私有内存。而堆内存中的对象对所有线程可见。堆内存中的对象可以被所有线程访问。</p>\n</blockquote>\n<p>ThreadLocal并不是存放在栈上。ThreadLocal实例实际上也是被其创建的类持有（更顶端应该是被线程持有）。而ThreadLocal的值其实也是被线程实例持有。它们都是位于堆上，只是通过一些技巧将可见性修改成线程可见。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//使用ThreadLocal保存Connection变量 </span></span><br><span class=\"line\">ThreadLocal&lt;Connection&gt; connThreadLocal = <span class=\"keyword\">new</span> ThreadLocal&lt;Connection&gt;(); </span><br><span class=\"line\"><span class=\"comment\">//保存到线程本地变量中</span></span><br><span class=\"line\">connThreadLocal.set(conn);  </span><br><span class=\"line\"><span class=\"comment\">// 直接返回线程本地变量  </span></span><br><span class=\"line\">connThreadLocal.get();</span><br></pre></td></tr></table></figure></p>\n"},{"title":"Kafka 概述","date":"2017-02-13T12:11:17.000Z","_content":"### Kafka架构\n* Broker：Kafka集群包含一个或多个服务器，这种服务器被称为broker\n* Topic：每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）\n\n* Partition：Partition（分片）是物理上的概念，每个Topic包含一个或多个Partition，创建topic时可指定parition数量。每个partition对应于一个文件夹，该文件夹下存储该partition的数据和索引文件。\n* Producer：负责发布消息到Kafka broker\n* Consumer：消息消费者，向kafka broker读取消息的客户端。每个consumer属于一个特定的consuer group（可为每个consumer指定group name，若不指定group name则属于默认的group）。使用consumer high level API时，同一topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。\n* Consumer Group：每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。\n\nKafka拓扑结构：\n\n![kafka-tupe-20170213.png](http://upload-images.jianshu.io/upload_images/1419542-2deb6eeb9853f960.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n### Kafka的Topic & Partition\nTopic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。\n消息发送时都被发送到一个topic，其本质就是一个目录，而__topic是由一些Partition Logs(分区日志)组成__，其组织结构如下图所示：\n![kafka_log_anatomy_20170213.png](http://upload-images.jianshu.io/upload_images/1419542-0da76ff4a59ef941.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n因为每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。\n\n### Kafka 分区机制\nKafka中可以将Topic从物理上划分成一个或多个分区（Partition），每个分区在物理上对应一个文件夹，以“topicName_partitionIndex”的命名方式命名，该文件夹下存储这个分区的所有**消息（.log）**和**索引文件（.index）**，这使得Kafka的吞吐率可以水平扩展。\n生产者在生产数据的时候，可以**为每条消息指定Key**，这样消息被发送到broker时，会根据分区规则选择被存储到哪一个分区中，如果分区规则设置的合理，那么所有的消息会将被均分的分布到不同的分区中，这样就实现了负载均衡和水平扩展。另外，在消费端，同一个消费组可以多线程并发的从多个分区中同时消费数据。\n默认kakfa.producer.Partitioner接口的类\n```\nclass DefaultPartitioner(props: VerifiableProperties = null) extends Partitioner {\n  def partition(key: Any, numPartitions: Int): Int = {\n    Utils.abs(key.hashCode) % numPartitions\n  }\n}\n```\n\n### Consumer Group\nKafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。\n* 单播：所有Consumer在同一个Croup里\n* 广播：每个Consumer有一个独立的Group\n\n使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。\n\n### Producer\nProducer发送消息到broker时，会根据Paritition机制选择将其存储到哪一个Partition。\nproducer 写入消息序列图:\n\n![kafka-producer-20170213.png.png](http://upload-images.jianshu.io/upload_images/1419542-1e171553afe93789.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n流程说明:\n```\n1. producer 先从 zookeeper 的 \"/brokers/.../state\" 节点找到该 partition 的 leader\n2. producer 将消息发送给该 leader\n3. leader 将消息写入本地 log\n4. followers 从 leader pull 消息，写入本地 log 后 leader 发送 ACK\n5. leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK\n```\n\n### Kafka Shell\n启动：\n```\n ./kafka-server-start.sh ../config/server.properties > /dev/null &\n```\n查看topic：\n```\n./kafka-topics.sh --zookeeper 10.211.55.5:2181 --list\n```\n创建topic：\n```\n./kafka-topics.sh --create --zookeeper 10.211.55.5:2181 --replication-factor 2 --partitions 1 --topic testYanY\n#  replication-factor 副本参数\n#  partitions 分区参数\n\n```\n删除topic:\n```\n./kafka-topic.sh --zookeeper 10.211.55.5:2181 --topic  testYanY --delete\n```\n消费者：\n```\n./kafka-console-consumer.sh --zookeeper 10.211.55.5:2181 --topic testYanY --from-beginning\n```\n生产者：\n```\n./kafka-console-producer.sh --broker-list 10.211.55.5:9092 --topic testYanY\n```\n    \n\n参考：\nhttp://www.infoq.com/cn/articles/kafka-analysis-part-1/\nhttp://www.cnblogs.com/cyfonly/p/5954614.html\n\n","source":"_posts/Kafka-概述.md","raw":"---\ntitle: Kafka 概述\ndate: 2017-02-13 20:11:17\ntags: [kafka]\ncategories: [kafka]\n---\n### Kafka架构\n* Broker：Kafka集群包含一个或多个服务器，这种服务器被称为broker\n* Topic：每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）\n\n* Partition：Partition（分片）是物理上的概念，每个Topic包含一个或多个Partition，创建topic时可指定parition数量。每个partition对应于一个文件夹，该文件夹下存储该partition的数据和索引文件。\n* Producer：负责发布消息到Kafka broker\n* Consumer：消息消费者，向kafka broker读取消息的客户端。每个consumer属于一个特定的consuer group（可为每个consumer指定group name，若不指定group name则属于默认的group）。使用consumer high level API时，同一topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。\n* Consumer Group：每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。\n\nKafka拓扑结构：\n\n![kafka-tupe-20170213.png](http://upload-images.jianshu.io/upload_images/1419542-2deb6eeb9853f960.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n### Kafka的Topic & Partition\nTopic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。\n消息发送时都被发送到一个topic，其本质就是一个目录，而__topic是由一些Partition Logs(分区日志)组成__，其组织结构如下图所示：\n![kafka_log_anatomy_20170213.png](http://upload-images.jianshu.io/upload_images/1419542-0da76ff4a59ef941.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n因为每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。\n\n### Kafka 分区机制\nKafka中可以将Topic从物理上划分成一个或多个分区（Partition），每个分区在物理上对应一个文件夹，以“topicName_partitionIndex”的命名方式命名，该文件夹下存储这个分区的所有**消息（.log）**和**索引文件（.index）**，这使得Kafka的吞吐率可以水平扩展。\n生产者在生产数据的时候，可以**为每条消息指定Key**，这样消息被发送到broker时，会根据分区规则选择被存储到哪一个分区中，如果分区规则设置的合理，那么所有的消息会将被均分的分布到不同的分区中，这样就实现了负载均衡和水平扩展。另外，在消费端，同一个消费组可以多线程并发的从多个分区中同时消费数据。\n默认kakfa.producer.Partitioner接口的类\n```\nclass DefaultPartitioner(props: VerifiableProperties = null) extends Partitioner {\n  def partition(key: Any, numPartitions: Int): Int = {\n    Utils.abs(key.hashCode) % numPartitions\n  }\n}\n```\n\n### Consumer Group\nKafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。\n* 单播：所有Consumer在同一个Croup里\n* 广播：每个Consumer有一个独立的Group\n\n使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。\n\n### Producer\nProducer发送消息到broker时，会根据Paritition机制选择将其存储到哪一个Partition。\nproducer 写入消息序列图:\n\n![kafka-producer-20170213.png.png](http://upload-images.jianshu.io/upload_images/1419542-1e171553afe93789.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n流程说明:\n```\n1. producer 先从 zookeeper 的 \"/brokers/.../state\" 节点找到该 partition 的 leader\n2. producer 将消息发送给该 leader\n3. leader 将消息写入本地 log\n4. followers 从 leader pull 消息，写入本地 log 后 leader 发送 ACK\n5. leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK\n```\n\n### Kafka Shell\n启动：\n```\n ./kafka-server-start.sh ../config/server.properties > /dev/null &\n```\n查看topic：\n```\n./kafka-topics.sh --zookeeper 10.211.55.5:2181 --list\n```\n创建topic：\n```\n./kafka-topics.sh --create --zookeeper 10.211.55.5:2181 --replication-factor 2 --partitions 1 --topic testYanY\n#  replication-factor 副本参数\n#  partitions 分区参数\n\n```\n删除topic:\n```\n./kafka-topic.sh --zookeeper 10.211.55.5:2181 --topic  testYanY --delete\n```\n消费者：\n```\n./kafka-console-consumer.sh --zookeeper 10.211.55.5:2181 --topic testYanY --from-beginning\n```\n生产者：\n```\n./kafka-console-producer.sh --broker-list 10.211.55.5:9092 --topic testYanY\n```\n    \n\n参考：\nhttp://www.infoq.com/cn/articles/kafka-analysis-part-1/\nhttp://www.cnblogs.com/cyfonly/p/5954614.html\n\n","slug":"Kafka-概述","published":1,"updated":"2018-09-03T12:29:46.716Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmo9un2u00079q0vs0bqhb31","content":"<h3 id=\"Kafka架构\"><a href=\"#Kafka架构\" class=\"headerlink\" title=\"Kafka架构\"></a>Kafka架构</h3><ul>\n<li>Broker：Kafka集群包含一个或多个服务器，这种服务器被称为broker</li>\n<li><p>Topic：每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</p>\n</li>\n<li><p>Partition：Partition（分片）是物理上的概念，每个Topic包含一个或多个Partition，创建topic时可指定parition数量。每个partition对应于一个文件夹，该文件夹下存储该partition的数据和索引文件。</p>\n</li>\n<li>Producer：负责发布消息到Kafka broker</li>\n<li>Consumer：消息消费者，向kafka broker读取消息的客户端。每个consumer属于一个特定的consuer group（可为每个consumer指定group name，若不指定group name则属于默认的group）。使用consumer high level API时，同一topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。</li>\n<li>Consumer Group：每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</li>\n</ul>\n<p>Kafka拓扑结构：</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-2deb6eeb9853f960.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kafka-tupe-20170213.png\"></p>\n<h3 id=\"Kafka的Topic-amp-Partition\"><a href=\"#Kafka的Topic-amp-Partition\" class=\"headerlink\" title=\"Kafka的Topic &amp; Partition\"></a>Kafka的Topic &amp; Partition</h3><p>Topic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。<br>消息发送时都被发送到一个topic，其本质就是一个目录，而<strong>topic是由一些Partition Logs(分区日志)组成</strong>，其组织结构如下图所示：<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-0da76ff4a59ef941.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kafka_log_anatomy_20170213.png\"><br>因为每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。</p>\n<h3 id=\"Kafka-分区机制\"><a href=\"#Kafka-分区机制\" class=\"headerlink\" title=\"Kafka 分区机制\"></a>Kafka 分区机制</h3><p>Kafka中可以将Topic从物理上划分成一个或多个分区（Partition），每个分区在物理上对应一个文件夹，以“topicName_partitionIndex”的命名方式命名，该文件夹下存储这个分区的所有<strong>消息（.log）</strong>和<strong>索引文件（.index）</strong>，这使得Kafka的吞吐率可以水平扩展。<br>生产者在生产数据的时候，可以<strong>为每条消息指定Key</strong>，这样消息被发送到broker时，会根据分区规则选择被存储到哪一个分区中，如果分区规则设置的合理，那么所有的消息会将被均分的分布到不同的分区中，这样就实现了负载均衡和水平扩展。另外，在消费端，同一个消费组可以多线程并发的从多个分区中同时消费数据。<br>默认kakfa.producer.Partitioner接口的类<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class DefaultPartitioner(props: VerifiableProperties = null) extends Partitioner &#123;</span><br><span class=\"line\">  def partition(key: Any, numPartitions: Int): Int = &#123;</span><br><span class=\"line\">    Utils.abs(key.hashCode) % numPartitions</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Consumer-Group\"><a href=\"#Consumer-Group\" class=\"headerlink\" title=\"Consumer Group\"></a>Consumer Group</h3><p>Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。</p>\n<ul>\n<li>单播：所有Consumer在同一个Croup里</li>\n<li>广播：每个Consumer有一个独立的Group</li>\n</ul>\n<p>使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。</p>\n<h3 id=\"Producer\"><a href=\"#Producer\" class=\"headerlink\" title=\"Producer\"></a>Producer</h3><p>Producer发送消息到broker时，会根据Paritition机制选择将其存储到哪一个Partition。<br>producer 写入消息序列图:</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-1e171553afe93789.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kafka-producer-20170213.png.png\"></p>\n<p>流程说明:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. producer 先从 zookeeper 的 &quot;/brokers/.../state&quot; 节点找到该 partition 的 leader</span><br><span class=\"line\">2. producer 将消息发送给该 leader</span><br><span class=\"line\">3. leader 将消息写入本地 log</span><br><span class=\"line\">4. followers 从 leader pull 消息，写入本地 log 后 leader 发送 ACK</span><br><span class=\"line\">5. leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Kafka-Shell\"><a href=\"#Kafka-Shell\" class=\"headerlink\" title=\"Kafka Shell\"></a>Kafka Shell</h3><p>启动：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./kafka-server-start.sh ../config/server.properties &gt; /dev/null &amp;</span><br></pre></td></tr></table></figure></p>\n<p>查看topic：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./kafka-topics.sh --zookeeper 10.211.55.5:2181 --list</span><br></pre></td></tr></table></figure></p>\n<p>创建topic：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./kafka-topics.sh --create --zookeeper 10.211.55.5:2181 --replication-factor 2 --partitions 1 --topic testYanY</span><br><span class=\"line\">#  replication-factor 副本参数</span><br><span class=\"line\">#  partitions 分区参数</span><br></pre></td></tr></table></figure></p>\n<p>删除topic:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./kafka-topic.sh --zookeeper 10.211.55.5:2181 --topic  testYanY --delete</span><br></pre></td></tr></table></figure></p>\n<p>消费者：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./kafka-console-consumer.sh --zookeeper 10.211.55.5:2181 --topic testYanY --from-beginning</span><br></pre></td></tr></table></figure></p>\n<p>生产者：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./kafka-console-producer.sh --broker-list 10.211.55.5:9092 --topic testYanY</span><br></pre></td></tr></table></figure></p>\n<p>参考：<br><a href=\"http://www.infoq.com/cn/articles/kafka-analysis-part-1/\" target=\"_blank\" rel=\"noopener\">http://www.infoq.com/cn/articles/kafka-analysis-part-1/</a><br><a href=\"http://www.cnblogs.com/cyfonly/p/5954614.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/cyfonly/p/5954614.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Kafka架构\"><a href=\"#Kafka架构\" class=\"headerlink\" title=\"Kafka架构\"></a>Kafka架构</h3><ul>\n<li>Broker：Kafka集群包含一个或多个服务器，这种服务器被称为broker</li>\n<li><p>Topic：每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</p>\n</li>\n<li><p>Partition：Partition（分片）是物理上的概念，每个Topic包含一个或多个Partition，创建topic时可指定parition数量。每个partition对应于一个文件夹，该文件夹下存储该partition的数据和索引文件。</p>\n</li>\n<li>Producer：负责发布消息到Kafka broker</li>\n<li>Consumer：消息消费者，向kafka broker读取消息的客户端。每个consumer属于一个特定的consuer group（可为每个consumer指定group name，若不指定group name则属于默认的group）。使用consumer high level API时，同一topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。</li>\n<li>Consumer Group：每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</li>\n</ul>\n<p>Kafka拓扑结构：</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-2deb6eeb9853f960.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kafka-tupe-20170213.png\"></p>\n<h3 id=\"Kafka的Topic-amp-Partition\"><a href=\"#Kafka的Topic-amp-Partition\" class=\"headerlink\" title=\"Kafka的Topic &amp; Partition\"></a>Kafka的Topic &amp; Partition</h3><p>Topic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。<br>消息发送时都被发送到一个topic，其本质就是一个目录，而<strong>topic是由一些Partition Logs(分区日志)组成</strong>，其组织结构如下图所示：<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-0da76ff4a59ef941.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kafka_log_anatomy_20170213.png\"><br>因为每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。</p>\n<h3 id=\"Kafka-分区机制\"><a href=\"#Kafka-分区机制\" class=\"headerlink\" title=\"Kafka 分区机制\"></a>Kafka 分区机制</h3><p>Kafka中可以将Topic从物理上划分成一个或多个分区（Partition），每个分区在物理上对应一个文件夹，以“topicName_partitionIndex”的命名方式命名，该文件夹下存储这个分区的所有<strong>消息（.log）</strong>和<strong>索引文件（.index）</strong>，这使得Kafka的吞吐率可以水平扩展。<br>生产者在生产数据的时候，可以<strong>为每条消息指定Key</strong>，这样消息被发送到broker时，会根据分区规则选择被存储到哪一个分区中，如果分区规则设置的合理，那么所有的消息会将被均分的分布到不同的分区中，这样就实现了负载均衡和水平扩展。另外，在消费端，同一个消费组可以多线程并发的从多个分区中同时消费数据。<br>默认kakfa.producer.Partitioner接口的类<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class DefaultPartitioner(props: VerifiableProperties = null) extends Partitioner &#123;</span><br><span class=\"line\">  def partition(key: Any, numPartitions: Int): Int = &#123;</span><br><span class=\"line\">    Utils.abs(key.hashCode) % numPartitions</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Consumer-Group\"><a href=\"#Consumer-Group\" class=\"headerlink\" title=\"Consumer Group\"></a>Consumer Group</h3><p>Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。</p>\n<ul>\n<li>单播：所有Consumer在同一个Croup里</li>\n<li>广播：每个Consumer有一个独立的Group</li>\n</ul>\n<p>使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。</p>\n<h3 id=\"Producer\"><a href=\"#Producer\" class=\"headerlink\" title=\"Producer\"></a>Producer</h3><p>Producer发送消息到broker时，会根据Paritition机制选择将其存储到哪一个Partition。<br>producer 写入消息序列图:</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-1e171553afe93789.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kafka-producer-20170213.png.png\"></p>\n<p>流程说明:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. producer 先从 zookeeper 的 &quot;/brokers/.../state&quot; 节点找到该 partition 的 leader</span><br><span class=\"line\">2. producer 将消息发送给该 leader</span><br><span class=\"line\">3. leader 将消息写入本地 log</span><br><span class=\"line\">4. followers 从 leader pull 消息，写入本地 log 后 leader 发送 ACK</span><br><span class=\"line\">5. leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Kafka-Shell\"><a href=\"#Kafka-Shell\" class=\"headerlink\" title=\"Kafka Shell\"></a>Kafka Shell</h3><p>启动：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./kafka-server-start.sh ../config/server.properties &gt; /dev/null &amp;</span><br></pre></td></tr></table></figure></p>\n<p>查看topic：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./kafka-topics.sh --zookeeper 10.211.55.5:2181 --list</span><br></pre></td></tr></table></figure></p>\n<p>创建topic：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./kafka-topics.sh --create --zookeeper 10.211.55.5:2181 --replication-factor 2 --partitions 1 --topic testYanY</span><br><span class=\"line\">#  replication-factor 副本参数</span><br><span class=\"line\">#  partitions 分区参数</span><br></pre></td></tr></table></figure></p>\n<p>删除topic:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./kafka-topic.sh --zookeeper 10.211.55.5:2181 --topic  testYanY --delete</span><br></pre></td></tr></table></figure></p>\n<p>消费者：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./kafka-console-consumer.sh --zookeeper 10.211.55.5:2181 --topic testYanY --from-beginning</span><br></pre></td></tr></table></figure></p>\n<p>生产者：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./kafka-console-producer.sh --broker-list 10.211.55.5:9092 --topic testYanY</span><br></pre></td></tr></table></figure></p>\n<p>参考：<br><a href=\"http://www.infoq.com/cn/articles/kafka-analysis-part-1/\" target=\"_blank\" rel=\"noopener\">http://www.infoq.com/cn/articles/kafka-analysis-part-1/</a><br><a href=\"http://www.cnblogs.com/cyfonly/p/5954614.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/cyfonly/p/5954614.html</a></p>\n"},{"title":"RPC原理 概述","date":"2017-03-02T01:40:18.000Z","_content":"远程过程调用（Remote Procedure Call，缩写为RPC）是一种计算机通信协议。该协议运行运行与一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方法调用。——维基百科\n\n### RPC调用分类\n同步调用：客户方等待调用执行完成并返回结果\n异步调用：客户方调用后不用等待执行结果返回，但依然可以通过回调通知等方式获取返回结果。 若客户方不关心调用返回结果，则变成单向异步调用，单向调用不用返回结果\n\n### RPC结构\n\n![rpc-20170302.jpg](http://upload-images.jianshu.io/upload_images/1419542-29bfe0b7d38005c1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/960)\nRPC 服务方通过 RpcServer 去导出（export）远程接口方法，而客户方通过 RpcClient 去引入（import）远程接口方法。 客户方像调用本地方法一样去调用远程接口方法，RPC 框架提供接口的代理实现，实际的调用将委托给代理 RpcProxy 。 代理封装调用信息并将调用转交给 RpcInvoker 去实际执行。 在客户端的 RpcInvoker 通过连接器 RpcConnector 去维持与服务端的通道 RpcChannel， 并使用 RpcProtocol 执行协议编码（encode）并将编码后的请求消息通过通道发送给服务方。\nRPC 服务端接收器 RpcAcceptor 接收客户端的调用请求，同样使用 RpcProtocol 执行协议解码（decode）。 解码后的调用信息传递给 RpcProcessor 去控制处理调用过程，最后再委托调用给 RpcInvoker 去实际执行并返回调用结果。\n\n### RPC组件职责\n1. RpcServer：负责导出（export）远程接口\n2. RpcClient：负责导入（import）远程接口的代理实现\n3. RpcProxy：远程接口的代理实现\n4. RpcInvoker：\n    1. 客户端实现方式：负责编码调用信息和发送调用请求到服务方并等待调用结果返回\n    2. 服务端实现方式：负责调用服务端接口的具体实现并返回调用结果\n5. RpcProtocol：负责协议编/解码\n6. RpcConnector：负责维持客户方和服务方的连接通道和发送数据到服务方\n7. RpcAcceptor：负责接收客户方请求并返回请求结果\n8. RpcProcessor：负责在服务方控制调用过程，包括管理调用线程池、超时时间等\n9. RpcChannel：数据传输通道\n\n参考：\nhttp://www.cnblogs.com/metoy/p/4321311.html?utm_source=tuicool&utm_medium=referral\nhttp://www.cnblogs.com/LBSer/p/4853234.html","source":"_posts/RPC原理-概述.md","raw":"---\ntitle: RPC原理 概述\ndate: 2017-03-02 09:40:18\ntags: [rpc]\n---\n远程过程调用（Remote Procedure Call，缩写为RPC）是一种计算机通信协议。该协议运行运行与一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方法调用。——维基百科\n\n### RPC调用分类\n同步调用：客户方等待调用执行完成并返回结果\n异步调用：客户方调用后不用等待执行结果返回，但依然可以通过回调通知等方式获取返回结果。 若客户方不关心调用返回结果，则变成单向异步调用，单向调用不用返回结果\n\n### RPC结构\n\n![rpc-20170302.jpg](http://upload-images.jianshu.io/upload_images/1419542-29bfe0b7d38005c1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/960)\nRPC 服务方通过 RpcServer 去导出（export）远程接口方法，而客户方通过 RpcClient 去引入（import）远程接口方法。 客户方像调用本地方法一样去调用远程接口方法，RPC 框架提供接口的代理实现，实际的调用将委托给代理 RpcProxy 。 代理封装调用信息并将调用转交给 RpcInvoker 去实际执行。 在客户端的 RpcInvoker 通过连接器 RpcConnector 去维持与服务端的通道 RpcChannel， 并使用 RpcProtocol 执行协议编码（encode）并将编码后的请求消息通过通道发送给服务方。\nRPC 服务端接收器 RpcAcceptor 接收客户端的调用请求，同样使用 RpcProtocol 执行协议解码（decode）。 解码后的调用信息传递给 RpcProcessor 去控制处理调用过程，最后再委托调用给 RpcInvoker 去实际执行并返回调用结果。\n\n### RPC组件职责\n1. RpcServer：负责导出（export）远程接口\n2. RpcClient：负责导入（import）远程接口的代理实现\n3. RpcProxy：远程接口的代理实现\n4. RpcInvoker：\n    1. 客户端实现方式：负责编码调用信息和发送调用请求到服务方并等待调用结果返回\n    2. 服务端实现方式：负责调用服务端接口的具体实现并返回调用结果\n5. RpcProtocol：负责协议编/解码\n6. RpcConnector：负责维持客户方和服务方的连接通道和发送数据到服务方\n7. RpcAcceptor：负责接收客户方请求并返回请求结果\n8. RpcProcessor：负责在服务方控制调用过程，包括管理调用线程池、超时时间等\n9. RpcChannel：数据传输通道\n\n参考：\nhttp://www.cnblogs.com/metoy/p/4321311.html?utm_source=tuicool&utm_medium=referral\nhttp://www.cnblogs.com/LBSer/p/4853234.html","slug":"RPC原理-概述","published":1,"updated":"2018-09-03T12:29:46.716Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmo9un2w00089q0v24hkiy7p","content":"<p>远程过程调用（Remote Procedure Call，缩写为RPC）是一种计算机通信协议。该协议运行运行与一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方法调用。——维基百科</p>\n<h3 id=\"RPC调用分类\"><a href=\"#RPC调用分类\" class=\"headerlink\" title=\"RPC调用分类\"></a>RPC调用分类</h3><p>同步调用：客户方等待调用执行完成并返回结果<br>异步调用：客户方调用后不用等待执行结果返回，但依然可以通过回调通知等方式获取返回结果。 若客户方不关心调用返回结果，则变成单向异步调用，单向调用不用返回结果</p>\n<h3 id=\"RPC结构\"><a href=\"#RPC结构\" class=\"headerlink\" title=\"RPC结构\"></a>RPC结构</h3><p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-29bfe0b7d38005c1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/960\" alt=\"rpc-20170302.jpg\"><br>RPC 服务方通过 RpcServer 去导出（export）远程接口方法，而客户方通过 RpcClient 去引入（import）远程接口方法。 客户方像调用本地方法一样去调用远程接口方法，RPC 框架提供接口的代理实现，实际的调用将委托给代理 RpcProxy 。 代理封装调用信息并将调用转交给 RpcInvoker 去实际执行。 在客户端的 RpcInvoker 通过连接器 RpcConnector 去维持与服务端的通道 RpcChannel， 并使用 RpcProtocol 执行协议编码（encode）并将编码后的请求消息通过通道发送给服务方。<br>RPC 服务端接收器 RpcAcceptor 接收客户端的调用请求，同样使用 RpcProtocol 执行协议解码（decode）。 解码后的调用信息传递给 RpcProcessor 去控制处理调用过程，最后再委托调用给 RpcInvoker 去实际执行并返回调用结果。</p>\n<h3 id=\"RPC组件职责\"><a href=\"#RPC组件职责\" class=\"headerlink\" title=\"RPC组件职责\"></a>RPC组件职责</h3><ol>\n<li>RpcServer：负责导出（export）远程接口</li>\n<li>RpcClient：负责导入（import）远程接口的代理实现</li>\n<li>RpcProxy：远程接口的代理实现</li>\n<li>RpcInvoker：<ol>\n<li>客户端实现方式：负责编码调用信息和发送调用请求到服务方并等待调用结果返回</li>\n<li>服务端实现方式：负责调用服务端接口的具体实现并返回调用结果</li>\n</ol>\n</li>\n<li>RpcProtocol：负责协议编/解码</li>\n<li>RpcConnector：负责维持客户方和服务方的连接通道和发送数据到服务方</li>\n<li>RpcAcceptor：负责接收客户方请求并返回请求结果</li>\n<li>RpcProcessor：负责在服务方控制调用过程，包括管理调用线程池、超时时间等</li>\n<li>RpcChannel：数据传输通道</li>\n</ol>\n<p>参考：<br><a href=\"http://www.cnblogs.com/metoy/p/4321311.html?utm_source=tuicool&amp;utm_medium=referral\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/metoy/p/4321311.html?utm_source=tuicool&amp;utm_medium=referral</a><br><a href=\"http://www.cnblogs.com/LBSer/p/4853234.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/LBSer/p/4853234.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>远程过程调用（Remote Procedure Call，缩写为RPC）是一种计算机通信协议。该协议运行运行与一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方法调用。——维基百科</p>\n<h3 id=\"RPC调用分类\"><a href=\"#RPC调用分类\" class=\"headerlink\" title=\"RPC调用分类\"></a>RPC调用分类</h3><p>同步调用：客户方等待调用执行完成并返回结果<br>异步调用：客户方调用后不用等待执行结果返回，但依然可以通过回调通知等方式获取返回结果。 若客户方不关心调用返回结果，则变成单向异步调用，单向调用不用返回结果</p>\n<h3 id=\"RPC结构\"><a href=\"#RPC结构\" class=\"headerlink\" title=\"RPC结构\"></a>RPC结构</h3><p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-29bfe0b7d38005c1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/960\" alt=\"rpc-20170302.jpg\"><br>RPC 服务方通过 RpcServer 去导出（export）远程接口方法，而客户方通过 RpcClient 去引入（import）远程接口方法。 客户方像调用本地方法一样去调用远程接口方法，RPC 框架提供接口的代理实现，实际的调用将委托给代理 RpcProxy 。 代理封装调用信息并将调用转交给 RpcInvoker 去实际执行。 在客户端的 RpcInvoker 通过连接器 RpcConnector 去维持与服务端的通道 RpcChannel， 并使用 RpcProtocol 执行协议编码（encode）并将编码后的请求消息通过通道发送给服务方。<br>RPC 服务端接收器 RpcAcceptor 接收客户端的调用请求，同样使用 RpcProtocol 执行协议解码（decode）。 解码后的调用信息传递给 RpcProcessor 去控制处理调用过程，最后再委托调用给 RpcInvoker 去实际执行并返回调用结果。</p>\n<h3 id=\"RPC组件职责\"><a href=\"#RPC组件职责\" class=\"headerlink\" title=\"RPC组件职责\"></a>RPC组件职责</h3><ol>\n<li>RpcServer：负责导出（export）远程接口</li>\n<li>RpcClient：负责导入（import）远程接口的代理实现</li>\n<li>RpcProxy：远程接口的代理实现</li>\n<li>RpcInvoker：<ol>\n<li>客户端实现方式：负责编码调用信息和发送调用请求到服务方并等待调用结果返回</li>\n<li>服务端实现方式：负责调用服务端接口的具体实现并返回调用结果</li>\n</ol>\n</li>\n<li>RpcProtocol：负责协议编/解码</li>\n<li>RpcConnector：负责维持客户方和服务方的连接通道和发送数据到服务方</li>\n<li>RpcAcceptor：负责接收客户方请求并返回请求结果</li>\n<li>RpcProcessor：负责在服务方控制调用过程，包括管理调用线程池、超时时间等</li>\n<li>RpcChannel：数据传输通道</li>\n</ol>\n<p>参考：<br><a href=\"http://www.cnblogs.com/metoy/p/4321311.html?utm_source=tuicool&amp;utm_medium=referral\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/metoy/p/4321311.html?utm_source=tuicool&amp;utm_medium=referral</a><br><a href=\"http://www.cnblogs.com/LBSer/p/4853234.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/LBSer/p/4853234.html</a></p>\n"},{"title":"Spark RDD详解","date":"2017-02-07T11:58:41.000Z","_content":"### RDD基本概念：\n* RDD（ resilient distributed dataset，弹性分布式数据集）：spark的基本计算单元，可以通过一系列算子进行操作（主要有Transformation和Action操作）。\n* RDD是一个不可修改的，分布的对象集合。每个RDD由多个分区组成，每个分区可以同时在集群中的不同节点上计算。RDD可以包含Python，Java和Scala中的任意对象。                \n* DAG （Directed Acycle graph，有向无环图）：反应RDD之间的依赖\n* 窄依赖（Narrow dependency）：子RDD依赖于父RDD中固定的data\n* 宽依赖（Wide Dependency）：子RDD对父RDD中的所有data partition都有依赖\n\n<!-- more -->\n\n### RDD构建图\n![sparkRdd.jpg](http://upload-images.jianshu.io/upload_images/1419542-ae8b332de4f1f91f.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n\n### RDD来源：\n*  parallelizing an existing collection in your driver program（程序内部已经存在的数据集）\n* referencing a dataset in an external storage system, such as a shared filesystem, HDFS, HBase, or any data source offering a Hadoop InputFormat（外部存储系统）\n\n\n\n### RDD特点：\n1、有一个分片列表。就是能被切分，和hadoop一样的，能够切分的数据才能并行计算。\n2、有一个函数计算每一个分片，这里指的是下面会提到的compute函数。\n3、对其他的RDD的依赖列表，依赖还具体分为宽依赖和窄依赖，但并不是所有的RDD都有依赖。\n4、可选：key-value型的RDD是根据哈希来分区的，类似于mapreduce当中的Paritioner接口，控制key分到哪个reduce。\n5、可选：每一个分片的优先计算位置（preferred locations），比如HDFS的block的所在位置应该是优先计算的位置。\n```\n// return the set of partitions in this RDD\nprotected def getPartitions: Array[Partition]\n/* 分片列表 */\n\n// compute a given partition\ndef compute(split: Partition, context: TaskContext): Iterator[T]\n/* compute 对分片进行计算,得出一个可遍历的结果 */\n\n// return how this RDD depends on parent RDDs\nprotected def getDependencies: Seq[Dependency[_]] = deps\n/* 只计算一次，计算RDD对父RDD的依赖 */\n\n@transient val partitioner: Option[Partitioner] = None\n /* 可选的，分区的方法，针对第4点，类似于mapreduce当中的Paritioner接口，控制key分到哪个reduce */\n\nprotected def getPreferredLocations(split: Partition): Seq[String] = Nil\n/* 可选的，指定优先位置，输入参数是split分片，输出结果是一组优先的节点位置*/\n```\n\n\n### RDD操作\n* transformations：接受RDD并返回RDD\nTransformation采用惰性调用机制，每个RDD记录父RDD转换的方法，这种调用链表称之为血缘（lineage）。\n* action：接受RDD但是返回非RDD\nAction调用会直接计算。\n\n### RDD优化技巧\n* RDD缓存：需要使用多次的数据需要cache，否则会进行不必要的重复操作。\n可以通过`rdd.persist(newLevel: StorageLevel, allowOverride: Boolean)`或`rdd.cache()`（就是调用persist）来缓存数据\n* 转换并行化：RDD的转换操作是并行化计算的，多个RDD的转换同样是可以并\n* 减少shuffle网络传输：网络I/O开销是很大的，减少网络开销，可以显著加快计算效率。\n\n### RDD运行过程（具体在Spark任务调度中详细说明）\n1、创建RDD对象\n2、DAGScheduler模块介入运行，计算RDD之间的依赖关系。RDD之间的依赖关系就形成了DAG\n3、每一个JOB被分为多个Stage，划分Stage的一个主要依据是当前计算因子的输入是否确定的，如果是则将其分在同一个Stage，避免多个Stage之间的消息传递开销\n\n\n\n参考：\nhttp://www.cnblogs.com/bourneli/p/4394271.html\nhttp://www.jianshu.com/p/4ff6afbbafe4\nhttp://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds\n\n### 附\nTransformation具体内容\n`map(func)` :返回一个新的分布式数据集，由每个原元素经过func函数转换后组成\n`filter(func) `: 返回一个新的数据集，由经过func函数后返回值为true的原元素组成\n`flatMap(func) `: 类似于map，但是每一个输入元素，会被映射为0到多个输出元素（因此，func函数的返回值是一个Seq，而不是单一元素）\n`sample(withReplacement, frac, seed) `:根据给定的随机种子seed，随机抽样出数量为frac的数据\n`union(otherDataset)` : 返回一个新的数据集，由原数据集和参数联合而成\n`groupByKey([numTasks])` :在一个由（K,V）对组成的数据集上调用，返回一个（K，Seq[V])对的数据集。注意：默认情况下，使用8个并行任务进行分组，你可以传入numTask可选参数，根据数据量设置不同数目的Task\n`reduceByKey(func, [numTasks]) `: 在一个（K，V)对的数据集上使用，返回一个（K，V）对的数据集，key相同的值，都被使用指定的reduce函数聚合到一起。和groupbykey类似，任务的个数是可以通过第二个可选参数来配置的。\n`join(otherDataset, [numTasks])` ：在类型为（K,V)和（K,W)类型的数据集上调用，返回一个（K,(V,W))对，每个key中的所有元素都在一起的数据集\n`groupWith(otherDataset, [numTasks])` ：在类型为（K,V)和(K,W)类型的数据集上调用，返回一个数据集，组成元素为（K, Seq[V], Seq[W]) Tuples。这个操作在其它框架，称为CoGroup\n`cartesian(otherDataset) `: 笛卡尔积。但在数据集T和U上调用时，返回一个(T，U）对的数据集，所有元素交互进行笛卡尔积。\n\nActions具体内容\n`reduce(func) `: 通过函数func聚集数据集中的所有元素。Func函数接受2个参数，返回一个值。这个函数必须是关联性的，确保可以被正确的并发执行\n`collect()` : 在Driver的程序中，以数组的形式，返回数据集的所有元素。这通常会在使用filter或者其它操作后，返回一个足够小的数据子集再使用，直接将整个RDD集Collect返回，很可能会让Driver程序OOM\n`count()` : 返回数据集的元素个数\n`take(n)` : 返回一个数组，由数据集的前n个元素组成。注意，这个操作目前并非在多个节点上，并行执行，而是Driver程序所在机器，单机计算所有的元素(Gateway的内存压力会增大，需要谨慎使用）\n`first()` : 返回数据集的第一个元素（类似于take(1)）\n`saveAsTextFile(path) `: 将数据集的元素，以textfile的形式，保存到本地文件系统，hdfs或者任何其它hadoop支持的文件系统。Spark将会调用每个元素的toString方法，并将它转换为文件中的一行文本\n`saveAsSequenceFile(path)` : 将数据集的元素，以sequencefile的格式，保存到指定的目录下，本地系统，hdfs或者任何其它hadoop支持的文件系统。RDD的元素必须由key-value对组成，并都实现了Hadoop的Writable接口，或隐式可以转换为Writable（Spark包括了基本类型的转换，例如Int，Double，String等等）\n`foreach(func)` : 在数据集的每一个元素上，运行函数func。这通常用于更新一个累加器变量，或者和外部存储系统做交互\n","source":"_posts/Spark-RDD详解.md","raw":"---\ntitle: Spark RDD详解\ndate: 2017-02-07 19:58:41\ntags: [spark]\ncategories: [spark]\n---\n### RDD基本概念：\n* RDD（ resilient distributed dataset，弹性分布式数据集）：spark的基本计算单元，可以通过一系列算子进行操作（主要有Transformation和Action操作）。\n* RDD是一个不可修改的，分布的对象集合。每个RDD由多个分区组成，每个分区可以同时在集群中的不同节点上计算。RDD可以包含Python，Java和Scala中的任意对象。                \n* DAG （Directed Acycle graph，有向无环图）：反应RDD之间的依赖\n* 窄依赖（Narrow dependency）：子RDD依赖于父RDD中固定的data\n* 宽依赖（Wide Dependency）：子RDD对父RDD中的所有data partition都有依赖\n\n<!-- more -->\n\n### RDD构建图\n![sparkRdd.jpg](http://upload-images.jianshu.io/upload_images/1419542-ae8b332de4f1f91f.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n\n### RDD来源：\n*  parallelizing an existing collection in your driver program（程序内部已经存在的数据集）\n* referencing a dataset in an external storage system, such as a shared filesystem, HDFS, HBase, or any data source offering a Hadoop InputFormat（外部存储系统）\n\n\n\n### RDD特点：\n1、有一个分片列表。就是能被切分，和hadoop一样的，能够切分的数据才能并行计算。\n2、有一个函数计算每一个分片，这里指的是下面会提到的compute函数。\n3、对其他的RDD的依赖列表，依赖还具体分为宽依赖和窄依赖，但并不是所有的RDD都有依赖。\n4、可选：key-value型的RDD是根据哈希来分区的，类似于mapreduce当中的Paritioner接口，控制key分到哪个reduce。\n5、可选：每一个分片的优先计算位置（preferred locations），比如HDFS的block的所在位置应该是优先计算的位置。\n```\n// return the set of partitions in this RDD\nprotected def getPartitions: Array[Partition]\n/* 分片列表 */\n\n// compute a given partition\ndef compute(split: Partition, context: TaskContext): Iterator[T]\n/* compute 对分片进行计算,得出一个可遍历的结果 */\n\n// return how this RDD depends on parent RDDs\nprotected def getDependencies: Seq[Dependency[_]] = deps\n/* 只计算一次，计算RDD对父RDD的依赖 */\n\n@transient val partitioner: Option[Partitioner] = None\n /* 可选的，分区的方法，针对第4点，类似于mapreduce当中的Paritioner接口，控制key分到哪个reduce */\n\nprotected def getPreferredLocations(split: Partition): Seq[String] = Nil\n/* 可选的，指定优先位置，输入参数是split分片，输出结果是一组优先的节点位置*/\n```\n\n\n### RDD操作\n* transformations：接受RDD并返回RDD\nTransformation采用惰性调用机制，每个RDD记录父RDD转换的方法，这种调用链表称之为血缘（lineage）。\n* action：接受RDD但是返回非RDD\nAction调用会直接计算。\n\n### RDD优化技巧\n* RDD缓存：需要使用多次的数据需要cache，否则会进行不必要的重复操作。\n可以通过`rdd.persist(newLevel: StorageLevel, allowOverride: Boolean)`或`rdd.cache()`（就是调用persist）来缓存数据\n* 转换并行化：RDD的转换操作是并行化计算的，多个RDD的转换同样是可以并\n* 减少shuffle网络传输：网络I/O开销是很大的，减少网络开销，可以显著加快计算效率。\n\n### RDD运行过程（具体在Spark任务调度中详细说明）\n1、创建RDD对象\n2、DAGScheduler模块介入运行，计算RDD之间的依赖关系。RDD之间的依赖关系就形成了DAG\n3、每一个JOB被分为多个Stage，划分Stage的一个主要依据是当前计算因子的输入是否确定的，如果是则将其分在同一个Stage，避免多个Stage之间的消息传递开销\n\n\n\n参考：\nhttp://www.cnblogs.com/bourneli/p/4394271.html\nhttp://www.jianshu.com/p/4ff6afbbafe4\nhttp://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds\n\n### 附\nTransformation具体内容\n`map(func)` :返回一个新的分布式数据集，由每个原元素经过func函数转换后组成\n`filter(func) `: 返回一个新的数据集，由经过func函数后返回值为true的原元素组成\n`flatMap(func) `: 类似于map，但是每一个输入元素，会被映射为0到多个输出元素（因此，func函数的返回值是一个Seq，而不是单一元素）\n`sample(withReplacement, frac, seed) `:根据给定的随机种子seed，随机抽样出数量为frac的数据\n`union(otherDataset)` : 返回一个新的数据集，由原数据集和参数联合而成\n`groupByKey([numTasks])` :在一个由（K,V）对组成的数据集上调用，返回一个（K，Seq[V])对的数据集。注意：默认情况下，使用8个并行任务进行分组，你可以传入numTask可选参数，根据数据量设置不同数目的Task\n`reduceByKey(func, [numTasks]) `: 在一个（K，V)对的数据集上使用，返回一个（K，V）对的数据集，key相同的值，都被使用指定的reduce函数聚合到一起。和groupbykey类似，任务的个数是可以通过第二个可选参数来配置的。\n`join(otherDataset, [numTasks])` ：在类型为（K,V)和（K,W)类型的数据集上调用，返回一个（K,(V,W))对，每个key中的所有元素都在一起的数据集\n`groupWith(otherDataset, [numTasks])` ：在类型为（K,V)和(K,W)类型的数据集上调用，返回一个数据集，组成元素为（K, Seq[V], Seq[W]) Tuples。这个操作在其它框架，称为CoGroup\n`cartesian(otherDataset) `: 笛卡尔积。但在数据集T和U上调用时，返回一个(T，U）对的数据集，所有元素交互进行笛卡尔积。\n\nActions具体内容\n`reduce(func) `: 通过函数func聚集数据集中的所有元素。Func函数接受2个参数，返回一个值。这个函数必须是关联性的，确保可以被正确的并发执行\n`collect()` : 在Driver的程序中，以数组的形式，返回数据集的所有元素。这通常会在使用filter或者其它操作后，返回一个足够小的数据子集再使用，直接将整个RDD集Collect返回，很可能会让Driver程序OOM\n`count()` : 返回数据集的元素个数\n`take(n)` : 返回一个数组，由数据集的前n个元素组成。注意，这个操作目前并非在多个节点上，并行执行，而是Driver程序所在机器，单机计算所有的元素(Gateway的内存压力会增大，需要谨慎使用）\n`first()` : 返回数据集的第一个元素（类似于take(1)）\n`saveAsTextFile(path) `: 将数据集的元素，以textfile的形式，保存到本地文件系统，hdfs或者任何其它hadoop支持的文件系统。Spark将会调用每个元素的toString方法，并将它转换为文件中的一行文本\n`saveAsSequenceFile(path)` : 将数据集的元素，以sequencefile的格式，保存到指定的目录下，本地系统，hdfs或者任何其它hadoop支持的文件系统。RDD的元素必须由key-value对组成，并都实现了Hadoop的Writable接口，或隐式可以转换为Writable（Spark包括了基本类型的转换，例如Int，Double，String等等）\n`foreach(func)` : 在数据集的每一个元素上，运行函数func。这通常用于更新一个累加器变量，或者和外部存储系统做交互\n","slug":"Spark-RDD详解","published":1,"updated":"2018-09-03T12:29:46.717Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmo9un2z000c9q0vu8cy5b12","content":"<h3 id=\"RDD基本概念：\"><a href=\"#RDD基本概念：\" class=\"headerlink\" title=\"RDD基本概念：\"></a>RDD基本概念：</h3><ul>\n<li>RDD（ resilient distributed dataset，弹性分布式数据集）：spark的基本计算单元，可以通过一系列算子进行操作（主要有Transformation和Action操作）。</li>\n<li>RDD是一个不可修改的，分布的对象集合。每个RDD由多个分区组成，每个分区可以同时在集群中的不同节点上计算。RDD可以包含Python，Java和Scala中的任意对象。                </li>\n<li>DAG （Directed Acycle graph，有向无环图）：反应RDD之间的依赖</li>\n<li>窄依赖（Narrow dependency）：子RDD依赖于父RDD中固定的data</li>\n<li>宽依赖（Wide Dependency）：子RDD对父RDD中的所有data partition都有依赖</li>\n</ul>\n<a id=\"more\"></a>\n<h3 id=\"RDD构建图\"><a href=\"#RDD构建图\" class=\"headerlink\" title=\"RDD构建图\"></a>RDD构建图</h3><p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-ae8b332de4f1f91f.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"sparkRdd.jpg\"></p>\n<h3 id=\"RDD来源：\"><a href=\"#RDD来源：\" class=\"headerlink\" title=\"RDD来源：\"></a>RDD来源：</h3><ul>\n<li>parallelizing an existing collection in your driver program（程序内部已经存在的数据集）</li>\n<li>referencing a dataset in an external storage system, such as a shared filesystem, HDFS, HBase, or any data source offering a Hadoop InputFormat（外部存储系统）</li>\n</ul>\n<h3 id=\"RDD特点：\"><a href=\"#RDD特点：\" class=\"headerlink\" title=\"RDD特点：\"></a>RDD特点：</h3><p>1、有一个分片列表。就是能被切分，和hadoop一样的，能够切分的数据才能并行计算。<br>2、有一个函数计算每一个分片，这里指的是下面会提到的compute函数。<br>3、对其他的RDD的依赖列表，依赖还具体分为宽依赖和窄依赖，但并不是所有的RDD都有依赖。<br>4、可选：key-value型的RDD是根据哈希来分区的，类似于mapreduce当中的Paritioner接口，控制key分到哪个reduce。<br>5、可选：每一个分片的优先计算位置（preferred locations），比如HDFS的block的所在位置应该是优先计算的位置。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// return the set of partitions in this RDD</span><br><span class=\"line\">protected def getPartitions: Array[Partition]</span><br><span class=\"line\">/* 分片列表 */</span><br><span class=\"line\"></span><br><span class=\"line\">// compute a given partition</span><br><span class=\"line\">def compute(split: Partition, context: TaskContext): Iterator[T]</span><br><span class=\"line\">/* compute 对分片进行计算,得出一个可遍历的结果 */</span><br><span class=\"line\"></span><br><span class=\"line\">// return how this RDD depends on parent RDDs</span><br><span class=\"line\">protected def getDependencies: Seq[Dependency[_]] = deps</span><br><span class=\"line\">/* 只计算一次，计算RDD对父RDD的依赖 */</span><br><span class=\"line\"></span><br><span class=\"line\">@transient val partitioner: Option[Partitioner] = None</span><br><span class=\"line\"> /* 可选的，分区的方法，针对第4点，类似于mapreduce当中的Paritioner接口，控制key分到哪个reduce */</span><br><span class=\"line\"></span><br><span class=\"line\">protected def getPreferredLocations(split: Partition): Seq[String] = Nil</span><br><span class=\"line\">/* 可选的，指定优先位置，输入参数是split分片，输出结果是一组优先的节点位置*/</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"RDD操作\"><a href=\"#RDD操作\" class=\"headerlink\" title=\"RDD操作\"></a>RDD操作</h3><ul>\n<li>transformations：接受RDD并返回RDD<br>Transformation采用惰性调用机制，每个RDD记录父RDD转换的方法，这种调用链表称之为血缘（lineage）。</li>\n<li>action：接受RDD但是返回非RDD<br>Action调用会直接计算。</li>\n</ul>\n<h3 id=\"RDD优化技巧\"><a href=\"#RDD优化技巧\" class=\"headerlink\" title=\"RDD优化技巧\"></a>RDD优化技巧</h3><ul>\n<li>RDD缓存：需要使用多次的数据需要cache，否则会进行不必要的重复操作。<br>可以通过<code>rdd.persist(newLevel: StorageLevel, allowOverride: Boolean)</code>或<code>rdd.cache()</code>（就是调用persist）来缓存数据</li>\n<li>转换并行化：RDD的转换操作是并行化计算的，多个RDD的转换同样是可以并</li>\n<li>减少shuffle网络传输：网络I/O开销是很大的，减少网络开销，可以显著加快计算效率。</li>\n</ul>\n<h3 id=\"RDD运行过程（具体在Spark任务调度中详细说明）\"><a href=\"#RDD运行过程（具体在Spark任务调度中详细说明）\" class=\"headerlink\" title=\"RDD运行过程（具体在Spark任务调度中详细说明）\"></a>RDD运行过程（具体在Spark任务调度中详细说明）</h3><p>1、创建RDD对象<br>2、DAGScheduler模块介入运行，计算RDD之间的依赖关系。RDD之间的依赖关系就形成了DAG<br>3、每一个JOB被分为多个Stage，划分Stage的一个主要依据是当前计算因子的输入是否确定的，如果是则将其分在同一个Stage，避免多个Stage之间的消息传递开销</p>\n<p>参考：<br><a href=\"http://www.cnblogs.com/bourneli/p/4394271.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/bourneli/p/4394271.html</a><br><a href=\"http://www.jianshu.com/p/4ff6afbbafe4\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/4ff6afbbafe4</a><br><a href=\"http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds\" target=\"_blank\" rel=\"noopener\">http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds</a></p>\n<h3 id=\"附\"><a href=\"#附\" class=\"headerlink\" title=\"附\"></a>附</h3><p>Transformation具体内容<br><code>map(func)</code> :返回一个新的分布式数据集，由每个原元素经过func函数转换后组成<br><code>filter(func)</code>: 返回一个新的数据集，由经过func函数后返回值为true的原元素组成<br><code>flatMap(func)</code>: 类似于map，但是每一个输入元素，会被映射为0到多个输出元素（因此，func函数的返回值是一个Seq，而不是单一元素）<br><code>sample(withReplacement, frac, seed)</code>:根据给定的随机种子seed，随机抽样出数量为frac的数据<br><code>union(otherDataset)</code> : 返回一个新的数据集，由原数据集和参数联合而成<br><code>groupByKey([numTasks])</code> :在一个由（K,V）对组成的数据集上调用，返回一个（K，Seq[V])对的数据集。注意：默认情况下，使用8个并行任务进行分组，你可以传入numTask可选参数，根据数据量设置不同数目的Task<br><code>reduceByKey(func, [numTasks])</code>: 在一个（K，V)对的数据集上使用，返回一个（K，V）对的数据集，key相同的值，都被使用指定的reduce函数聚合到一起。和groupbykey类似，任务的个数是可以通过第二个可选参数来配置的。<br><code>join(otherDataset, [numTasks])</code> ：在类型为（K,V)和（K,W)类型的数据集上调用，返回一个（K,(V,W))对，每个key中的所有元素都在一起的数据集<br><code>groupWith(otherDataset, [numTasks])</code> ：在类型为（K,V)和(K,W)类型的数据集上调用，返回一个数据集，组成元素为（K, Seq[V], Seq[W]) Tuples。这个操作在其它框架，称为CoGroup<br><code>cartesian(otherDataset)</code>: 笛卡尔积。但在数据集T和U上调用时，返回一个(T，U）对的数据集，所有元素交互进行笛卡尔积。</p>\n<p>Actions具体内容<br><code>reduce(func)</code>: 通过函数func聚集数据集中的所有元素。Func函数接受2个参数，返回一个值。这个函数必须是关联性的，确保可以被正确的并发执行<br><code>collect()</code> : 在Driver的程序中，以数组的形式，返回数据集的所有元素。这通常会在使用filter或者其它操作后，返回一个足够小的数据子集再使用，直接将整个RDD集Collect返回，很可能会让Driver程序OOM<br><code>count()</code> : 返回数据集的元素个数<br><code>take(n)</code> : 返回一个数组，由数据集的前n个元素组成。注意，这个操作目前并非在多个节点上，并行执行，而是Driver程序所在机器，单机计算所有的元素(Gateway的内存压力会增大，需要谨慎使用）<br><code>first()</code> : 返回数据集的第一个元素（类似于take(1)）<br><code>saveAsTextFile(path)</code>: 将数据集的元素，以textfile的形式，保存到本地文件系统，hdfs或者任何其它hadoop支持的文件系统。Spark将会调用每个元素的toString方法，并将它转换为文件中的一行文本<br><code>saveAsSequenceFile(path)</code> : 将数据集的元素，以sequencefile的格式，保存到指定的目录下，本地系统，hdfs或者任何其它hadoop支持的文件系统。RDD的元素必须由key-value对组成，并都实现了Hadoop的Writable接口，或隐式可以转换为Writable（Spark包括了基本类型的转换，例如Int，Double，String等等）<br><code>foreach(func)</code> : 在数据集的每一个元素上，运行函数func。这通常用于更新一个累加器变量，或者和外部存储系统做交互</p>\n","site":{"data":{}},"excerpt":"<h3 id=\"RDD基本概念：\"><a href=\"#RDD基本概念：\" class=\"headerlink\" title=\"RDD基本概念：\"></a>RDD基本概念：</h3><ul>\n<li>RDD（ resilient distributed dataset，弹性分布式数据集）：spark的基本计算单元，可以通过一系列算子进行操作（主要有Transformation和Action操作）。</li>\n<li>RDD是一个不可修改的，分布的对象集合。每个RDD由多个分区组成，每个分区可以同时在集群中的不同节点上计算。RDD可以包含Python，Java和Scala中的任意对象。                </li>\n<li>DAG （Directed Acycle graph，有向无环图）：反应RDD之间的依赖</li>\n<li>窄依赖（Narrow dependency）：子RDD依赖于父RDD中固定的data</li>\n<li>宽依赖（Wide Dependency）：子RDD对父RDD中的所有data partition都有依赖</li>\n</ul>","more":"<h3 id=\"RDD构建图\"><a href=\"#RDD构建图\" class=\"headerlink\" title=\"RDD构建图\"></a>RDD构建图</h3><p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-ae8b332de4f1f91f.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"sparkRdd.jpg\"></p>\n<h3 id=\"RDD来源：\"><a href=\"#RDD来源：\" class=\"headerlink\" title=\"RDD来源：\"></a>RDD来源：</h3><ul>\n<li>parallelizing an existing collection in your driver program（程序内部已经存在的数据集）</li>\n<li>referencing a dataset in an external storage system, such as a shared filesystem, HDFS, HBase, or any data source offering a Hadoop InputFormat（外部存储系统）</li>\n</ul>\n<h3 id=\"RDD特点：\"><a href=\"#RDD特点：\" class=\"headerlink\" title=\"RDD特点：\"></a>RDD特点：</h3><p>1、有一个分片列表。就是能被切分，和hadoop一样的，能够切分的数据才能并行计算。<br>2、有一个函数计算每一个分片，这里指的是下面会提到的compute函数。<br>3、对其他的RDD的依赖列表，依赖还具体分为宽依赖和窄依赖，但并不是所有的RDD都有依赖。<br>4、可选：key-value型的RDD是根据哈希来分区的，类似于mapreduce当中的Paritioner接口，控制key分到哪个reduce。<br>5、可选：每一个分片的优先计算位置（preferred locations），比如HDFS的block的所在位置应该是优先计算的位置。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// return the set of partitions in this RDD</span><br><span class=\"line\">protected def getPartitions: Array[Partition]</span><br><span class=\"line\">/* 分片列表 */</span><br><span class=\"line\"></span><br><span class=\"line\">// compute a given partition</span><br><span class=\"line\">def compute(split: Partition, context: TaskContext): Iterator[T]</span><br><span class=\"line\">/* compute 对分片进行计算,得出一个可遍历的结果 */</span><br><span class=\"line\"></span><br><span class=\"line\">// return how this RDD depends on parent RDDs</span><br><span class=\"line\">protected def getDependencies: Seq[Dependency[_]] = deps</span><br><span class=\"line\">/* 只计算一次，计算RDD对父RDD的依赖 */</span><br><span class=\"line\"></span><br><span class=\"line\">@transient val partitioner: Option[Partitioner] = None</span><br><span class=\"line\"> /* 可选的，分区的方法，针对第4点，类似于mapreduce当中的Paritioner接口，控制key分到哪个reduce */</span><br><span class=\"line\"></span><br><span class=\"line\">protected def getPreferredLocations(split: Partition): Seq[String] = Nil</span><br><span class=\"line\">/* 可选的，指定优先位置，输入参数是split分片，输出结果是一组优先的节点位置*/</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"RDD操作\"><a href=\"#RDD操作\" class=\"headerlink\" title=\"RDD操作\"></a>RDD操作</h3><ul>\n<li>transformations：接受RDD并返回RDD<br>Transformation采用惰性调用机制，每个RDD记录父RDD转换的方法，这种调用链表称之为血缘（lineage）。</li>\n<li>action：接受RDD但是返回非RDD<br>Action调用会直接计算。</li>\n</ul>\n<h3 id=\"RDD优化技巧\"><a href=\"#RDD优化技巧\" class=\"headerlink\" title=\"RDD优化技巧\"></a>RDD优化技巧</h3><ul>\n<li>RDD缓存：需要使用多次的数据需要cache，否则会进行不必要的重复操作。<br>可以通过<code>rdd.persist(newLevel: StorageLevel, allowOverride: Boolean)</code>或<code>rdd.cache()</code>（就是调用persist）来缓存数据</li>\n<li>转换并行化：RDD的转换操作是并行化计算的，多个RDD的转换同样是可以并</li>\n<li>减少shuffle网络传输：网络I/O开销是很大的，减少网络开销，可以显著加快计算效率。</li>\n</ul>\n<h3 id=\"RDD运行过程（具体在Spark任务调度中详细说明）\"><a href=\"#RDD运行过程（具体在Spark任务调度中详细说明）\" class=\"headerlink\" title=\"RDD运行过程（具体在Spark任务调度中详细说明）\"></a>RDD运行过程（具体在Spark任务调度中详细说明）</h3><p>1、创建RDD对象<br>2、DAGScheduler模块介入运行，计算RDD之间的依赖关系。RDD之间的依赖关系就形成了DAG<br>3、每一个JOB被分为多个Stage，划分Stage的一个主要依据是当前计算因子的输入是否确定的，如果是则将其分在同一个Stage，避免多个Stage之间的消息传递开销</p>\n<p>参考：<br><a href=\"http://www.cnblogs.com/bourneli/p/4394271.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/bourneli/p/4394271.html</a><br><a href=\"http://www.jianshu.com/p/4ff6afbbafe4\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/4ff6afbbafe4</a><br><a href=\"http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds\" target=\"_blank\" rel=\"noopener\">http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds</a></p>\n<h3 id=\"附\"><a href=\"#附\" class=\"headerlink\" title=\"附\"></a>附</h3><p>Transformation具体内容<br><code>map(func)</code> :返回一个新的分布式数据集，由每个原元素经过func函数转换后组成<br><code>filter(func)</code>: 返回一个新的数据集，由经过func函数后返回值为true的原元素组成<br><code>flatMap(func)</code>: 类似于map，但是每一个输入元素，会被映射为0到多个输出元素（因此，func函数的返回值是一个Seq，而不是单一元素）<br><code>sample(withReplacement, frac, seed)</code>:根据给定的随机种子seed，随机抽样出数量为frac的数据<br><code>union(otherDataset)</code> : 返回一个新的数据集，由原数据集和参数联合而成<br><code>groupByKey([numTasks])</code> :在一个由（K,V）对组成的数据集上调用，返回一个（K，Seq[V])对的数据集。注意：默认情况下，使用8个并行任务进行分组，你可以传入numTask可选参数，根据数据量设置不同数目的Task<br><code>reduceByKey(func, [numTasks])</code>: 在一个（K，V)对的数据集上使用，返回一个（K，V）对的数据集，key相同的值，都被使用指定的reduce函数聚合到一起。和groupbykey类似，任务的个数是可以通过第二个可选参数来配置的。<br><code>join(otherDataset, [numTasks])</code> ：在类型为（K,V)和（K,W)类型的数据集上调用，返回一个（K,(V,W))对，每个key中的所有元素都在一起的数据集<br><code>groupWith(otherDataset, [numTasks])</code> ：在类型为（K,V)和(K,W)类型的数据集上调用，返回一个数据集，组成元素为（K, Seq[V], Seq[W]) Tuples。这个操作在其它框架，称为CoGroup<br><code>cartesian(otherDataset)</code>: 笛卡尔积。但在数据集T和U上调用时，返回一个(T，U）对的数据集，所有元素交互进行笛卡尔积。</p>\n<p>Actions具体内容<br><code>reduce(func)</code>: 通过函数func聚集数据集中的所有元素。Func函数接受2个参数，返回一个值。这个函数必须是关联性的，确保可以被正确的并发执行<br><code>collect()</code> : 在Driver的程序中，以数组的形式，返回数据集的所有元素。这通常会在使用filter或者其它操作后，返回一个足够小的数据子集再使用，直接将整个RDD集Collect返回，很可能会让Driver程序OOM<br><code>count()</code> : 返回数据集的元素个数<br><code>take(n)</code> : 返回一个数组，由数据集的前n个元素组成。注意，这个操作目前并非在多个节点上，并行执行，而是Driver程序所在机器，单机计算所有的元素(Gateway的内存压力会增大，需要谨慎使用）<br><code>first()</code> : 返回数据集的第一个元素（类似于take(1)）<br><code>saveAsTextFile(path)</code>: 将数据集的元素，以textfile的形式，保存到本地文件系统，hdfs或者任何其它hadoop支持的文件系统。Spark将会调用每个元素的toString方法，并将它转换为文件中的一行文本<br><code>saveAsSequenceFile(path)</code> : 将数据集的元素，以sequencefile的格式，保存到指定的目录下，本地系统，hdfs或者任何其它hadoop支持的文件系统。RDD的元素必须由key-value对组成，并都实现了Hadoop的Writable接口，或隐式可以转换为Writable（Spark包括了基本类型的转换，例如Int，Double，String等等）<br><code>foreach(func)</code> : 在数据集的每一个元素上，运行函数func。这通常用于更新一个累加器变量，或者和外部存储系统做交互</p>"},{"title":"Spark Shuffle基础","date":"2017-02-06T07:45:36.000Z","_content":"### Shuffle 基本概念\n#### 概述：\n* Shuffle描述着数据从map task输出到reduce task 输入的这段过程。在分布式情况下，reduce task需要跨节点拉取其它节点上的map task结果。\n* 当Map的输出结果要被Reduce使用时，输出结果需要按key哈希，并且分发到每一个Reducer上去，这个过程就是shuffle。\n* 由于shuffle涉及到了磁盘的读写和网络的传输，因此shuffle性能的高低直接影响到了整个程序的运行效率。\n<!--more-->\n#### Spark 的Shuffle 分为 Write，Read 两阶段\n* Write 对应的是ShuffleMapTask，具体的写操作ExternalSorter来负责\n* Read 阶段由ShuffleRDD里的HashShuffleReader来完成。如果拉来的数据如果过大，需要落地，则也由ExternalSorter来完成的\n* 所有Write 写完后，才会执行Read。 他们被分成了两个不同的Stage阶段。\n\nShuffle Write ,Shuffle Read 两阶段都可能需要落磁盘，并且通过Disk Merge 来完成最后的Sort归并排序。\n\n### Spark的Shuffle机制\n> Spark中的Shuffle是把一组无规则的数据尽量转换成一组具有一定规则的数据。\n\nShuffle就是包裹在各种需要重分区的算子之下的一个对数据进行重新组合的过程。\nShuffle将数据进行收集分配到指定Reduce分区，Reduce阶段根据函数对相应的分区做Reduce所需的函数处理。\n\n\n### Shuffle的基本流程\n> bucket是一个抽象概念，在实现中每个bucket可以对应一个文件，可以对应文件的一部分或是其他等\n\n![shuffle-write-no-consolidation.png](http://upload-images.jianshu.io/upload_images/1419542-47813c3a4aeccf1e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n* 首先每一个Mapper会根据Reducer的数量创建出相应的bucket，bucket的数量是M×R，其中M是Map的个数，R是Reduce的个数。\n* 其次Mapper产生的结果会根据设置的partition算法填充到每个bucket中去。这里的partition算法是可以自定义的，当然默认的算法是根据key哈希到不同的bucket中去。\n* 当Reducer启动时，它会根据自己task的id和所依赖的Mapper的id从远端或是本地的block manager中取得相应的bucket作为Reducer的输入进行处理。\n\n### Spark中Shuffle类型\n* Hash Shuffle：\n第一版是每个map产生r个文件，一共产生mr个文件，但是产生的中间文件太大影响扩展性。而后进行修改，让一个core上的map共用文件，减少文件数目，这样共产生core个文件，但中间文件数目仍随任务数线性增加，仍然难以对应大作业。\n* Sort Shuffle：\n每个map产生一个文件，彻底解决了扩展性问题\n\n\n本文只是对Shuffle作了初步的描述，了解基本概念\n\n\n### 问题\n今天遇到如下问题，特来了解一下。\n```\n17/02/06 11:50:21 ERROR Executor: Exception in task 0.0 in stage 857456.0 (TID 437542)\njava.io.FileNotFoundException: /tmp/spark-be115c66-a319-4931-a2ca-81ae9e7a6198/executor-54de96d2-5256-4637-b474-4342b00e755a/blockmgr-0c1c3d9f-c5d7-4b1c-bc12-7773083fa181/18/shuffle_426055_0_0.data.5874ce88-94f5-4c34-b56a-f729d4d4e393 (No such file or directory)\n     at java.io.FileOutputStream.open(Native Method)\n     at java.io.FileOutputStream.<init>(FileOutputStream.java:212)\n     at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.writePartitionedFile(BypassMergeSortShuffleWriter.java:182)\n     at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:159)\n     at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)\n     at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)\n     at org.apache.spark.scheduler.Task.run(Task.scala:85)\n     at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\n     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n     at java.lang.Thread.run(Thread.java:722)\n```\n一般造成此问题的是系统资源不够用\n参考网上的解决方案,修改启动参数：\n* 添加：--conf spark.shuffle.manager=SORT\n Spark默认的shuffle采用Hash模式，会产生相当规模的文件，与此同时带来了大量的内存开销\n* 是因为一个excutor给分配的内存不够，此时，减少excutor-core的数量，加大excutor-memory的值应该就没有问题。\n     \n\n\n参考：\nhttp://blog.jasonding.top/2015/07/14/Spark/【Spark】Spark的Shuffle机制/\nhttp://www.jianshu.com/p/c83bb237caa8\nhttps://github.com/JerryLead/SparkInternals/blob/master/markdown/4-shuffleDetails.md\n","source":"_posts/Spark-Shuffle基础.md","raw":"---\ntitle: Spark Shuffle基础\ndate: 2017-02-06 15:45:36\ntags: [spark]\ncategories: [spark]\n---\n### Shuffle 基本概念\n#### 概述：\n* Shuffle描述着数据从map task输出到reduce task 输入的这段过程。在分布式情况下，reduce task需要跨节点拉取其它节点上的map task结果。\n* 当Map的输出结果要被Reduce使用时，输出结果需要按key哈希，并且分发到每一个Reducer上去，这个过程就是shuffle。\n* 由于shuffle涉及到了磁盘的读写和网络的传输，因此shuffle性能的高低直接影响到了整个程序的运行效率。\n<!--more-->\n#### Spark 的Shuffle 分为 Write，Read 两阶段\n* Write 对应的是ShuffleMapTask，具体的写操作ExternalSorter来负责\n* Read 阶段由ShuffleRDD里的HashShuffleReader来完成。如果拉来的数据如果过大，需要落地，则也由ExternalSorter来完成的\n* 所有Write 写完后，才会执行Read。 他们被分成了两个不同的Stage阶段。\n\nShuffle Write ,Shuffle Read 两阶段都可能需要落磁盘，并且通过Disk Merge 来完成最后的Sort归并排序。\n\n### Spark的Shuffle机制\n> Spark中的Shuffle是把一组无规则的数据尽量转换成一组具有一定规则的数据。\n\nShuffle就是包裹在各种需要重分区的算子之下的一个对数据进行重新组合的过程。\nShuffle将数据进行收集分配到指定Reduce分区，Reduce阶段根据函数对相应的分区做Reduce所需的函数处理。\n\n\n### Shuffle的基本流程\n> bucket是一个抽象概念，在实现中每个bucket可以对应一个文件，可以对应文件的一部分或是其他等\n\n![shuffle-write-no-consolidation.png](http://upload-images.jianshu.io/upload_images/1419542-47813c3a4aeccf1e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n* 首先每一个Mapper会根据Reducer的数量创建出相应的bucket，bucket的数量是M×R，其中M是Map的个数，R是Reduce的个数。\n* 其次Mapper产生的结果会根据设置的partition算法填充到每个bucket中去。这里的partition算法是可以自定义的，当然默认的算法是根据key哈希到不同的bucket中去。\n* 当Reducer启动时，它会根据自己task的id和所依赖的Mapper的id从远端或是本地的block manager中取得相应的bucket作为Reducer的输入进行处理。\n\n### Spark中Shuffle类型\n* Hash Shuffle：\n第一版是每个map产生r个文件，一共产生mr个文件，但是产生的中间文件太大影响扩展性。而后进行修改，让一个core上的map共用文件，减少文件数目，这样共产生core个文件，但中间文件数目仍随任务数线性增加，仍然难以对应大作业。\n* Sort Shuffle：\n每个map产生一个文件，彻底解决了扩展性问题\n\n\n本文只是对Shuffle作了初步的描述，了解基本概念\n\n\n### 问题\n今天遇到如下问题，特来了解一下。\n```\n17/02/06 11:50:21 ERROR Executor: Exception in task 0.0 in stage 857456.0 (TID 437542)\njava.io.FileNotFoundException: /tmp/spark-be115c66-a319-4931-a2ca-81ae9e7a6198/executor-54de96d2-5256-4637-b474-4342b00e755a/blockmgr-0c1c3d9f-c5d7-4b1c-bc12-7773083fa181/18/shuffle_426055_0_0.data.5874ce88-94f5-4c34-b56a-f729d4d4e393 (No such file or directory)\n     at java.io.FileOutputStream.open(Native Method)\n     at java.io.FileOutputStream.<init>(FileOutputStream.java:212)\n     at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.writePartitionedFile(BypassMergeSortShuffleWriter.java:182)\n     at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:159)\n     at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)\n     at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)\n     at org.apache.spark.scheduler.Task.run(Task.scala:85)\n     at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\n     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n     at java.lang.Thread.run(Thread.java:722)\n```\n一般造成此问题的是系统资源不够用\n参考网上的解决方案,修改启动参数：\n* 添加：--conf spark.shuffle.manager=SORT\n Spark默认的shuffle采用Hash模式，会产生相当规模的文件，与此同时带来了大量的内存开销\n* 是因为一个excutor给分配的内存不够，此时，减少excutor-core的数量，加大excutor-memory的值应该就没有问题。\n     \n\n\n参考：\nhttp://blog.jasonding.top/2015/07/14/Spark/【Spark】Spark的Shuffle机制/\nhttp://www.jianshu.com/p/c83bb237caa8\nhttps://github.com/JerryLead/SparkInternals/blob/master/markdown/4-shuffleDetails.md\n","slug":"Spark-Shuffle基础","published":1,"updated":"2018-09-03T12:29:46.717Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmo9un31000d9q0vizz2jax0","content":"<h3 id=\"Shuffle-基本概念\"><a href=\"#Shuffle-基本概念\" class=\"headerlink\" title=\"Shuffle 基本概念\"></a>Shuffle 基本概念</h3><h4 id=\"概述：\"><a href=\"#概述：\" class=\"headerlink\" title=\"概述：\"></a>概述：</h4><ul>\n<li>Shuffle描述着数据从map task输出到reduce task 输入的这段过程。在分布式情况下，reduce task需要跨节点拉取其它节点上的map task结果。</li>\n<li>当Map的输出结果要被Reduce使用时，输出结果需要按key哈希，并且分发到每一个Reducer上去，这个过程就是shuffle。</li>\n<li>由于shuffle涉及到了磁盘的读写和网络的传输，因此shuffle性能的高低直接影响到了整个程序的运行效率。<a id=\"more\"></a>\n<h4 id=\"Spark-的Shuffle-分为-Write，Read-两阶段\"><a href=\"#Spark-的Shuffle-分为-Write，Read-两阶段\" class=\"headerlink\" title=\"Spark 的Shuffle 分为 Write，Read 两阶段\"></a>Spark 的Shuffle 分为 Write，Read 两阶段</h4></li>\n<li>Write 对应的是ShuffleMapTask，具体的写操作ExternalSorter来负责</li>\n<li>Read 阶段由ShuffleRDD里的HashShuffleReader来完成。如果拉来的数据如果过大，需要落地，则也由ExternalSorter来完成的</li>\n<li>所有Write 写完后，才会执行Read。 他们被分成了两个不同的Stage阶段。</li>\n</ul>\n<p>Shuffle Write ,Shuffle Read 两阶段都可能需要落磁盘，并且通过Disk Merge 来完成最后的Sort归并排序。</p>\n<h3 id=\"Spark的Shuffle机制\"><a href=\"#Spark的Shuffle机制\" class=\"headerlink\" title=\"Spark的Shuffle机制\"></a>Spark的Shuffle机制</h3><blockquote>\n<p>Spark中的Shuffle是把一组无规则的数据尽量转换成一组具有一定规则的数据。</p>\n</blockquote>\n<p>Shuffle就是包裹在各种需要重分区的算子之下的一个对数据进行重新组合的过程。<br>Shuffle将数据进行收集分配到指定Reduce分区，Reduce阶段根据函数对相应的分区做Reduce所需的函数处理。</p>\n<h3 id=\"Shuffle的基本流程\"><a href=\"#Shuffle的基本流程\" class=\"headerlink\" title=\"Shuffle的基本流程\"></a>Shuffle的基本流程</h3><blockquote>\n<p>bucket是一个抽象概念，在实现中每个bucket可以对应一个文件，可以对应文件的一部分或是其他等</p>\n</blockquote>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-47813c3a4aeccf1e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"shuffle-write-no-consolidation.png\"></p>\n<ul>\n<li>首先每一个Mapper会根据Reducer的数量创建出相应的bucket，bucket的数量是M×R，其中M是Map的个数，R是Reduce的个数。</li>\n<li>其次Mapper产生的结果会根据设置的partition算法填充到每个bucket中去。这里的partition算法是可以自定义的，当然默认的算法是根据key哈希到不同的bucket中去。</li>\n<li>当Reducer启动时，它会根据自己task的id和所依赖的Mapper的id从远端或是本地的block manager中取得相应的bucket作为Reducer的输入进行处理。</li>\n</ul>\n<h3 id=\"Spark中Shuffle类型\"><a href=\"#Spark中Shuffle类型\" class=\"headerlink\" title=\"Spark中Shuffle类型\"></a>Spark中Shuffle类型</h3><ul>\n<li>Hash Shuffle：<br>第一版是每个map产生r个文件，一共产生mr个文件，但是产生的中间文件太大影响扩展性。而后进行修改，让一个core上的map共用文件，减少文件数目，这样共产生core个文件，但中间文件数目仍随任务数线性增加，仍然难以对应大作业。</li>\n<li>Sort Shuffle：<br>每个map产生一个文件，彻底解决了扩展性问题</li>\n</ul>\n<p>本文只是对Shuffle作了初步的描述，了解基本概念</p>\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><p>今天遇到如下问题，特来了解一下。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">17/02/06 11:50:21 ERROR Executor: Exception in task 0.0 in stage 857456.0 (TID 437542)</span><br><span class=\"line\">java.io.FileNotFoundException: /tmp/spark-be115c66-a319-4931-a2ca-81ae9e7a6198/executor-54de96d2-5256-4637-b474-4342b00e755a/blockmgr-0c1c3d9f-c5d7-4b1c-bc12-7773083fa181/18/shuffle_426055_0_0.data.5874ce88-94f5-4c34-b56a-f729d4d4e393 (No such file or directory)</span><br><span class=\"line\">     at java.io.FileOutputStream.open(Native Method)</span><br><span class=\"line\">     at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:212)</span><br><span class=\"line\">     at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.writePartitionedFile(BypassMergeSortShuffleWriter.java:182)</span><br><span class=\"line\">     at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:159)</span><br><span class=\"line\">     at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)</span><br><span class=\"line\">     at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)</span><br><span class=\"line\">     at org.apache.spark.scheduler.Task.run(Task.scala:85)</span><br><span class=\"line\">     at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)</span><br><span class=\"line\">     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)</span><br><span class=\"line\">     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)</span><br><span class=\"line\">     at java.lang.Thread.run(Thread.java:722)</span><br></pre></td></tr></table></figure></p>\n<p>一般造成此问题的是系统资源不够用<br>参考网上的解决方案,修改启动参数：</p>\n<ul>\n<li>添加：–conf spark.shuffle.manager=SORT<br>Spark默认的shuffle采用Hash模式，会产生相当规模的文件，与此同时带来了大量的内存开销</li>\n<li>是因为一个excutor给分配的内存不够，此时，减少excutor-core的数量，加大excutor-memory的值应该就没有问题。</li>\n</ul>\n<p>参考：<br><a href=\"http://blog.jasonding.top/2015/07/14/Spark/【Spark】Spark的Shuffle机制/\" target=\"_blank\" rel=\"noopener\">http://blog.jasonding.top/2015/07/14/Spark/【Spark】Spark的Shuffle机制/</a><br><a href=\"http://www.jianshu.com/p/c83bb237caa8\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/c83bb237caa8</a><br><a href=\"https://github.com/JerryLead/SparkInternals/blob/master/markdown/4-shuffleDetails.md\" target=\"_blank\" rel=\"noopener\">https://github.com/JerryLead/SparkInternals/blob/master/markdown/4-shuffleDetails.md</a></p>\n","site":{"data":{}},"excerpt":"<h3 id=\"Shuffle-基本概念\"><a href=\"#Shuffle-基本概念\" class=\"headerlink\" title=\"Shuffle 基本概念\"></a>Shuffle 基本概念</h3><h4 id=\"概述：\"><a href=\"#概述：\" class=\"headerlink\" title=\"概述：\"></a>概述：</h4><ul>\n<li>Shuffle描述着数据从map task输出到reduce task 输入的这段过程。在分布式情况下，reduce task需要跨节点拉取其它节点上的map task结果。</li>\n<li>当Map的输出结果要被Reduce使用时，输出结果需要按key哈希，并且分发到每一个Reducer上去，这个过程就是shuffle。</li>\n<li>由于shuffle涉及到了磁盘的读写和网络的传输，因此shuffle性能的高低直接影响到了整个程序的运行效率。","more":"<h4 id=\"Spark-的Shuffle-分为-Write，Read-两阶段\"><a href=\"#Spark-的Shuffle-分为-Write，Read-两阶段\" class=\"headerlink\" title=\"Spark 的Shuffle 分为 Write，Read 两阶段\"></a>Spark 的Shuffle 分为 Write，Read 两阶段</h4></li>\n<li>Write 对应的是ShuffleMapTask，具体的写操作ExternalSorter来负责</li>\n<li>Read 阶段由ShuffleRDD里的HashShuffleReader来完成。如果拉来的数据如果过大，需要落地，则也由ExternalSorter来完成的</li>\n<li>所有Write 写完后，才会执行Read。 他们被分成了两个不同的Stage阶段。</li>\n</ul>\n<p>Shuffle Write ,Shuffle Read 两阶段都可能需要落磁盘，并且通过Disk Merge 来完成最后的Sort归并排序。</p>\n<h3 id=\"Spark的Shuffle机制\"><a href=\"#Spark的Shuffle机制\" class=\"headerlink\" title=\"Spark的Shuffle机制\"></a>Spark的Shuffle机制</h3><blockquote>\n<p>Spark中的Shuffle是把一组无规则的数据尽量转换成一组具有一定规则的数据。</p>\n</blockquote>\n<p>Shuffle就是包裹在各种需要重分区的算子之下的一个对数据进行重新组合的过程。<br>Shuffle将数据进行收集分配到指定Reduce分区，Reduce阶段根据函数对相应的分区做Reduce所需的函数处理。</p>\n<h3 id=\"Shuffle的基本流程\"><a href=\"#Shuffle的基本流程\" class=\"headerlink\" title=\"Shuffle的基本流程\"></a>Shuffle的基本流程</h3><blockquote>\n<p>bucket是一个抽象概念，在实现中每个bucket可以对应一个文件，可以对应文件的一部分或是其他等</p>\n</blockquote>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-47813c3a4aeccf1e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"shuffle-write-no-consolidation.png\"></p>\n<ul>\n<li>首先每一个Mapper会根据Reducer的数量创建出相应的bucket，bucket的数量是M×R，其中M是Map的个数，R是Reduce的个数。</li>\n<li>其次Mapper产生的结果会根据设置的partition算法填充到每个bucket中去。这里的partition算法是可以自定义的，当然默认的算法是根据key哈希到不同的bucket中去。</li>\n<li>当Reducer启动时，它会根据自己task的id和所依赖的Mapper的id从远端或是本地的block manager中取得相应的bucket作为Reducer的输入进行处理。</li>\n</ul>\n<h3 id=\"Spark中Shuffle类型\"><a href=\"#Spark中Shuffle类型\" class=\"headerlink\" title=\"Spark中Shuffle类型\"></a>Spark中Shuffle类型</h3><ul>\n<li>Hash Shuffle：<br>第一版是每个map产生r个文件，一共产生mr个文件，但是产生的中间文件太大影响扩展性。而后进行修改，让一个core上的map共用文件，减少文件数目，这样共产生core个文件，但中间文件数目仍随任务数线性增加，仍然难以对应大作业。</li>\n<li>Sort Shuffle：<br>每个map产生一个文件，彻底解决了扩展性问题</li>\n</ul>\n<p>本文只是对Shuffle作了初步的描述，了解基本概念</p>\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><p>今天遇到如下问题，特来了解一下。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">17/02/06 11:50:21 ERROR Executor: Exception in task 0.0 in stage 857456.0 (TID 437542)</span><br><span class=\"line\">java.io.FileNotFoundException: /tmp/spark-be115c66-a319-4931-a2ca-81ae9e7a6198/executor-54de96d2-5256-4637-b474-4342b00e755a/blockmgr-0c1c3d9f-c5d7-4b1c-bc12-7773083fa181/18/shuffle_426055_0_0.data.5874ce88-94f5-4c34-b56a-f729d4d4e393 (No such file or directory)</span><br><span class=\"line\">     at java.io.FileOutputStream.open(Native Method)</span><br><span class=\"line\">     at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:212)</span><br><span class=\"line\">     at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.writePartitionedFile(BypassMergeSortShuffleWriter.java:182)</span><br><span class=\"line\">     at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:159)</span><br><span class=\"line\">     at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)</span><br><span class=\"line\">     at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)</span><br><span class=\"line\">     at org.apache.spark.scheduler.Task.run(Task.scala:85)</span><br><span class=\"line\">     at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)</span><br><span class=\"line\">     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)</span><br><span class=\"line\">     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)</span><br><span class=\"line\">     at java.lang.Thread.run(Thread.java:722)</span><br></pre></td></tr></table></figure></p>\n<p>一般造成此问题的是系统资源不够用<br>参考网上的解决方案,修改启动参数：</p>\n<ul>\n<li>添加：–conf spark.shuffle.manager=SORT<br>Spark默认的shuffle采用Hash模式，会产生相当规模的文件，与此同时带来了大量的内存开销</li>\n<li>是因为一个excutor给分配的内存不够，此时，减少excutor-core的数量，加大excutor-memory的值应该就没有问题。</li>\n</ul>\n<p>参考：<br><a href=\"http://blog.jasonding.top/2015/07/14/Spark/【Spark】Spark的Shuffle机制/\" target=\"_blank\" rel=\"noopener\">http://blog.jasonding.top/2015/07/14/Spark/【Spark】Spark的Shuffle机制/</a><br><a href=\"http://www.jianshu.com/p/c83bb237caa8\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/c83bb237caa8</a><br><a href=\"https://github.com/JerryLead/SparkInternals/blob/master/markdown/4-shuffleDetails.md\" target=\"_blank\" rel=\"noopener\">https://github.com/JerryLead/SparkInternals/blob/master/markdown/4-shuffleDetails.md</a></p>"},{"title":"SparkStream 函数详解-Transformations","date":"2017-02-05T12:36:59.000Z","_content":"一个DStream对象可以调用多种操作，主要分为如下几类：\n* Transformations\n* Window Operations\n* Join Operations\n* Output Operations\n\n### Transformations\n#### map(func)\n> Return a new DStream by passing each element of the source DStream through a function func.\n\n主要作用是，对DStream对象a，将func函数作用到a中的每一个元素上并生成新的元素，得到的DStream对象b中包含这些新的元素。\n```\n//拼接一个”_NEW”字符串\nval linesNew = lines.map(lines => lines + \"_NEW\" )\n```\nmap中操作复杂可把函数抽出来在外部定义：\n```\n    val mapResult = stream.map(new Transformations().customeMap(_))\n\n    def customeMap(word: String): String = {\n        word + \"ss\"\n    }\n```\n\n#### filter(func)\n> Return a new DStream by selecting only the records of the source DStream on which func returns true.\n\n对DStream a中的每一个元素，应用func方法进行计算，如果func函数返回结果为true，则保留该元素，否则丢弃该元素，返回一个新的DStream b。\n```\nval filterWords = words.filter(_ != \"hello\" )\n```\n在定义函数式时，返回值必须是boolean类型，\n\n#### flatMap(func)\n> Similar to map, but each input item can be mapped to 0 or more output items.\n\n主要作用是，对DStream对象a，将func函数作用到a中的每一个元素上并生成0个或多个新的元素，得到的DStream对象b中包含这些新的元素。\n```\n//将lines根据空格进行分割，分割成若干个单词\nval words = lines.flatMap(_.split( \" \" ))\n```\n同map若函数复杂可提出去\n\n#### union(otherStream)\n> Return a new DStream that contains the union of the elements in the source DStream and otherDStream.\n\n这个操作将两个DStream进行合并，生成一个包含着两个DStream中所有元素的新DStream对象。\n```\nval wordsOne = words.map(_ + \"_one\" )\nval wordsTwo = words.map(_ + \"_two\" )\nval unionWords = wordsOne.union(wordsTwo)\n```\n输入 hello yany tian，结果是将wordsOne和wordsTwo合成一个unionWords的DStream\n\n```\nhello_one\nyany_one\ntian_one\nhello_two\nyany_two\ntian_two\n```\n\n#### repartition(numPartitions)\n> Changes the level of parallelism in this DStream by creating more or fewer partitions.\n\nReturn a new DStream with an increased or decreased level of parallelism. Each RDD in the returned DStream has exactly numPartitions partitions.\n\n#### count()\n> Return a new DStream of single-element RDDs by counting the number of elements in each RDD of the source DStream.\n\n统计DStream中每个RDD包含的元素的个数，得到一个新的DStream，这个DStream中只包含一个元素，这个元素是对应语句单词统计数值。\n```\nval wordsCount = words.count()\n```\n\n#### reduce(func)\n> Return a new DStream of single-element RDDs by aggregating the elements in each RDD of the source DStream using a function func (which takes two arguments and returns one). The function should be associative and commutative so that it can be computed in parallel.\n\n返回一个包含一个元素的DStream，传入的func方法会作用在调用者的每一个元素上，将其中的元素顺次的两两进行计算。\n```\nval reduceWords = words.reduce(_ + \"-\" + _)\n// 或\n\ndef customerReduce(line1: String, line2: String): String = {\n    line1 + \"|||\" + line2\n  }\n // val reduceResult = flatMapResult.reduce(new Transformations().customerReduce(_, _));\n    val reduceResult = flatMapResult.reduce((x, y) => new Transformations().customerReduce(x, y));\n```\n\n#### countByValue()\n> When called on a DStream of elements of type K, return a new DStream of (K, Long) pairs where the value of each key is its frequency in each RDD of the source DStream.\n\n某个DStream中的元素类型为K，调用这个方法后，返回的DStream的元素为(K, Long)对，后面这个Long值是原DStream中每个RDD元素key出现的频率。\n```\nval countByValueWords = words.countByValue()\n```\n\n#### reduceByKey(func, [numTasks])\n> When called on a DStream of (K, V) pairs, return a new DStream of (K, V) pairs where the values for each key are aggregated using the given reduce function. Note: By default, this uses Spark's default number of parallel tasks (2 for local mode, and in cluster mode the number is determined by the config property spark.default.parallelism) to do the grouping. You can pass an optional numTasks argument to set a different number of tasks.\n\n调用这个操作的DStream是以(K, V)的形式出现，返回一个新的元素格式为(K, V)的DStream。返回结果中，K为原来的K，V是由K经过传入func计算得到的。还可以传入一个并行计算的参数，在local模式下，默认为2。在其他模式下，默认值由参数 spark.default.parallelism 确定。\n\n注：reduceByKey使用时DStream需要以(K, V)的形式出现\n```\nval pairs = words.map(word => (word , 1))\nval wordCounts = pairs.reduceByKey(_ + _)\n//===========\n/**\n    * \n    * reducebykey 通过对于两两的value进行操作,可自定义\n    * @param line1\n    * @param line2\n    * @return\n    */\n  def customerReduceByKey(line1: String, line2: String): String = {\n    \"ss\"\n  }\n    val reduceByKeyResult = flatMapResult.map((_, \"ss\")).reduceByKey(new Transformations().customerReduceByKey(_, _))\n```\n\n#### join(otherStream, [numTasks])\n> When called on two DStreams of (K, V) and (K, W) pairs, return a new DStream of (K, (V, W)) pairs with all pairs of elements for each key.\n\n由一个DStream对象调用该方法，元素内容为 (k, V) ，传入另一个DStream对象，元素内容为(k, W)，返回的DStream中包含的内容是 (k, (V, W)) 。这个方法也可以传入一个并行计算的参数，该参数与reduceByKey中是相同的。\n```\nval wordsOne = words.map(word => (word , word + \"_one\" ))\nval wordsTwo = words.map(word => (word , word + \"_two\" ))\nval joinWords = wordsOne.join(wordsTwo)\n\n```\n结果\n```\n// 输入 hello world hello join\n\n(hello,(hello_one,hello_two))\n(hello,(hello_one,hello_two))\n(hello,(hello_one,hello_two))\n(hello,(hello_one,hello_two))\n(join,(join_one,join_two))\n(world,(world_one,world_two))\n```\n如果key相同，出现笛卡尔积现象\n\n#### cogroup(otherStream, [numTasks])\n> When called on a DStream of (K, V) and (K, W) pairs, return a new DStream of (K, Seq[V], Seq[W]) tuples.\n\n由一个DStream对象调用该方法，元素内容为(k, V)，传入另一个DStream对象，元素内容为(k, W)，返回的DStream中包含的内容是 (k, (Seq[V], Seq[W])) 。这个方法也可以传入一个并行计算的参数，该参数与reduceByKey中是相同的。\n\n```\nval wordsOne = words.map(word => (word , word + \"_one\" ))\nval wordsTwo = words.map(word => (word , word + \"_two\" ))\nval joinWords = wordsOne.cogroup(wordsTwo)\n```\n\n结果：\n```\n// 输入 hello world hello cogroup\n\n(hello,(CompactBuffer(hello_one, hello_one),CompactBuffer(hello_two, hello_two)))\n(world,(CompactBuffer(world_one),CompactBuffer(world_two)))\n(cogroup,(CompactBuffer(cogroup_one),CompactBuffer(cogroup_two)))\n```\n\n#### transform(func)\n#### updateStateByKey(func)\n\n\n参考：\nhttp://blog.csdn.net/dabokele/article/details/52602412?utm_source=tuicool&utm_medium=referral\n\n博客：http://yany8060.xyz/\ngithup: https://github.com/yany8060/SparkDemo","source":"_posts/SparkStream-函数详解-Transformations.md","raw":"---\ntitle: SparkStream 函数详解-Transformations\ndate: 2017-02-05 20:36:59\ntags: [sparkstream,spark]\ncategories: [spark]\n---\n一个DStream对象可以调用多种操作，主要分为如下几类：\n* Transformations\n* Window Operations\n* Join Operations\n* Output Operations\n\n### Transformations\n#### map(func)\n> Return a new DStream by passing each element of the source DStream through a function func.\n\n主要作用是，对DStream对象a，将func函数作用到a中的每一个元素上并生成新的元素，得到的DStream对象b中包含这些新的元素。\n```\n//拼接一个”_NEW”字符串\nval linesNew = lines.map(lines => lines + \"_NEW\" )\n```\nmap中操作复杂可把函数抽出来在外部定义：\n```\n    val mapResult = stream.map(new Transformations().customeMap(_))\n\n    def customeMap(word: String): String = {\n        word + \"ss\"\n    }\n```\n\n#### filter(func)\n> Return a new DStream by selecting only the records of the source DStream on which func returns true.\n\n对DStream a中的每一个元素，应用func方法进行计算，如果func函数返回结果为true，则保留该元素，否则丢弃该元素，返回一个新的DStream b。\n```\nval filterWords = words.filter(_ != \"hello\" )\n```\n在定义函数式时，返回值必须是boolean类型，\n\n#### flatMap(func)\n> Similar to map, but each input item can be mapped to 0 or more output items.\n\n主要作用是，对DStream对象a，将func函数作用到a中的每一个元素上并生成0个或多个新的元素，得到的DStream对象b中包含这些新的元素。\n```\n//将lines根据空格进行分割，分割成若干个单词\nval words = lines.flatMap(_.split( \" \" ))\n```\n同map若函数复杂可提出去\n\n#### union(otherStream)\n> Return a new DStream that contains the union of the elements in the source DStream and otherDStream.\n\n这个操作将两个DStream进行合并，生成一个包含着两个DStream中所有元素的新DStream对象。\n```\nval wordsOne = words.map(_ + \"_one\" )\nval wordsTwo = words.map(_ + \"_two\" )\nval unionWords = wordsOne.union(wordsTwo)\n```\n输入 hello yany tian，结果是将wordsOne和wordsTwo合成一个unionWords的DStream\n\n```\nhello_one\nyany_one\ntian_one\nhello_two\nyany_two\ntian_two\n```\n\n#### repartition(numPartitions)\n> Changes the level of parallelism in this DStream by creating more or fewer partitions.\n\nReturn a new DStream with an increased or decreased level of parallelism. Each RDD in the returned DStream has exactly numPartitions partitions.\n\n#### count()\n> Return a new DStream of single-element RDDs by counting the number of elements in each RDD of the source DStream.\n\n统计DStream中每个RDD包含的元素的个数，得到一个新的DStream，这个DStream中只包含一个元素，这个元素是对应语句单词统计数值。\n```\nval wordsCount = words.count()\n```\n\n#### reduce(func)\n> Return a new DStream of single-element RDDs by aggregating the elements in each RDD of the source DStream using a function func (which takes two arguments and returns one). The function should be associative and commutative so that it can be computed in parallel.\n\n返回一个包含一个元素的DStream，传入的func方法会作用在调用者的每一个元素上，将其中的元素顺次的两两进行计算。\n```\nval reduceWords = words.reduce(_ + \"-\" + _)\n// 或\n\ndef customerReduce(line1: String, line2: String): String = {\n    line1 + \"|||\" + line2\n  }\n // val reduceResult = flatMapResult.reduce(new Transformations().customerReduce(_, _));\n    val reduceResult = flatMapResult.reduce((x, y) => new Transformations().customerReduce(x, y));\n```\n\n#### countByValue()\n> When called on a DStream of elements of type K, return a new DStream of (K, Long) pairs where the value of each key is its frequency in each RDD of the source DStream.\n\n某个DStream中的元素类型为K，调用这个方法后，返回的DStream的元素为(K, Long)对，后面这个Long值是原DStream中每个RDD元素key出现的频率。\n```\nval countByValueWords = words.countByValue()\n```\n\n#### reduceByKey(func, [numTasks])\n> When called on a DStream of (K, V) pairs, return a new DStream of (K, V) pairs where the values for each key are aggregated using the given reduce function. Note: By default, this uses Spark's default number of parallel tasks (2 for local mode, and in cluster mode the number is determined by the config property spark.default.parallelism) to do the grouping. You can pass an optional numTasks argument to set a different number of tasks.\n\n调用这个操作的DStream是以(K, V)的形式出现，返回一个新的元素格式为(K, V)的DStream。返回结果中，K为原来的K，V是由K经过传入func计算得到的。还可以传入一个并行计算的参数，在local模式下，默认为2。在其他模式下，默认值由参数 spark.default.parallelism 确定。\n\n注：reduceByKey使用时DStream需要以(K, V)的形式出现\n```\nval pairs = words.map(word => (word , 1))\nval wordCounts = pairs.reduceByKey(_ + _)\n//===========\n/**\n    * \n    * reducebykey 通过对于两两的value进行操作,可自定义\n    * @param line1\n    * @param line2\n    * @return\n    */\n  def customerReduceByKey(line1: String, line2: String): String = {\n    \"ss\"\n  }\n    val reduceByKeyResult = flatMapResult.map((_, \"ss\")).reduceByKey(new Transformations().customerReduceByKey(_, _))\n```\n\n#### join(otherStream, [numTasks])\n> When called on two DStreams of (K, V) and (K, W) pairs, return a new DStream of (K, (V, W)) pairs with all pairs of elements for each key.\n\n由一个DStream对象调用该方法，元素内容为 (k, V) ，传入另一个DStream对象，元素内容为(k, W)，返回的DStream中包含的内容是 (k, (V, W)) 。这个方法也可以传入一个并行计算的参数，该参数与reduceByKey中是相同的。\n```\nval wordsOne = words.map(word => (word , word + \"_one\" ))\nval wordsTwo = words.map(word => (word , word + \"_two\" ))\nval joinWords = wordsOne.join(wordsTwo)\n\n```\n结果\n```\n// 输入 hello world hello join\n\n(hello,(hello_one,hello_two))\n(hello,(hello_one,hello_two))\n(hello,(hello_one,hello_two))\n(hello,(hello_one,hello_two))\n(join,(join_one,join_two))\n(world,(world_one,world_two))\n```\n如果key相同，出现笛卡尔积现象\n\n#### cogroup(otherStream, [numTasks])\n> When called on a DStream of (K, V) and (K, W) pairs, return a new DStream of (K, Seq[V], Seq[W]) tuples.\n\n由一个DStream对象调用该方法，元素内容为(k, V)，传入另一个DStream对象，元素内容为(k, W)，返回的DStream中包含的内容是 (k, (Seq[V], Seq[W])) 。这个方法也可以传入一个并行计算的参数，该参数与reduceByKey中是相同的。\n\n```\nval wordsOne = words.map(word => (word , word + \"_one\" ))\nval wordsTwo = words.map(word => (word , word + \"_two\" ))\nval joinWords = wordsOne.cogroup(wordsTwo)\n```\n\n结果：\n```\n// 输入 hello world hello cogroup\n\n(hello,(CompactBuffer(hello_one, hello_one),CompactBuffer(hello_two, hello_two)))\n(world,(CompactBuffer(world_one),CompactBuffer(world_two)))\n(cogroup,(CompactBuffer(cogroup_one),CompactBuffer(cogroup_two)))\n```\n\n#### transform(func)\n#### updateStateByKey(func)\n\n\n参考：\nhttp://blog.csdn.net/dabokele/article/details/52602412?utm_source=tuicool&utm_medium=referral\n\n博客：http://yany8060.xyz/\ngithup: https://github.com/yany8060/SparkDemo","slug":"SparkStream-函数详解-Transformations","published":1,"updated":"2018-09-03T12:29:46.718Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmo9un34000i9q0ve480517c","content":"<p>一个DStream对象可以调用多种操作，主要分为如下几类：</p>\n<ul>\n<li>Transformations</li>\n<li>Window Operations</li>\n<li>Join Operations</li>\n<li>Output Operations</li>\n</ul>\n<h3 id=\"Transformations\"><a href=\"#Transformations\" class=\"headerlink\" title=\"Transformations\"></a>Transformations</h3><h4 id=\"map-func\"><a href=\"#map-func\" class=\"headerlink\" title=\"map(func)\"></a>map(func)</h4><blockquote>\n<p>Return a new DStream by passing each element of the source DStream through a function func.</p>\n</blockquote>\n<p>主要作用是，对DStream对象a，将func函数作用到a中的每一个元素上并生成新的元素，得到的DStream对象b中包含这些新的元素。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//拼接一个”_NEW”字符串</span><br><span class=\"line\">val linesNew = lines.map(lines =&gt; lines + &quot;_NEW&quot; )</span><br></pre></td></tr></table></figure></p>\n<p>map中操作复杂可把函数抽出来在外部定义：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val mapResult = stream.map(new Transformations().customeMap(_))</span><br><span class=\"line\"></span><br><span class=\"line\">def customeMap(word: String): String = &#123;</span><br><span class=\"line\">    word + &quot;ss&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"filter-func\"><a href=\"#filter-func\" class=\"headerlink\" title=\"filter(func)\"></a>filter(func)</h4><blockquote>\n<p>Return a new DStream by selecting only the records of the source DStream on which func returns true.</p>\n</blockquote>\n<p>对DStream a中的每一个元素，应用func方法进行计算，如果func函数返回结果为true，则保留该元素，否则丢弃该元素，返回一个新的DStream b。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val filterWords = words.filter(_ != &quot;hello&quot; )</span><br></pre></td></tr></table></figure></p>\n<p>在定义函数式时，返回值必须是boolean类型，</p>\n<h4 id=\"flatMap-func\"><a href=\"#flatMap-func\" class=\"headerlink\" title=\"flatMap(func)\"></a>flatMap(func)</h4><blockquote>\n<p>Similar to map, but each input item can be mapped to 0 or more output items.</p>\n</blockquote>\n<p>主要作用是，对DStream对象a，将func函数作用到a中的每一个元素上并生成0个或多个新的元素，得到的DStream对象b中包含这些新的元素。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//将lines根据空格进行分割，分割成若干个单词</span><br><span class=\"line\">val words = lines.flatMap(_.split( &quot; &quot; ))</span><br></pre></td></tr></table></figure></p>\n<p>同map若函数复杂可提出去</p>\n<h4 id=\"union-otherStream\"><a href=\"#union-otherStream\" class=\"headerlink\" title=\"union(otherStream)\"></a>union(otherStream)</h4><blockquote>\n<p>Return a new DStream that contains the union of the elements in the source DStream and otherDStream.</p>\n</blockquote>\n<p>这个操作将两个DStream进行合并，生成一个包含着两个DStream中所有元素的新DStream对象。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val wordsOne = words.map(_ + &quot;_one&quot; )</span><br><span class=\"line\">val wordsTwo = words.map(_ + &quot;_two&quot; )</span><br><span class=\"line\">val unionWords = wordsOne.union(wordsTwo)</span><br></pre></td></tr></table></figure></p>\n<p>输入 hello yany tian，结果是将wordsOne和wordsTwo合成一个unionWords的DStream</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hello_one</span><br><span class=\"line\">yany_one</span><br><span class=\"line\">tian_one</span><br><span class=\"line\">hello_two</span><br><span class=\"line\">yany_two</span><br><span class=\"line\">tian_two</span><br></pre></td></tr></table></figure>\n<h4 id=\"repartition-numPartitions\"><a href=\"#repartition-numPartitions\" class=\"headerlink\" title=\"repartition(numPartitions)\"></a>repartition(numPartitions)</h4><blockquote>\n<p>Changes the level of parallelism in this DStream by creating more or fewer partitions.</p>\n</blockquote>\n<p>Return a new DStream with an increased or decreased level of parallelism. Each RDD in the returned DStream has exactly numPartitions partitions.</p>\n<h4 id=\"count\"><a href=\"#count\" class=\"headerlink\" title=\"count()\"></a>count()</h4><blockquote>\n<p>Return a new DStream of single-element RDDs by counting the number of elements in each RDD of the source DStream.</p>\n</blockquote>\n<p>统计DStream中每个RDD包含的元素的个数，得到一个新的DStream，这个DStream中只包含一个元素，这个元素是对应语句单词统计数值。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val wordsCount = words.count()</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"reduce-func\"><a href=\"#reduce-func\" class=\"headerlink\" title=\"reduce(func)\"></a>reduce(func)</h4><blockquote>\n<p>Return a new DStream of single-element RDDs by aggregating the elements in each RDD of the source DStream using a function func (which takes two arguments and returns one). The function should be associative and commutative so that it can be computed in parallel.</p>\n</blockquote>\n<p>返回一个包含一个元素的DStream，传入的func方法会作用在调用者的每一个元素上，将其中的元素顺次的两两进行计算。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val reduceWords = words.reduce(_ + &quot;-&quot; + _)</span><br><span class=\"line\">// 或</span><br><span class=\"line\"></span><br><span class=\"line\">def customerReduce(line1: String, line2: String): String = &#123;</span><br><span class=\"line\">    line1 + &quot;|||&quot; + line2</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"> // val reduceResult = flatMapResult.reduce(new Transformations().customerReduce(_, _));</span><br><span class=\"line\">    val reduceResult = flatMapResult.reduce((x, y) =&gt; new Transformations().customerReduce(x, y));</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"countByValue\"><a href=\"#countByValue\" class=\"headerlink\" title=\"countByValue()\"></a>countByValue()</h4><blockquote>\n<p>When called on a DStream of elements of type K, return a new DStream of (K, Long) pairs where the value of each key is its frequency in each RDD of the source DStream.</p>\n</blockquote>\n<p>某个DStream中的元素类型为K，调用这个方法后，返回的DStream的元素为(K, Long)对，后面这个Long值是原DStream中每个RDD元素key出现的频率。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val countByValueWords = words.countByValue()</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"reduceByKey-func-numTasks\"><a href=\"#reduceByKey-func-numTasks\" class=\"headerlink\" title=\"reduceByKey(func, [numTasks])\"></a>reduceByKey(func, [numTasks])</h4><blockquote>\n<p>When called on a DStream of (K, V) pairs, return a new DStream of (K, V) pairs where the values for each key are aggregated using the given reduce function. Note: By default, this uses Spark’s default number of parallel tasks (2 for local mode, and in cluster mode the number is determined by the config property spark.default.parallelism) to do the grouping. You can pass an optional numTasks argument to set a different number of tasks.</p>\n</blockquote>\n<p>调用这个操作的DStream是以(K, V)的形式出现，返回一个新的元素格式为(K, V)的DStream。返回结果中，K为原来的K，V是由K经过传入func计算得到的。还可以传入一个并行计算的参数，在local模式下，默认为2。在其他模式下，默认值由参数 spark.default.parallelism 确定。</p>\n<p>注：reduceByKey使用时DStream需要以(K, V)的形式出现<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val pairs = words.map(word =&gt; (word , 1))</span><br><span class=\"line\">val wordCounts = pairs.reduceByKey(_ + _)</span><br><span class=\"line\">//===========</span><br><span class=\"line\">/**</span><br><span class=\"line\">    * </span><br><span class=\"line\">    * reducebykey 通过对于两两的value进行操作,可自定义</span><br><span class=\"line\">    * @param line1</span><br><span class=\"line\">    * @param line2</span><br><span class=\"line\">    * @return</span><br><span class=\"line\">    */</span><br><span class=\"line\">  def customerReduceByKey(line1: String, line2: String): String = &#123;</span><br><span class=\"line\">    &quot;ss&quot;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">    val reduceByKeyResult = flatMapResult.map((_, &quot;ss&quot;)).reduceByKey(new Transformations().customerReduceByKey(_, _))</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"join-otherStream-numTasks\"><a href=\"#join-otherStream-numTasks\" class=\"headerlink\" title=\"join(otherStream, [numTasks])\"></a>join(otherStream, [numTasks])</h4><blockquote>\n<p>When called on two DStreams of (K, V) and (K, W) pairs, return a new DStream of (K, (V, W)) pairs with all pairs of elements for each key.</p>\n</blockquote>\n<p>由一个DStream对象调用该方法，元素内容为 (k, V) ，传入另一个DStream对象，元素内容为(k, W)，返回的DStream中包含的内容是 (k, (V, W)) 。这个方法也可以传入一个并行计算的参数，该参数与reduceByKey中是相同的。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val wordsOne = words.map(word =&gt; (word , word + &quot;_one&quot; ))</span><br><span class=\"line\">val wordsTwo = words.map(word =&gt; (word , word + &quot;_two&quot; ))</span><br><span class=\"line\">val joinWords = wordsOne.join(wordsTwo)</span><br></pre></td></tr></table></figure></p>\n<p>结果<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 输入 hello world hello join</span><br><span class=\"line\"></span><br><span class=\"line\">(hello,(hello_one,hello_two))</span><br><span class=\"line\">(hello,(hello_one,hello_two))</span><br><span class=\"line\">(hello,(hello_one,hello_two))</span><br><span class=\"line\">(hello,(hello_one,hello_two))</span><br><span class=\"line\">(join,(join_one,join_two))</span><br><span class=\"line\">(world,(world_one,world_two))</span><br></pre></td></tr></table></figure></p>\n<p>如果key相同，出现笛卡尔积现象</p>\n<h4 id=\"cogroup-otherStream-numTasks\"><a href=\"#cogroup-otherStream-numTasks\" class=\"headerlink\" title=\"cogroup(otherStream, [numTasks])\"></a>cogroup(otherStream, [numTasks])</h4><blockquote>\n<p>When called on a DStream of (K, V) and (K, W) pairs, return a new DStream of (K, Seq[V], Seq[W]) tuples.</p>\n</blockquote>\n<p>由一个DStream对象调用该方法，元素内容为(k, V)，传入另一个DStream对象，元素内容为(k, W)，返回的DStream中包含的内容是 (k, (Seq[V], Seq[W])) 。这个方法也可以传入一个并行计算的参数，该参数与reduceByKey中是相同的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val wordsOne = words.map(word =&gt; (word , word + &quot;_one&quot; ))</span><br><span class=\"line\">val wordsTwo = words.map(word =&gt; (word , word + &quot;_two&quot; ))</span><br><span class=\"line\">val joinWords = wordsOne.cogroup(wordsTwo)</span><br></pre></td></tr></table></figure>\n<p>结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 输入 hello world hello cogroup</span><br><span class=\"line\"></span><br><span class=\"line\">(hello,(CompactBuffer(hello_one, hello_one),CompactBuffer(hello_two, hello_two)))</span><br><span class=\"line\">(world,(CompactBuffer(world_one),CompactBuffer(world_two)))</span><br><span class=\"line\">(cogroup,(CompactBuffer(cogroup_one),CompactBuffer(cogroup_two)))</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"transform-func\"><a href=\"#transform-func\" class=\"headerlink\" title=\"transform(func)\"></a>transform(func)</h4><h4 id=\"updateStateByKey-func\"><a href=\"#updateStateByKey-func\" class=\"headerlink\" title=\"updateStateByKey(func)\"></a>updateStateByKey(func)</h4><p>参考：<br><a href=\"http://blog.csdn.net/dabokele/article/details/52602412?utm_source=tuicool&amp;utm_medium=referral\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/dabokele/article/details/52602412?utm_source=tuicool&amp;utm_medium=referral</a></p>\n<p>博客：<a href=\"http://yany8060.xyz/\" target=\"_blank\" rel=\"noopener\">http://yany8060.xyz/</a><br>githup: <a href=\"https://github.com/yany8060/SparkDemo\" target=\"_blank\" rel=\"noopener\">https://github.com/yany8060/SparkDemo</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>一个DStream对象可以调用多种操作，主要分为如下几类：</p>\n<ul>\n<li>Transformations</li>\n<li>Window Operations</li>\n<li>Join Operations</li>\n<li>Output Operations</li>\n</ul>\n<h3 id=\"Transformations\"><a href=\"#Transformations\" class=\"headerlink\" title=\"Transformations\"></a>Transformations</h3><h4 id=\"map-func\"><a href=\"#map-func\" class=\"headerlink\" title=\"map(func)\"></a>map(func)</h4><blockquote>\n<p>Return a new DStream by passing each element of the source DStream through a function func.</p>\n</blockquote>\n<p>主要作用是，对DStream对象a，将func函数作用到a中的每一个元素上并生成新的元素，得到的DStream对象b中包含这些新的元素。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//拼接一个”_NEW”字符串</span><br><span class=\"line\">val linesNew = lines.map(lines =&gt; lines + &quot;_NEW&quot; )</span><br></pre></td></tr></table></figure></p>\n<p>map中操作复杂可把函数抽出来在外部定义：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val mapResult = stream.map(new Transformations().customeMap(_))</span><br><span class=\"line\"></span><br><span class=\"line\">def customeMap(word: String): String = &#123;</span><br><span class=\"line\">    word + &quot;ss&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"filter-func\"><a href=\"#filter-func\" class=\"headerlink\" title=\"filter(func)\"></a>filter(func)</h4><blockquote>\n<p>Return a new DStream by selecting only the records of the source DStream on which func returns true.</p>\n</blockquote>\n<p>对DStream a中的每一个元素，应用func方法进行计算，如果func函数返回结果为true，则保留该元素，否则丢弃该元素，返回一个新的DStream b。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val filterWords = words.filter(_ != &quot;hello&quot; )</span><br></pre></td></tr></table></figure></p>\n<p>在定义函数式时，返回值必须是boolean类型，</p>\n<h4 id=\"flatMap-func\"><a href=\"#flatMap-func\" class=\"headerlink\" title=\"flatMap(func)\"></a>flatMap(func)</h4><blockquote>\n<p>Similar to map, but each input item can be mapped to 0 or more output items.</p>\n</blockquote>\n<p>主要作用是，对DStream对象a，将func函数作用到a中的每一个元素上并生成0个或多个新的元素，得到的DStream对象b中包含这些新的元素。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//将lines根据空格进行分割，分割成若干个单词</span><br><span class=\"line\">val words = lines.flatMap(_.split( &quot; &quot; ))</span><br></pre></td></tr></table></figure></p>\n<p>同map若函数复杂可提出去</p>\n<h4 id=\"union-otherStream\"><a href=\"#union-otherStream\" class=\"headerlink\" title=\"union(otherStream)\"></a>union(otherStream)</h4><blockquote>\n<p>Return a new DStream that contains the union of the elements in the source DStream and otherDStream.</p>\n</blockquote>\n<p>这个操作将两个DStream进行合并，生成一个包含着两个DStream中所有元素的新DStream对象。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val wordsOne = words.map(_ + &quot;_one&quot; )</span><br><span class=\"line\">val wordsTwo = words.map(_ + &quot;_two&quot; )</span><br><span class=\"line\">val unionWords = wordsOne.union(wordsTwo)</span><br></pre></td></tr></table></figure></p>\n<p>输入 hello yany tian，结果是将wordsOne和wordsTwo合成一个unionWords的DStream</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hello_one</span><br><span class=\"line\">yany_one</span><br><span class=\"line\">tian_one</span><br><span class=\"line\">hello_two</span><br><span class=\"line\">yany_two</span><br><span class=\"line\">tian_two</span><br></pre></td></tr></table></figure>\n<h4 id=\"repartition-numPartitions\"><a href=\"#repartition-numPartitions\" class=\"headerlink\" title=\"repartition(numPartitions)\"></a>repartition(numPartitions)</h4><blockquote>\n<p>Changes the level of parallelism in this DStream by creating more or fewer partitions.</p>\n</blockquote>\n<p>Return a new DStream with an increased or decreased level of parallelism. Each RDD in the returned DStream has exactly numPartitions partitions.</p>\n<h4 id=\"count\"><a href=\"#count\" class=\"headerlink\" title=\"count()\"></a>count()</h4><blockquote>\n<p>Return a new DStream of single-element RDDs by counting the number of elements in each RDD of the source DStream.</p>\n</blockquote>\n<p>统计DStream中每个RDD包含的元素的个数，得到一个新的DStream，这个DStream中只包含一个元素，这个元素是对应语句单词统计数值。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val wordsCount = words.count()</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"reduce-func\"><a href=\"#reduce-func\" class=\"headerlink\" title=\"reduce(func)\"></a>reduce(func)</h4><blockquote>\n<p>Return a new DStream of single-element RDDs by aggregating the elements in each RDD of the source DStream using a function func (which takes two arguments and returns one). The function should be associative and commutative so that it can be computed in parallel.</p>\n</blockquote>\n<p>返回一个包含一个元素的DStream，传入的func方法会作用在调用者的每一个元素上，将其中的元素顺次的两两进行计算。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val reduceWords = words.reduce(_ + &quot;-&quot; + _)</span><br><span class=\"line\">// 或</span><br><span class=\"line\"></span><br><span class=\"line\">def customerReduce(line1: String, line2: String): String = &#123;</span><br><span class=\"line\">    line1 + &quot;|||&quot; + line2</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"> // val reduceResult = flatMapResult.reduce(new Transformations().customerReduce(_, _));</span><br><span class=\"line\">    val reduceResult = flatMapResult.reduce((x, y) =&gt; new Transformations().customerReduce(x, y));</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"countByValue\"><a href=\"#countByValue\" class=\"headerlink\" title=\"countByValue()\"></a>countByValue()</h4><blockquote>\n<p>When called on a DStream of elements of type K, return a new DStream of (K, Long) pairs where the value of each key is its frequency in each RDD of the source DStream.</p>\n</blockquote>\n<p>某个DStream中的元素类型为K，调用这个方法后，返回的DStream的元素为(K, Long)对，后面这个Long值是原DStream中每个RDD元素key出现的频率。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val countByValueWords = words.countByValue()</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"reduceByKey-func-numTasks\"><a href=\"#reduceByKey-func-numTasks\" class=\"headerlink\" title=\"reduceByKey(func, [numTasks])\"></a>reduceByKey(func, [numTasks])</h4><blockquote>\n<p>When called on a DStream of (K, V) pairs, return a new DStream of (K, V) pairs where the values for each key are aggregated using the given reduce function. Note: By default, this uses Spark’s default number of parallel tasks (2 for local mode, and in cluster mode the number is determined by the config property spark.default.parallelism) to do the grouping. You can pass an optional numTasks argument to set a different number of tasks.</p>\n</blockquote>\n<p>调用这个操作的DStream是以(K, V)的形式出现，返回一个新的元素格式为(K, V)的DStream。返回结果中，K为原来的K，V是由K经过传入func计算得到的。还可以传入一个并行计算的参数，在local模式下，默认为2。在其他模式下，默认值由参数 spark.default.parallelism 确定。</p>\n<p>注：reduceByKey使用时DStream需要以(K, V)的形式出现<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val pairs = words.map(word =&gt; (word , 1))</span><br><span class=\"line\">val wordCounts = pairs.reduceByKey(_ + _)</span><br><span class=\"line\">//===========</span><br><span class=\"line\">/**</span><br><span class=\"line\">    * </span><br><span class=\"line\">    * reducebykey 通过对于两两的value进行操作,可自定义</span><br><span class=\"line\">    * @param line1</span><br><span class=\"line\">    * @param line2</span><br><span class=\"line\">    * @return</span><br><span class=\"line\">    */</span><br><span class=\"line\">  def customerReduceByKey(line1: String, line2: String): String = &#123;</span><br><span class=\"line\">    &quot;ss&quot;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">    val reduceByKeyResult = flatMapResult.map((_, &quot;ss&quot;)).reduceByKey(new Transformations().customerReduceByKey(_, _))</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"join-otherStream-numTasks\"><a href=\"#join-otherStream-numTasks\" class=\"headerlink\" title=\"join(otherStream, [numTasks])\"></a>join(otherStream, [numTasks])</h4><blockquote>\n<p>When called on two DStreams of (K, V) and (K, W) pairs, return a new DStream of (K, (V, W)) pairs with all pairs of elements for each key.</p>\n</blockquote>\n<p>由一个DStream对象调用该方法，元素内容为 (k, V) ，传入另一个DStream对象，元素内容为(k, W)，返回的DStream中包含的内容是 (k, (V, W)) 。这个方法也可以传入一个并行计算的参数，该参数与reduceByKey中是相同的。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val wordsOne = words.map(word =&gt; (word , word + &quot;_one&quot; ))</span><br><span class=\"line\">val wordsTwo = words.map(word =&gt; (word , word + &quot;_two&quot; ))</span><br><span class=\"line\">val joinWords = wordsOne.join(wordsTwo)</span><br></pre></td></tr></table></figure></p>\n<p>结果<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 输入 hello world hello join</span><br><span class=\"line\"></span><br><span class=\"line\">(hello,(hello_one,hello_two))</span><br><span class=\"line\">(hello,(hello_one,hello_two))</span><br><span class=\"line\">(hello,(hello_one,hello_two))</span><br><span class=\"line\">(hello,(hello_one,hello_two))</span><br><span class=\"line\">(join,(join_one,join_two))</span><br><span class=\"line\">(world,(world_one,world_two))</span><br></pre></td></tr></table></figure></p>\n<p>如果key相同，出现笛卡尔积现象</p>\n<h4 id=\"cogroup-otherStream-numTasks\"><a href=\"#cogroup-otherStream-numTasks\" class=\"headerlink\" title=\"cogroup(otherStream, [numTasks])\"></a>cogroup(otherStream, [numTasks])</h4><blockquote>\n<p>When called on a DStream of (K, V) and (K, W) pairs, return a new DStream of (K, Seq[V], Seq[W]) tuples.</p>\n</blockquote>\n<p>由一个DStream对象调用该方法，元素内容为(k, V)，传入另一个DStream对象，元素内容为(k, W)，返回的DStream中包含的内容是 (k, (Seq[V], Seq[W])) 。这个方法也可以传入一个并行计算的参数，该参数与reduceByKey中是相同的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val wordsOne = words.map(word =&gt; (word , word + &quot;_one&quot; ))</span><br><span class=\"line\">val wordsTwo = words.map(word =&gt; (word , word + &quot;_two&quot; ))</span><br><span class=\"line\">val joinWords = wordsOne.cogroup(wordsTwo)</span><br></pre></td></tr></table></figure>\n<p>结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 输入 hello world hello cogroup</span><br><span class=\"line\"></span><br><span class=\"line\">(hello,(CompactBuffer(hello_one, hello_one),CompactBuffer(hello_two, hello_two)))</span><br><span class=\"line\">(world,(CompactBuffer(world_one),CompactBuffer(world_two)))</span><br><span class=\"line\">(cogroup,(CompactBuffer(cogroup_one),CompactBuffer(cogroup_two)))</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"transform-func\"><a href=\"#transform-func\" class=\"headerlink\" title=\"transform(func)\"></a>transform(func)</h4><h4 id=\"updateStateByKey-func\"><a href=\"#updateStateByKey-func\" class=\"headerlink\" title=\"updateStateByKey(func)\"></a>updateStateByKey(func)</h4><p>参考：<br><a href=\"http://blog.csdn.net/dabokele/article/details/52602412?utm_source=tuicool&amp;utm_medium=referral\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/dabokele/article/details/52602412?utm_source=tuicool&amp;utm_medium=referral</a></p>\n<p>博客：<a href=\"http://yany8060.xyz/\" target=\"_blank\" rel=\"noopener\">http://yany8060.xyz/</a><br>githup: <a href=\"https://github.com/yany8060/SparkDemo\" target=\"_blank\" rel=\"noopener\">https://github.com/yany8060/SparkDemo</a></p>\n"},{"title":"Spring-boot-MyBatis配置-2","date":"2017-02-04T08:35:04.000Z","_content":"### 多数据源配置\n1. 分包: 不同数据源的在不同的目录下;事务的回滚需要创建根据数据源创建\n2. 注解\n3. AOP: aop注解切面需要在Service层进行数据源切换;事务可以将多个数据源放在一个事务中;\n\n\n### 分包形式\n> 不同的数据源的sql操作分布在不同的路径下\n\n两个数据源的basepackage分别为：\n* com.yany.dao.multi.ads\n* com.yany.dao.multi.rds\n\n在创建MapperScannerConfigurer时，对应不同的数据源扫描不同的basepackage路径\n```java\nmapperScannerConfigurer.setBasePackage(\"xxxx\");\n```\n\n对应的xml，即MAPPER_PATH\n* classpath:/com/yany/mapper/multi/ads/**.xml\n* classpath:/com/yany/mapper/multi/rds/**.xml\n\n在创建SqlSessionFactoryBean时，MAPPER_PATH对应分别对应于ads和rds的sql路径\n```java\n sessionFactory.setMapperLocations(pathMatchingResourcePatternResolver.getResources(MAPPER_PATH));\n```\n在使用时，不同数据源的操作在分别在不同的路径创建即可。\n\n### 注解形式\n#### 准备好两个注解类，分别对应于两个数据源：\n```java\npublic @interface RdsRepository {\n}\npublic @interface AdsRepository {\n}\n```\n同分包类似分别为Rds和Ads两个数据源创建两个SqlSessionFactoryBean和DataSourceTransactionManager，略微不同的是SqlSessionFactoryBean的setMapperLocations是__允许相同路径__。\n#### 在创建两个MapperScannerConfigurer\n```java\n    /**\n     * 以注解的方式 进行多数据源配置\n     *\n     * @return\n     */\n    @Bean\n    public MapperScannerConfigurer createAnnotatationAdsMapperScannerConfigurer() {\n        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();\n        mapperScannerConfigurer.setBasePackage(\"com.yany.dao.multi.annotation\");\n        mapperScannerConfigurer.setSqlSessionFactoryBeanName(\"annotationAdsSqlSessionFactory\");\n        mapperScannerConfigurer.setAnnotationClass(AdsRepository.class);\n        return mapperScannerConfigurer;\n    }\n\n    /**\n     * 以注解的方式 进行多数据源配置\n     *\n     * @return\n     */\n    @Bean\n    public MapperScannerConfigurer createAnnotatationRdsMapperScannerConfigurer() {\n        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();\n        mapperScannerConfigurer.setBasePackage(\"com.yany.dao.multi.annotation\");\n        mapperScannerConfigurer.setSqlSessionFactoryBeanName(\"annotationRdsSqlSessionFactory\");\n        mapperScannerConfigurer.setAnnotationClass(RdsRepository.class);\n        return mapperScannerConfigurer;\n    }\n```\n上述代码和以前的主要的区别在：setAnnotationClass设置对应不同的注解类\n\n#### 使用时，在不同数据源的dao接口上添加对应的注解\n\n```java\n@RdsRepository\npublic interface AnnotationRdsDao {\n    int selectCount();\n}\n@AdsRepository\npublic interface AnnotationAdsDao {\n    int selectCount();\n}\n```\n而sql对应的xml不变，对应好namespace即可\n\n### AOP形式\n#### 创建一个动态数据源\n创建数据源类型的枚举类\n```java\npublic enum DatabaseType {\n    Ads, Rds\n}\n```\n\n创建一个线程安全的DatabaseType容器\n\n```java\npublic class DatabaseContextHolder {\n    private final static ThreadLocal<DatabaseType> contextHolder = new ThreadLocal<>();\n\n    public static DatabaseType getDatabaseType() {\n        return contextHolder.get();\n    }\n\n    public static void setDatabaseType(DatabaseType type) {\n        contextHolder.set(type);\n    }\n\n}\n```\nThreadLocal类为每一个线程都维护了自己独有的变量拷贝，每个线程都拥有了自己独立的一个变量，避免并发问题。\n\n创建动态数据源DynamicDataSource继承AbstractRoutingDataSource\n```java\npublic class DynamicDataSource extends AbstractRoutingDataSource {\n\n    @Override\n    protected Object determineCurrentLookupKey() {\n        return DatabaseContextHolder.getDatabaseType();\n    }\n}\n```\n\n#### 创建AOP对应的MyBatis配置\n  创建动态数据源的bean\n```java\n    @Bean\n    public DynamicDataSource setDataSource() {\n        Map<Object, Object> targetDataSources = new HashMap<>();\n        targetDataSources.put(DatabaseType.Ads, adsDataSource);\n        targetDataSources.put(DatabaseType.Rds, rdsDataSource);\n\n        DynamicDataSource dataSource = new DynamicDataSource();\n        dataSource.setTargetDataSources(targetDataSources);\n        dataSource.setDefaultTargetDataSource(rdsDataSource);// 默认的datasource设置为rdsDataSource\n        return dataSource;\n    }\n```\n创建SqlSessionFactoryBean和DataSourceTransactionManager以及这个和以前类似不再赘述，具体看github上代码\n\n#### 创建切边\n扫描对应的Service层，在执行具体的服务代码前，根据调用的Service类进行数据源的切换。\n```java\n@Aspect\n@Component\npublic class DataSourceAspect {\n    /**\n     * 使用空方法定义切点表达式\n     */\n    @Pointcut(\"execution(* com.yany.service.**.*(..))\")\n    public void declareJointPointExpression() {\n    }\n\n    @Before(\"declareJointPointExpression()\")\n    public void setDataSourceKey(JoinPoint point) {\n        if (point.getTarget() instanceof IAdsAopService ||\n                point.getTarget() instanceof AdsAopServiceImpl) {\n            //根据连接点所属的类实例，动态切换数据源\n            System.out.println(\"IAdsAopService Aspect\");\n            DatabaseContextHolder.setDatabaseType(DatabaseType.Ads);\n        } else {//连接点所属的类实例是（当然，这一步也可以不写，因为defaultTargertDataSource就是该类所用的rdsDataSource）\n            System.out.println(\"IRdsAopService Aspect\");\n            DatabaseContextHolder.setDatabaseType(DatabaseType.Rds);\n        }\n\n    }\n}\n```\n上述切换规则比较简单，具体可根据业务情况，包目录结构，或者是类名规则等进行解析切换。\n\n具体代码将github：https://github.com/yany8060/SpringDemo.git\n博客：http://yany8060.xyz","source":"_posts/Spring-boot-MyBatis配置-2.md","raw":"---\ntitle: Spring-boot-MyBatis配置-2\ndate: 2017-02-04 16:35:04\ntags: [spring-boot,spring]\ncategories: [java]\n---\n### 多数据源配置\n1. 分包: 不同数据源的在不同的目录下;事务的回滚需要创建根据数据源创建\n2. 注解\n3. AOP: aop注解切面需要在Service层进行数据源切换;事务可以将多个数据源放在一个事务中;\n\n\n### 分包形式\n> 不同的数据源的sql操作分布在不同的路径下\n\n两个数据源的basepackage分别为：\n* com.yany.dao.multi.ads\n* com.yany.dao.multi.rds\n\n在创建MapperScannerConfigurer时，对应不同的数据源扫描不同的basepackage路径\n```java\nmapperScannerConfigurer.setBasePackage(\"xxxx\");\n```\n\n对应的xml，即MAPPER_PATH\n* classpath:/com/yany/mapper/multi/ads/**.xml\n* classpath:/com/yany/mapper/multi/rds/**.xml\n\n在创建SqlSessionFactoryBean时，MAPPER_PATH对应分别对应于ads和rds的sql路径\n```java\n sessionFactory.setMapperLocations(pathMatchingResourcePatternResolver.getResources(MAPPER_PATH));\n```\n在使用时，不同数据源的操作在分别在不同的路径创建即可。\n\n### 注解形式\n#### 准备好两个注解类，分别对应于两个数据源：\n```java\npublic @interface RdsRepository {\n}\npublic @interface AdsRepository {\n}\n```\n同分包类似分别为Rds和Ads两个数据源创建两个SqlSessionFactoryBean和DataSourceTransactionManager，略微不同的是SqlSessionFactoryBean的setMapperLocations是__允许相同路径__。\n#### 在创建两个MapperScannerConfigurer\n```java\n    /**\n     * 以注解的方式 进行多数据源配置\n     *\n     * @return\n     */\n    @Bean\n    public MapperScannerConfigurer createAnnotatationAdsMapperScannerConfigurer() {\n        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();\n        mapperScannerConfigurer.setBasePackage(\"com.yany.dao.multi.annotation\");\n        mapperScannerConfigurer.setSqlSessionFactoryBeanName(\"annotationAdsSqlSessionFactory\");\n        mapperScannerConfigurer.setAnnotationClass(AdsRepository.class);\n        return mapperScannerConfigurer;\n    }\n\n    /**\n     * 以注解的方式 进行多数据源配置\n     *\n     * @return\n     */\n    @Bean\n    public MapperScannerConfigurer createAnnotatationRdsMapperScannerConfigurer() {\n        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();\n        mapperScannerConfigurer.setBasePackage(\"com.yany.dao.multi.annotation\");\n        mapperScannerConfigurer.setSqlSessionFactoryBeanName(\"annotationRdsSqlSessionFactory\");\n        mapperScannerConfigurer.setAnnotationClass(RdsRepository.class);\n        return mapperScannerConfigurer;\n    }\n```\n上述代码和以前的主要的区别在：setAnnotationClass设置对应不同的注解类\n\n#### 使用时，在不同数据源的dao接口上添加对应的注解\n\n```java\n@RdsRepository\npublic interface AnnotationRdsDao {\n    int selectCount();\n}\n@AdsRepository\npublic interface AnnotationAdsDao {\n    int selectCount();\n}\n```\n而sql对应的xml不变，对应好namespace即可\n\n### AOP形式\n#### 创建一个动态数据源\n创建数据源类型的枚举类\n```java\npublic enum DatabaseType {\n    Ads, Rds\n}\n```\n\n创建一个线程安全的DatabaseType容器\n\n```java\npublic class DatabaseContextHolder {\n    private final static ThreadLocal<DatabaseType> contextHolder = new ThreadLocal<>();\n\n    public static DatabaseType getDatabaseType() {\n        return contextHolder.get();\n    }\n\n    public static void setDatabaseType(DatabaseType type) {\n        contextHolder.set(type);\n    }\n\n}\n```\nThreadLocal类为每一个线程都维护了自己独有的变量拷贝，每个线程都拥有了自己独立的一个变量，避免并发问题。\n\n创建动态数据源DynamicDataSource继承AbstractRoutingDataSource\n```java\npublic class DynamicDataSource extends AbstractRoutingDataSource {\n\n    @Override\n    protected Object determineCurrentLookupKey() {\n        return DatabaseContextHolder.getDatabaseType();\n    }\n}\n```\n\n#### 创建AOP对应的MyBatis配置\n  创建动态数据源的bean\n```java\n    @Bean\n    public DynamicDataSource setDataSource() {\n        Map<Object, Object> targetDataSources = new HashMap<>();\n        targetDataSources.put(DatabaseType.Ads, adsDataSource);\n        targetDataSources.put(DatabaseType.Rds, rdsDataSource);\n\n        DynamicDataSource dataSource = new DynamicDataSource();\n        dataSource.setTargetDataSources(targetDataSources);\n        dataSource.setDefaultTargetDataSource(rdsDataSource);// 默认的datasource设置为rdsDataSource\n        return dataSource;\n    }\n```\n创建SqlSessionFactoryBean和DataSourceTransactionManager以及这个和以前类似不再赘述，具体看github上代码\n\n#### 创建切边\n扫描对应的Service层，在执行具体的服务代码前，根据调用的Service类进行数据源的切换。\n```java\n@Aspect\n@Component\npublic class DataSourceAspect {\n    /**\n     * 使用空方法定义切点表达式\n     */\n    @Pointcut(\"execution(* com.yany.service.**.*(..))\")\n    public void declareJointPointExpression() {\n    }\n\n    @Before(\"declareJointPointExpression()\")\n    public void setDataSourceKey(JoinPoint point) {\n        if (point.getTarget() instanceof IAdsAopService ||\n                point.getTarget() instanceof AdsAopServiceImpl) {\n            //根据连接点所属的类实例，动态切换数据源\n            System.out.println(\"IAdsAopService Aspect\");\n            DatabaseContextHolder.setDatabaseType(DatabaseType.Ads);\n        } else {//连接点所属的类实例是（当然，这一步也可以不写，因为defaultTargertDataSource就是该类所用的rdsDataSource）\n            System.out.println(\"IRdsAopService Aspect\");\n            DatabaseContextHolder.setDatabaseType(DatabaseType.Rds);\n        }\n\n    }\n}\n```\n上述切换规则比较简单，具体可根据业务情况，包目录结构，或者是类名规则等进行解析切换。\n\n具体代码将github：https://github.com/yany8060/SpringDemo.git\n博客：http://yany8060.xyz","slug":"Spring-boot-MyBatis配置-2","published":1,"updated":"2018-09-03T12:29:46.719Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmo9un35000j9q0vg8h0c32y","content":"<h3 id=\"多数据源配置\"><a href=\"#多数据源配置\" class=\"headerlink\" title=\"多数据源配置\"></a>多数据源配置</h3><ol>\n<li>分包: 不同数据源的在不同的目录下;事务的回滚需要创建根据数据源创建</li>\n<li>注解</li>\n<li>AOP: aop注解切面需要在Service层进行数据源切换;事务可以将多个数据源放在一个事务中;</li>\n</ol>\n<h3 id=\"分包形式\"><a href=\"#分包形式\" class=\"headerlink\" title=\"分包形式\"></a>分包形式</h3><blockquote>\n<p>不同的数据源的sql操作分布在不同的路径下</p>\n</blockquote>\n<p>两个数据源的basepackage分别为：</p>\n<ul>\n<li>com.yany.dao.multi.ads</li>\n<li>com.yany.dao.multi.rds</li>\n</ul>\n<p>在创建MapperScannerConfigurer时，对应不同的数据源扫描不同的basepackage路径<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mapperScannerConfigurer.setBasePackage(<span class=\"string\">\"xxxx\"</span>);</span><br></pre></td></tr></table></figure></p>\n<p>对应的xml，即MAPPER_PATH</p>\n<ul>\n<li>classpath:/com/yany/mapper/multi/ads/**.xml</li>\n<li>classpath:/com/yany/mapper/multi/rds/**.xml</li>\n</ul>\n<p>在创建SqlSessionFactoryBean时，MAPPER_PATH对应分别对应于ads和rds的sql路径<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sessionFactory.setMapperLocations(pathMatchingResourcePatternResolver.getResources(MAPPER_PATH));</span><br></pre></td></tr></table></figure></p>\n<p>在使用时，不同数据源的操作在分别在不同的路径创建即可。</p>\n<h3 id=\"注解形式\"><a href=\"#注解形式\" class=\"headerlink\" title=\"注解形式\"></a>注解形式</h3><h4 id=\"准备好两个注解类，分别对应于两个数据源：\"><a href=\"#准备好两个注解类，分别对应于两个数据源：\" class=\"headerlink\" title=\"准备好两个注解类，分别对应于两个数据源：\"></a>准备好两个注解类，分别对应于两个数据源：</h4><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"meta\">@interface</span> RdsRepository &#123;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"meta\">@interface</span> AdsRepository &#123;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>同分包类似分别为Rds和Ads两个数据源创建两个SqlSessionFactoryBean和DataSourceTransactionManager，略微不同的是SqlSessionFactoryBean的setMapperLocations是<strong>允许相同路径</strong>。</p>\n<h4 id=\"在创建两个MapperScannerConfigurer\"><a href=\"#在创建两个MapperScannerConfigurer\" class=\"headerlink\" title=\"在创建两个MapperScannerConfigurer\"></a>在创建两个MapperScannerConfigurer</h4><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 以注解的方式 进行多数据源配置</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"meta\">@Bean</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> MapperScannerConfigurer <span class=\"title\">createAnnotatationAdsMapperScannerConfigurer</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    MapperScannerConfigurer mapperScannerConfigurer = <span class=\"keyword\">new</span> MapperScannerConfigurer();</span><br><span class=\"line\">    mapperScannerConfigurer.setBasePackage(<span class=\"string\">\"com.yany.dao.multi.annotation\"</span>);</span><br><span class=\"line\">    mapperScannerConfigurer.setSqlSessionFactoryBeanName(<span class=\"string\">\"annotationAdsSqlSessionFactory\"</span>);</span><br><span class=\"line\">    mapperScannerConfigurer.setAnnotationClass(AdsRepository.class);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> mapperScannerConfigurer;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 以注解的方式 进行多数据源配置</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"meta\">@Bean</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> MapperScannerConfigurer <span class=\"title\">createAnnotatationRdsMapperScannerConfigurer</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    MapperScannerConfigurer mapperScannerConfigurer = <span class=\"keyword\">new</span> MapperScannerConfigurer();</span><br><span class=\"line\">    mapperScannerConfigurer.setBasePackage(<span class=\"string\">\"com.yany.dao.multi.annotation\"</span>);</span><br><span class=\"line\">    mapperScannerConfigurer.setSqlSessionFactoryBeanName(<span class=\"string\">\"annotationRdsSqlSessionFactory\"</span>);</span><br><span class=\"line\">    mapperScannerConfigurer.setAnnotationClass(RdsRepository.class);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> mapperScannerConfigurer;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>上述代码和以前的主要的区别在：setAnnotationClass设置对应不同的注解类</p>\n<h4 id=\"使用时，在不同数据源的dao接口上添加对应的注解\"><a href=\"#使用时，在不同数据源的dao接口上添加对应的注解\" class=\"headerlink\" title=\"使用时，在不同数据源的dao接口上添加对应的注解\"></a>使用时，在不同数据源的dao接口上添加对应的注解</h4><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@RdsRepository</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">AnnotationRdsDao</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">selectCount</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"meta\">@AdsRepository</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">AnnotationAdsDao</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">selectCount</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>而sql对应的xml不变，对应好namespace即可</p>\n<h3 id=\"AOP形式\"><a href=\"#AOP形式\" class=\"headerlink\" title=\"AOP形式\"></a>AOP形式</h3><h4 id=\"创建一个动态数据源\"><a href=\"#创建一个动态数据源\" class=\"headerlink\" title=\"创建一个动态数据源\"></a>创建一个动态数据源</h4><p>创建数据源类型的枚举类<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">enum</span> DatabaseType &#123;</span><br><span class=\"line\">    Ads, Rds</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>创建一个线程安全的DatabaseType容器</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DatabaseContextHolder</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> ThreadLocal&lt;DatabaseType&gt; contextHolder = <span class=\"keyword\">new</span> ThreadLocal&lt;&gt;();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> DatabaseType <span class=\"title\">getDatabaseType</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> contextHolder.get();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">setDatabaseType</span><span class=\"params\">(DatabaseType type)</span> </span>&#123;</span><br><span class=\"line\">        contextHolder.set(type);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>ThreadLocal类为每一个线程都维护了自己独有的变量拷贝，每个线程都拥有了自己独立的一个变量，避免并发问题。</p>\n<p>创建动态数据源DynamicDataSource继承AbstractRoutingDataSource<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DynamicDataSource</span> <span class=\"keyword\">extends</span> <span class=\"title\">AbstractRoutingDataSource</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> Object <span class=\"title\">determineCurrentLookupKey</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> DatabaseContextHolder.getDatabaseType();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"创建AOP对应的MyBatis配置\"><a href=\"#创建AOP对应的MyBatis配置\" class=\"headerlink\" title=\"创建AOP对应的MyBatis配置\"></a>创建AOP对应的MyBatis配置</h4><p>  创建动态数据源的bean<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Bean</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> DynamicDataSource <span class=\"title\">setDataSource</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    Map&lt;Object, Object&gt; targetDataSources = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">    targetDataSources.put(DatabaseType.Ads, adsDataSource);</span><br><span class=\"line\">    targetDataSources.put(DatabaseType.Rds, rdsDataSource);</span><br><span class=\"line\"></span><br><span class=\"line\">    DynamicDataSource dataSource = <span class=\"keyword\">new</span> DynamicDataSource();</span><br><span class=\"line\">    dataSource.setTargetDataSources(targetDataSources);</span><br><span class=\"line\">    dataSource.setDefaultTargetDataSource(rdsDataSource);<span class=\"comment\">// 默认的datasource设置为rdsDataSource</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> dataSource;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>创建SqlSessionFactoryBean和DataSourceTransactionManager以及这个和以前类似不再赘述，具体看github上代码</p>\n<h4 id=\"创建切边\"><a href=\"#创建切边\" class=\"headerlink\" title=\"创建切边\"></a>创建切边</h4><p>扫描对应的Service层，在执行具体的服务代码前，根据调用的Service类进行数据源的切换。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Aspect</span></span><br><span class=\"line\"><span class=\"meta\">@Component</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DataSourceAspect</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 使用空方法定义切点表达式</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Pointcut</span>(<span class=\"string\">\"execution(* com.yany.service.**.*(..))\"</span>)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">declareJointPointExpression</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Before</span>(<span class=\"string\">\"declareJointPointExpression()\"</span>)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setDataSourceKey</span><span class=\"params\">(JoinPoint point)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (point.getTarget() <span class=\"keyword\">instanceof</span> IAdsAopService ||</span><br><span class=\"line\">                point.getTarget() <span class=\"keyword\">instanceof</span> AdsAopServiceImpl) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//根据连接点所属的类实例，动态切换数据源</span></span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"IAdsAopService Aspect\"</span>);</span><br><span class=\"line\">            DatabaseContextHolder.setDatabaseType(DatabaseType.Ads);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;<span class=\"comment\">//连接点所属的类实例是（当然，这一步也可以不写，因为defaultTargertDataSource就是该类所用的rdsDataSource）</span></span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"IRdsAopService Aspect\"</span>);</span><br><span class=\"line\">            DatabaseContextHolder.setDatabaseType(DatabaseType.Rds);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>上述切换规则比较简单，具体可根据业务情况，包目录结构，或者是类名规则等进行解析切换。</p>\n<p>具体代码将github：<a href=\"https://github.com/yany8060/SpringDemo.git\" target=\"_blank\" rel=\"noopener\">https://github.com/yany8060/SpringDemo.git</a><br>博客：<a href=\"http://yany8060.xyz\" target=\"_blank\" rel=\"noopener\">http://yany8060.xyz</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"多数据源配置\"><a href=\"#多数据源配置\" class=\"headerlink\" title=\"多数据源配置\"></a>多数据源配置</h3><ol>\n<li>分包: 不同数据源的在不同的目录下;事务的回滚需要创建根据数据源创建</li>\n<li>注解</li>\n<li>AOP: aop注解切面需要在Service层进行数据源切换;事务可以将多个数据源放在一个事务中;</li>\n</ol>\n<h3 id=\"分包形式\"><a href=\"#分包形式\" class=\"headerlink\" title=\"分包形式\"></a>分包形式</h3><blockquote>\n<p>不同的数据源的sql操作分布在不同的路径下</p>\n</blockquote>\n<p>两个数据源的basepackage分别为：</p>\n<ul>\n<li>com.yany.dao.multi.ads</li>\n<li>com.yany.dao.multi.rds</li>\n</ul>\n<p>在创建MapperScannerConfigurer时，对应不同的数据源扫描不同的basepackage路径<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mapperScannerConfigurer.setBasePackage(<span class=\"string\">\"xxxx\"</span>);</span><br></pre></td></tr></table></figure></p>\n<p>对应的xml，即MAPPER_PATH</p>\n<ul>\n<li>classpath:/com/yany/mapper/multi/ads/**.xml</li>\n<li>classpath:/com/yany/mapper/multi/rds/**.xml</li>\n</ul>\n<p>在创建SqlSessionFactoryBean时，MAPPER_PATH对应分别对应于ads和rds的sql路径<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sessionFactory.setMapperLocations(pathMatchingResourcePatternResolver.getResources(MAPPER_PATH));</span><br></pre></td></tr></table></figure></p>\n<p>在使用时，不同数据源的操作在分别在不同的路径创建即可。</p>\n<h3 id=\"注解形式\"><a href=\"#注解形式\" class=\"headerlink\" title=\"注解形式\"></a>注解形式</h3><h4 id=\"准备好两个注解类，分别对应于两个数据源：\"><a href=\"#准备好两个注解类，分别对应于两个数据源：\" class=\"headerlink\" title=\"准备好两个注解类，分别对应于两个数据源：\"></a>准备好两个注解类，分别对应于两个数据源：</h4><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"meta\">@interface</span> RdsRepository &#123;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"meta\">@interface</span> AdsRepository &#123;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>同分包类似分别为Rds和Ads两个数据源创建两个SqlSessionFactoryBean和DataSourceTransactionManager，略微不同的是SqlSessionFactoryBean的setMapperLocations是<strong>允许相同路径</strong>。</p>\n<h4 id=\"在创建两个MapperScannerConfigurer\"><a href=\"#在创建两个MapperScannerConfigurer\" class=\"headerlink\" title=\"在创建两个MapperScannerConfigurer\"></a>在创建两个MapperScannerConfigurer</h4><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 以注解的方式 进行多数据源配置</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"meta\">@Bean</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> MapperScannerConfigurer <span class=\"title\">createAnnotatationAdsMapperScannerConfigurer</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    MapperScannerConfigurer mapperScannerConfigurer = <span class=\"keyword\">new</span> MapperScannerConfigurer();</span><br><span class=\"line\">    mapperScannerConfigurer.setBasePackage(<span class=\"string\">\"com.yany.dao.multi.annotation\"</span>);</span><br><span class=\"line\">    mapperScannerConfigurer.setSqlSessionFactoryBeanName(<span class=\"string\">\"annotationAdsSqlSessionFactory\"</span>);</span><br><span class=\"line\">    mapperScannerConfigurer.setAnnotationClass(AdsRepository.class);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> mapperScannerConfigurer;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 以注解的方式 进行多数据源配置</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"meta\">@Bean</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> MapperScannerConfigurer <span class=\"title\">createAnnotatationRdsMapperScannerConfigurer</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    MapperScannerConfigurer mapperScannerConfigurer = <span class=\"keyword\">new</span> MapperScannerConfigurer();</span><br><span class=\"line\">    mapperScannerConfigurer.setBasePackage(<span class=\"string\">\"com.yany.dao.multi.annotation\"</span>);</span><br><span class=\"line\">    mapperScannerConfigurer.setSqlSessionFactoryBeanName(<span class=\"string\">\"annotationRdsSqlSessionFactory\"</span>);</span><br><span class=\"line\">    mapperScannerConfigurer.setAnnotationClass(RdsRepository.class);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> mapperScannerConfigurer;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>上述代码和以前的主要的区别在：setAnnotationClass设置对应不同的注解类</p>\n<h4 id=\"使用时，在不同数据源的dao接口上添加对应的注解\"><a href=\"#使用时，在不同数据源的dao接口上添加对应的注解\" class=\"headerlink\" title=\"使用时，在不同数据源的dao接口上添加对应的注解\"></a>使用时，在不同数据源的dao接口上添加对应的注解</h4><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@RdsRepository</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">AnnotationRdsDao</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">selectCount</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"meta\">@AdsRepository</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">AnnotationAdsDao</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">selectCount</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>而sql对应的xml不变，对应好namespace即可</p>\n<h3 id=\"AOP形式\"><a href=\"#AOP形式\" class=\"headerlink\" title=\"AOP形式\"></a>AOP形式</h3><h4 id=\"创建一个动态数据源\"><a href=\"#创建一个动态数据源\" class=\"headerlink\" title=\"创建一个动态数据源\"></a>创建一个动态数据源</h4><p>创建数据源类型的枚举类<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">enum</span> DatabaseType &#123;</span><br><span class=\"line\">    Ads, Rds</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>创建一个线程安全的DatabaseType容器</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DatabaseContextHolder</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> ThreadLocal&lt;DatabaseType&gt; contextHolder = <span class=\"keyword\">new</span> ThreadLocal&lt;&gt;();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> DatabaseType <span class=\"title\">getDatabaseType</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> contextHolder.get();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">setDatabaseType</span><span class=\"params\">(DatabaseType type)</span> </span>&#123;</span><br><span class=\"line\">        contextHolder.set(type);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>ThreadLocal类为每一个线程都维护了自己独有的变量拷贝，每个线程都拥有了自己独立的一个变量，避免并发问题。</p>\n<p>创建动态数据源DynamicDataSource继承AbstractRoutingDataSource<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DynamicDataSource</span> <span class=\"keyword\">extends</span> <span class=\"title\">AbstractRoutingDataSource</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> Object <span class=\"title\">determineCurrentLookupKey</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> DatabaseContextHolder.getDatabaseType();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"创建AOP对应的MyBatis配置\"><a href=\"#创建AOP对应的MyBatis配置\" class=\"headerlink\" title=\"创建AOP对应的MyBatis配置\"></a>创建AOP对应的MyBatis配置</h4><p>  创建动态数据源的bean<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Bean</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> DynamicDataSource <span class=\"title\">setDataSource</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    Map&lt;Object, Object&gt; targetDataSources = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">    targetDataSources.put(DatabaseType.Ads, adsDataSource);</span><br><span class=\"line\">    targetDataSources.put(DatabaseType.Rds, rdsDataSource);</span><br><span class=\"line\"></span><br><span class=\"line\">    DynamicDataSource dataSource = <span class=\"keyword\">new</span> DynamicDataSource();</span><br><span class=\"line\">    dataSource.setTargetDataSources(targetDataSources);</span><br><span class=\"line\">    dataSource.setDefaultTargetDataSource(rdsDataSource);<span class=\"comment\">// 默认的datasource设置为rdsDataSource</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> dataSource;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>创建SqlSessionFactoryBean和DataSourceTransactionManager以及这个和以前类似不再赘述，具体看github上代码</p>\n<h4 id=\"创建切边\"><a href=\"#创建切边\" class=\"headerlink\" title=\"创建切边\"></a>创建切边</h4><p>扫描对应的Service层，在执行具体的服务代码前，根据调用的Service类进行数据源的切换。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Aspect</span></span><br><span class=\"line\"><span class=\"meta\">@Component</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DataSourceAspect</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 使用空方法定义切点表达式</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Pointcut</span>(<span class=\"string\">\"execution(* com.yany.service.**.*(..))\"</span>)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">declareJointPointExpression</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Before</span>(<span class=\"string\">\"declareJointPointExpression()\"</span>)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setDataSourceKey</span><span class=\"params\">(JoinPoint point)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (point.getTarget() <span class=\"keyword\">instanceof</span> IAdsAopService ||</span><br><span class=\"line\">                point.getTarget() <span class=\"keyword\">instanceof</span> AdsAopServiceImpl) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//根据连接点所属的类实例，动态切换数据源</span></span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"IAdsAopService Aspect\"</span>);</span><br><span class=\"line\">            DatabaseContextHolder.setDatabaseType(DatabaseType.Ads);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;<span class=\"comment\">//连接点所属的类实例是（当然，这一步也可以不写，因为defaultTargertDataSource就是该类所用的rdsDataSource）</span></span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"IRdsAopService Aspect\"</span>);</span><br><span class=\"line\">            DatabaseContextHolder.setDatabaseType(DatabaseType.Rds);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>上述切换规则比较简单，具体可根据业务情况，包目录结构，或者是类名规则等进行解析切换。</p>\n<p>具体代码将github：<a href=\"https://github.com/yany8060/SpringDemo.git\" target=\"_blank\" rel=\"noopener\">https://github.com/yany8060/SpringDemo.git</a><br>博客：<a href=\"http://yany8060.xyz\" target=\"_blank\" rel=\"noopener\">http://yany8060.xyz</a></p>\n"},{"title":"TensorFlow 基本概念与函数-1","year":2018,"date":"2018-09-03T12:18:38.000Z","_content":"\n### 编程模型\n> TensorFlow的数据流图是由`节点（Node） `和`边（edge）`组成的`有向无环图（directed acycline graph，DAG）`。TensorFlow 由 Tensor 和 Flow 两部 分组成，Tensor(张量)代表了数据流图中的边，而 Flow(流动)这个动作就代表了数据流图中节点所做的操作。\n> \n\n计算过程：首先从输入层开始，经过塑形层后，一层一层进行前向传播运算。Relu层（隐藏层）里两个参数，即Wh1和bh1，在输出前使用Rule（Rectified Linear Units）激活函数做非线性处理。然后进入Logit层（输出层），学习两个参数Wsm 和 bsm。用Softmax来计算输出结果中各个类别的概率分布。用交叉熵来度量两个概率分布（源样本的概率分布和输出结果 的概率分布）直接的相似性。然后开始计算梯度，这是需要参数Wh1、bh1、Wsm 和 bsm，以及 交叉熵后的结果。随后进入 SGD 训练，也就是反向传播的过程，从上往下计算每一层的参数， 依次进行更新。也就是说，计算和更新的顺序为 bsm、Wsm、bh1 和 Wh1。\n\n![avatar](https://wx3.sinaimg.cn/large/007h1WTYly1fup5sc9m7ag30700cgwol.gif)\n\n### 张量\nTensorFlow用张量这种数据结构来表示所有的数据。一个张量有一个静态类型和动态类型的维数。张量可以在图中的节点之间流通。\n张量的维数来被描述为`阶`\n> 秩：Tensor维度的数量\n\n#### 属性\n* 数据类型（例如 float32、int32 或 string）\n* 形状：即张量的维数和每个维度的大小\n\n#### 方法\n* tf.rank：返回张量的秩\n\n```python\n# shape of tensor 't' is [2, 2, 3]\nt = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\ntf.rank(t)  # 3\n```\n\n* tf.shape：返回某个张量的形状\n\n```python\nt = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\ntf.shape(t)  # [2, 2, 3]\n```\n* tf.reshape：重构张量\n* tf.cast：将 tf.Tensor 从一种数据类型转型为另一种\n\n### 变量\n\n#### 变量集合\n默认情况下，每个 tf.Variable 都放置在以下两个集合中\n\n* `tf.GraphKeys.GLOBAL_VARIABLES` - 可以在多台设备间共享的变量，\n* `tf.GraphKeys.TRAINABLE_VARIABLES` - TensorFlow 将计算其梯度的变量\n\n```\n# 如果不希望变量可训练，可以将其添加到 tf.GraphKeys.LOCAL_VARIABLES 集合中\nmy_local = tf.get_variable(\"my_local\", shape=(),collections=[tf.GraphKeys.LOCAL_VARIABLES])\n# 或\nmy_non_trainable = tf.get_variable(\"my_non_trainable\",\n                                   shape=(),\n                                   trainable=False)\n```\n可以定义自己的集合\n\n```\n# 将名为 my_local 的现有变量添加到名为 my_collection_name 的集合中\ntf.add_to_collection(\"my_collection_name\", my_local)\n# 获取某个集合中的所有变量（或其他对象）的列表\ntf.get_collection(\"my_collection_name\")\n\n```\n\n#### 初始化变量\n> 初始化器: tf.initializers（constant、zeros）\n\n要在训练开始前一次性初始化所有可训练变量，请调用`tf.global_variables_initializer()`。默认情况下，`tf.global_variables_initializer`不会指定变量的初始化顺序\n\n```\nv = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\nw = tf.get_variable(\"w\", initializer=v.initialized_value() + 1)\n```\n\n#### 基本操作\n要为变量赋值，请使用 assign、assign_add 方法以及 tf.Variable 类中的友元。\n\n共享变量两种方式：\n\n* 显式传递 `tf.Variable` 对象\n* 在 `tf.variable_scope` 对象内隐式封装 tf.Variable 对象。\n\n变量作用域允许您在调用隐式创建和使用变量的函数时控制变量重用。作用域还允许您以分层和可理解的方式命名变量。\n\n### 图和会话\n\n#### tf.Graph \n* 图结构：图的节点和边缘，表示各个操作组合在一起的方式，但不规定它们的使用方式。\n* 图集合：TensorFlow 提供了一种在`tf.Graph`中存储元数据集合的通用机制。`tf.add_to_collection` 函数允许您将对象列表与一个键关联（其中 tf.GraphKeys 定义了部分标准键），`tf.get_collection` 允许您查询与某个键关联的所有对象。\n\n大多数 TensorFlow 程序都以数据流图构建阶段开始。在此阶段，您会调用 TensorFlow API 函数，这些函数可构建新的 `tf.Operation（节点）`和 `tf.Tensor（边缘` 对象并将它们添加到 tf.Graph 实例中。\n\n类张量类型:\n\n* tf.Tensor\n* tf.Variable\n* numpy.ndarray\n* list（以及类似于张量的对象的列表）\n* 标量 Python 类型：bool、float、int、str\n\n> 注意：在 TensorFlow API 中调用大多数函数时，只是将操作和张量添加到默认图中，并不会执行实际的计算。您应编写这些函数，直到拥有表示整个计算（例如执行梯度下降法的一步）的 tf.Tensor 或 tf.Operation，然后将该对象传递给 tf.Session 以执行计算。\n\n\n#### tf.Sessoin\n`tf.Session` 拥有物理资源（例如 GPU 和网络连接），因此通常（在 with 代码块中）用作上下文管理器，并在您退出代码块时自动关闭会话\n\n```python\n# Create a default in-process session.\nwith tf.Session() as sess:\n  # ...\n\n# Create a remote session.\nwith tf.Session(\"grpc://example.org:2222\"):\n  # ...\n```\n\n* tf.Session.init \n\t* target： 如果将此参数留空（默认设置），会话将仅使用本地机器中的设备。也可以指定 grpc:// 网址，以便指定 TensorFlow 服务器的地址，这使得会话可以访问该服务器控制的机器上的所有设备。\n\t* graph：默认情况下，新的 tf.Session 将绑定到当前的默认图，并且仅能够在当前的默认图中运行操作。如果您在程序中使用了多个图，则可以在构建会话时指定明确的 `tf.Graph`。\n\t* config：此参数允许您指定一个控制会话行为的`tf.ConfigProto`\n* `tf.Session.run`：运行 `tf.Operation` 或评估 `tf.Tensor` 的主要机制\n\t* `tf.Session.run` 要求您指定一组 fetch，这些 fetch 可确定返回值，并且可能是 `tf.Operation`、`tf.Tensor` 或`类张量类型`\n\t* `tf.Session.run` 也可以选择接受 Feed 字典，该字典是从 `tf.Tensor` 对象（通常是 tf.placeholder 张量）到在执行时会被替换为这些张量的值（通常是 Python 标量、列表或 NumPy 数组）的映射\n\t* `tf.Session.run` 也接受可选的 options 参数（允许您指定与调用有关的选项）和可选的 run_metadata 参数（允许您收集与执行有关的元数据）","source":"_posts/Tensorflow 入门-1.md","raw":"---\ntitle: TensorFlow 基本概念与函数-1\nyear: 2018\ndate: 2018-09-03 20:18:38\ntags: tensorflow\ncategories: tensorflow\n---\n\n### 编程模型\n> TensorFlow的数据流图是由`节点（Node） `和`边（edge）`组成的`有向无环图（directed acycline graph，DAG）`。TensorFlow 由 Tensor 和 Flow 两部 分组成，Tensor(张量)代表了数据流图中的边，而 Flow(流动)这个动作就代表了数据流图中节点所做的操作。\n> \n\n计算过程：首先从输入层开始，经过塑形层后，一层一层进行前向传播运算。Relu层（隐藏层）里两个参数，即Wh1和bh1，在输出前使用Rule（Rectified Linear Units）激活函数做非线性处理。然后进入Logit层（输出层），学习两个参数Wsm 和 bsm。用Softmax来计算输出结果中各个类别的概率分布。用交叉熵来度量两个概率分布（源样本的概率分布和输出结果 的概率分布）直接的相似性。然后开始计算梯度，这是需要参数Wh1、bh1、Wsm 和 bsm，以及 交叉熵后的结果。随后进入 SGD 训练，也就是反向传播的过程，从上往下计算每一层的参数， 依次进行更新。也就是说，计算和更新的顺序为 bsm、Wsm、bh1 和 Wh1。\n\n![avatar](https://wx3.sinaimg.cn/large/007h1WTYly1fup5sc9m7ag30700cgwol.gif)\n\n### 张量\nTensorFlow用张量这种数据结构来表示所有的数据。一个张量有一个静态类型和动态类型的维数。张量可以在图中的节点之间流通。\n张量的维数来被描述为`阶`\n> 秩：Tensor维度的数量\n\n#### 属性\n* 数据类型（例如 float32、int32 或 string）\n* 形状：即张量的维数和每个维度的大小\n\n#### 方法\n* tf.rank：返回张量的秩\n\n```python\n# shape of tensor 't' is [2, 2, 3]\nt = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\ntf.rank(t)  # 3\n```\n\n* tf.shape：返回某个张量的形状\n\n```python\nt = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\ntf.shape(t)  # [2, 2, 3]\n```\n* tf.reshape：重构张量\n* tf.cast：将 tf.Tensor 从一种数据类型转型为另一种\n\n### 变量\n\n#### 变量集合\n默认情况下，每个 tf.Variable 都放置在以下两个集合中\n\n* `tf.GraphKeys.GLOBAL_VARIABLES` - 可以在多台设备间共享的变量，\n* `tf.GraphKeys.TRAINABLE_VARIABLES` - TensorFlow 将计算其梯度的变量\n\n```\n# 如果不希望变量可训练，可以将其添加到 tf.GraphKeys.LOCAL_VARIABLES 集合中\nmy_local = tf.get_variable(\"my_local\", shape=(),collections=[tf.GraphKeys.LOCAL_VARIABLES])\n# 或\nmy_non_trainable = tf.get_variable(\"my_non_trainable\",\n                                   shape=(),\n                                   trainable=False)\n```\n可以定义自己的集合\n\n```\n# 将名为 my_local 的现有变量添加到名为 my_collection_name 的集合中\ntf.add_to_collection(\"my_collection_name\", my_local)\n# 获取某个集合中的所有变量（或其他对象）的列表\ntf.get_collection(\"my_collection_name\")\n\n```\n\n#### 初始化变量\n> 初始化器: tf.initializers（constant、zeros）\n\n要在训练开始前一次性初始化所有可训练变量，请调用`tf.global_variables_initializer()`。默认情况下，`tf.global_variables_initializer`不会指定变量的初始化顺序\n\n```\nv = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\nw = tf.get_variable(\"w\", initializer=v.initialized_value() + 1)\n```\n\n#### 基本操作\n要为变量赋值，请使用 assign、assign_add 方法以及 tf.Variable 类中的友元。\n\n共享变量两种方式：\n\n* 显式传递 `tf.Variable` 对象\n* 在 `tf.variable_scope` 对象内隐式封装 tf.Variable 对象。\n\n变量作用域允许您在调用隐式创建和使用变量的函数时控制变量重用。作用域还允许您以分层和可理解的方式命名变量。\n\n### 图和会话\n\n#### tf.Graph \n* 图结构：图的节点和边缘，表示各个操作组合在一起的方式，但不规定它们的使用方式。\n* 图集合：TensorFlow 提供了一种在`tf.Graph`中存储元数据集合的通用机制。`tf.add_to_collection` 函数允许您将对象列表与一个键关联（其中 tf.GraphKeys 定义了部分标准键），`tf.get_collection` 允许您查询与某个键关联的所有对象。\n\n大多数 TensorFlow 程序都以数据流图构建阶段开始。在此阶段，您会调用 TensorFlow API 函数，这些函数可构建新的 `tf.Operation（节点）`和 `tf.Tensor（边缘` 对象并将它们添加到 tf.Graph 实例中。\n\n类张量类型:\n\n* tf.Tensor\n* tf.Variable\n* numpy.ndarray\n* list（以及类似于张量的对象的列表）\n* 标量 Python 类型：bool、float、int、str\n\n> 注意：在 TensorFlow API 中调用大多数函数时，只是将操作和张量添加到默认图中，并不会执行实际的计算。您应编写这些函数，直到拥有表示整个计算（例如执行梯度下降法的一步）的 tf.Tensor 或 tf.Operation，然后将该对象传递给 tf.Session 以执行计算。\n\n\n#### tf.Sessoin\n`tf.Session` 拥有物理资源（例如 GPU 和网络连接），因此通常（在 with 代码块中）用作上下文管理器，并在您退出代码块时自动关闭会话\n\n```python\n# Create a default in-process session.\nwith tf.Session() as sess:\n  # ...\n\n# Create a remote session.\nwith tf.Session(\"grpc://example.org:2222\"):\n  # ...\n```\n\n* tf.Session.init \n\t* target： 如果将此参数留空（默认设置），会话将仅使用本地机器中的设备。也可以指定 grpc:// 网址，以便指定 TensorFlow 服务器的地址，这使得会话可以访问该服务器控制的机器上的所有设备。\n\t* graph：默认情况下，新的 tf.Session 将绑定到当前的默认图，并且仅能够在当前的默认图中运行操作。如果您在程序中使用了多个图，则可以在构建会话时指定明确的 `tf.Graph`。\n\t* config：此参数允许您指定一个控制会话行为的`tf.ConfigProto`\n* `tf.Session.run`：运行 `tf.Operation` 或评估 `tf.Tensor` 的主要机制\n\t* `tf.Session.run` 要求您指定一组 fetch，这些 fetch 可确定返回值，并且可能是 `tf.Operation`、`tf.Tensor` 或`类张量类型`\n\t* `tf.Session.run` 也可以选择接受 Feed 字典，该字典是从 `tf.Tensor` 对象（通常是 tf.placeholder 张量）到在执行时会被替换为这些张量的值（通常是 Python 标量、列表或 NumPy 数组）的映射\n\t* `tf.Session.run` 也接受可选的 options 参数（允许您指定与调用有关的选项）和可选的 run_metadata 参数（允许您收集与执行有关的元数据）","slug":"Tensorflow 入门-1","published":1,"updated":"2018-09-29T09:58:34.775Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmo9un3a000n9q0vz7zq5hka","content":"<h3 id=\"编程模型\"><a href=\"#编程模型\" class=\"headerlink\" title=\"编程模型\"></a>编程模型</h3><blockquote>\n<p>TensorFlow的数据流图是由<code>节点（Node）</code>和<code>边（edge）</code>组成的<code>有向无环图（directed acycline graph，DAG）</code>。TensorFlow 由 Tensor 和 Flow 两部 分组成，Tensor(张量)代表了数据流图中的边，而 Flow(流动)这个动作就代表了数据流图中节点所做的操作。</p>\n</blockquote>\n<p>计算过程：首先从输入层开始，经过塑形层后，一层一层进行前向传播运算。Relu层（隐藏层）里两个参数，即Wh1和bh1，在输出前使用Rule（Rectified Linear Units）激活函数做非线性处理。然后进入Logit层（输出层），学习两个参数Wsm 和 bsm。用Softmax来计算输出结果中各个类别的概率分布。用交叉熵来度量两个概率分布（源样本的概率分布和输出结果 的概率分布）直接的相似性。然后开始计算梯度，这是需要参数Wh1、bh1、Wsm 和 bsm，以及 交叉熵后的结果。随后进入 SGD 训练，也就是反向传播的过程，从上往下计算每一层的参数， 依次进行更新。也就是说，计算和更新的顺序为 bsm、Wsm、bh1 和 Wh1。</p>\n<p><img src=\"https://wx3.sinaimg.cn/large/007h1WTYly1fup5sc9m7ag30700cgwol.gif\" alt=\"avatar\"></p>\n<h3 id=\"张量\"><a href=\"#张量\" class=\"headerlink\" title=\"张量\"></a>张量</h3><p>TensorFlow用张量这种数据结构来表示所有的数据。一个张量有一个静态类型和动态类型的维数。张量可以在图中的节点之间流通。<br>张量的维数来被描述为<code>阶</code></p>\n<blockquote>\n<p>秩：Tensor维度的数量</p>\n</blockquote>\n<h4 id=\"属性\"><a href=\"#属性\" class=\"headerlink\" title=\"属性\"></a>属性</h4><ul>\n<li>数据类型（例如 float32、int32 或 string）</li>\n<li>形状：即张量的维数和每个维度的大小</li>\n</ul>\n<h4 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h4><ul>\n<li>tf.rank：返回张量的秩</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># shape of tensor 't' is [2, 2, 3]</span></span><br><span class=\"line\">t = tf.constant([[[<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>], [<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>]], [[<span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">4</span>, <span class=\"number\">4</span>]]])</span><br><span class=\"line\">tf.rank(t)  <span class=\"comment\"># 3</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>tf.shape：返回某个张量的形状</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">t = tf.constant([[[<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>], [<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>]], [[<span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">4</span>, <span class=\"number\">4</span>]]])</span><br><span class=\"line\">tf.shape(t)  <span class=\"comment\"># [2, 2, 3]</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>tf.reshape：重构张量</li>\n<li>tf.cast：将 tf.Tensor 从一种数据类型转型为另一种</li>\n</ul>\n<h3 id=\"变量\"><a href=\"#变量\" class=\"headerlink\" title=\"变量\"></a>变量</h3><h4 id=\"变量集合\"><a href=\"#变量集合\" class=\"headerlink\" title=\"变量集合\"></a>变量集合</h4><p>默认情况下，每个 tf.Variable 都放置在以下两个集合中</p>\n<ul>\n<li><code>tf.GraphKeys.GLOBAL_VARIABLES</code> - 可以在多台设备间共享的变量，</li>\n<li><code>tf.GraphKeys.TRAINABLE_VARIABLES</code> - TensorFlow 将计算其梯度的变量</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 如果不希望变量可训练，可以将其添加到 tf.GraphKeys.LOCAL_VARIABLES 集合中</span><br><span class=\"line\">my_local = tf.get_variable(&quot;my_local&quot;, shape=(),collections=[tf.GraphKeys.LOCAL_VARIABLES])</span><br><span class=\"line\"># 或</span><br><span class=\"line\">my_non_trainable = tf.get_variable(&quot;my_non_trainable&quot;,</span><br><span class=\"line\">                                   shape=(),</span><br><span class=\"line\">                                   trainable=False)</span><br></pre></td></tr></table></figure>\n<p>可以定义自己的集合</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 将名为 my_local 的现有变量添加到名为 my_collection_name 的集合中</span><br><span class=\"line\">tf.add_to_collection(&quot;my_collection_name&quot;, my_local)</span><br><span class=\"line\"># 获取某个集合中的所有变量（或其他对象）的列表</span><br><span class=\"line\">tf.get_collection(&quot;my_collection_name&quot;)</span><br></pre></td></tr></table></figure>\n<h4 id=\"初始化变量\"><a href=\"#初始化变量\" class=\"headerlink\" title=\"初始化变量\"></a>初始化变量</h4><blockquote>\n<p>初始化器: tf.initializers（constant、zeros）</p>\n</blockquote>\n<p>要在训练开始前一次性初始化所有可训练变量，请调用<code>tf.global_variables_initializer()</code>。默认情况下，<code>tf.global_variables_initializer</code>不会指定变量的初始化顺序</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">v = tf.get_variable(&quot;v&quot;, shape=(), initializer=tf.zeros_initializer())</span><br><span class=\"line\">w = tf.get_variable(&quot;w&quot;, initializer=v.initialized_value() + 1)</span><br></pre></td></tr></table></figure>\n<h4 id=\"基本操作\"><a href=\"#基本操作\" class=\"headerlink\" title=\"基本操作\"></a>基本操作</h4><p>要为变量赋值，请使用 assign、assign_add 方法以及 tf.Variable 类中的友元。</p>\n<p>共享变量两种方式：</p>\n<ul>\n<li>显式传递 <code>tf.Variable</code> 对象</li>\n<li>在 <code>tf.variable_scope</code> 对象内隐式封装 tf.Variable 对象。</li>\n</ul>\n<p>变量作用域允许您在调用隐式创建和使用变量的函数时控制变量重用。作用域还允许您以分层和可理解的方式命名变量。</p>\n<h3 id=\"图和会话\"><a href=\"#图和会话\" class=\"headerlink\" title=\"图和会话\"></a>图和会话</h3><h4 id=\"tf-Graph\"><a href=\"#tf-Graph\" class=\"headerlink\" title=\"tf.Graph\"></a>tf.Graph</h4><ul>\n<li>图结构：图的节点和边缘，表示各个操作组合在一起的方式，但不规定它们的使用方式。</li>\n<li>图集合：TensorFlow 提供了一种在<code>tf.Graph</code>中存储元数据集合的通用机制。<code>tf.add_to_collection</code> 函数允许您将对象列表与一个键关联（其中 tf.GraphKeys 定义了部分标准键），<code>tf.get_collection</code> 允许您查询与某个键关联的所有对象。</li>\n</ul>\n<p>大多数 TensorFlow 程序都以数据流图构建阶段开始。在此阶段，您会调用 TensorFlow API 函数，这些函数可构建新的 <code>tf.Operation（节点）</code>和 <code>tf.Tensor（边缘</code> 对象并将它们添加到 tf.Graph 实例中。</p>\n<p>类张量类型:</p>\n<ul>\n<li>tf.Tensor</li>\n<li>tf.Variable</li>\n<li>numpy.ndarray</li>\n<li>list（以及类似于张量的对象的列表）</li>\n<li>标量 Python 类型：bool、float、int、str</li>\n</ul>\n<blockquote>\n<p>注意：在 TensorFlow API 中调用大多数函数时，只是将操作和张量添加到默认图中，并不会执行实际的计算。您应编写这些函数，直到拥有表示整个计算（例如执行梯度下降法的一步）的 tf.Tensor 或 tf.Operation，然后将该对象传递给 tf.Session 以执行计算。</p>\n</blockquote>\n<h4 id=\"tf-Sessoin\"><a href=\"#tf-Sessoin\" class=\"headerlink\" title=\"tf.Sessoin\"></a>tf.Sessoin</h4><p><code>tf.Session</code> 拥有物理资源（例如 GPU 和网络连接），因此通常（在 with 代码块中）用作上下文管理器，并在您退出代码块时自动关闭会话</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Create a default in-process session.</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">  <span class=\"comment\"># ...</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a remote session.</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session(<span class=\"string\">\"grpc://example.org:2222\"</span>):</span><br><span class=\"line\">  <span class=\"comment\"># ...</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>tf.Session.init <ul>\n<li>target： 如果将此参数留空（默认设置），会话将仅使用本地机器中的设备。也可以指定 grpc:// 网址，以便指定 TensorFlow 服务器的地址，这使得会话可以访问该服务器控制的机器上的所有设备。</li>\n<li>graph：默认情况下，新的 tf.Session 将绑定到当前的默认图，并且仅能够在当前的默认图中运行操作。如果您在程序中使用了多个图，则可以在构建会话时指定明确的 <code>tf.Graph</code>。</li>\n<li>config：此参数允许您指定一个控制会话行为的<code>tf.ConfigProto</code></li>\n</ul>\n</li>\n<li><code>tf.Session.run</code>：运行 <code>tf.Operation</code> 或评估 <code>tf.Tensor</code> 的主要机制<ul>\n<li><code>tf.Session.run</code> 要求您指定一组 fetch，这些 fetch 可确定返回值，并且可能是 <code>tf.Operation</code>、<code>tf.Tensor</code> 或<code>类张量类型</code></li>\n<li><code>tf.Session.run</code> 也可以选择接受 Feed 字典，该字典是从 <code>tf.Tensor</code> 对象（通常是 tf.placeholder 张量）到在执行时会被替换为这些张量的值（通常是 Python 标量、列表或 NumPy 数组）的映射</li>\n<li><code>tf.Session.run</code> 也接受可选的 options 参数（允许您指定与调用有关的选项）和可选的 run_metadata 参数（允许您收集与执行有关的元数据）</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"编程模型\"><a href=\"#编程模型\" class=\"headerlink\" title=\"编程模型\"></a>编程模型</h3><blockquote>\n<p>TensorFlow的数据流图是由<code>节点（Node）</code>和<code>边（edge）</code>组成的<code>有向无环图（directed acycline graph，DAG）</code>。TensorFlow 由 Tensor 和 Flow 两部 分组成，Tensor(张量)代表了数据流图中的边，而 Flow(流动)这个动作就代表了数据流图中节点所做的操作。</p>\n</blockquote>\n<p>计算过程：首先从输入层开始，经过塑形层后，一层一层进行前向传播运算。Relu层（隐藏层）里两个参数，即Wh1和bh1，在输出前使用Rule（Rectified Linear Units）激活函数做非线性处理。然后进入Logit层（输出层），学习两个参数Wsm 和 bsm。用Softmax来计算输出结果中各个类别的概率分布。用交叉熵来度量两个概率分布（源样本的概率分布和输出结果 的概率分布）直接的相似性。然后开始计算梯度，这是需要参数Wh1、bh1、Wsm 和 bsm，以及 交叉熵后的结果。随后进入 SGD 训练，也就是反向传播的过程，从上往下计算每一层的参数， 依次进行更新。也就是说，计算和更新的顺序为 bsm、Wsm、bh1 和 Wh1。</p>\n<p><img src=\"https://wx3.sinaimg.cn/large/007h1WTYly1fup5sc9m7ag30700cgwol.gif\" alt=\"avatar\"></p>\n<h3 id=\"张量\"><a href=\"#张量\" class=\"headerlink\" title=\"张量\"></a>张量</h3><p>TensorFlow用张量这种数据结构来表示所有的数据。一个张量有一个静态类型和动态类型的维数。张量可以在图中的节点之间流通。<br>张量的维数来被描述为<code>阶</code></p>\n<blockquote>\n<p>秩：Tensor维度的数量</p>\n</blockquote>\n<h4 id=\"属性\"><a href=\"#属性\" class=\"headerlink\" title=\"属性\"></a>属性</h4><ul>\n<li>数据类型（例如 float32、int32 或 string）</li>\n<li>形状：即张量的维数和每个维度的大小</li>\n</ul>\n<h4 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h4><ul>\n<li>tf.rank：返回张量的秩</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># shape of tensor 't' is [2, 2, 3]</span></span><br><span class=\"line\">t = tf.constant([[[<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>], [<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>]], [[<span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">4</span>, <span class=\"number\">4</span>]]])</span><br><span class=\"line\">tf.rank(t)  <span class=\"comment\"># 3</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>tf.shape：返回某个张量的形状</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">t = tf.constant([[[<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>], [<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>]], [[<span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">4</span>, <span class=\"number\">4</span>]]])</span><br><span class=\"line\">tf.shape(t)  <span class=\"comment\"># [2, 2, 3]</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>tf.reshape：重构张量</li>\n<li>tf.cast：将 tf.Tensor 从一种数据类型转型为另一种</li>\n</ul>\n<h3 id=\"变量\"><a href=\"#变量\" class=\"headerlink\" title=\"变量\"></a>变量</h3><h4 id=\"变量集合\"><a href=\"#变量集合\" class=\"headerlink\" title=\"变量集合\"></a>变量集合</h4><p>默认情况下，每个 tf.Variable 都放置在以下两个集合中</p>\n<ul>\n<li><code>tf.GraphKeys.GLOBAL_VARIABLES</code> - 可以在多台设备间共享的变量，</li>\n<li><code>tf.GraphKeys.TRAINABLE_VARIABLES</code> - TensorFlow 将计算其梯度的变量</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 如果不希望变量可训练，可以将其添加到 tf.GraphKeys.LOCAL_VARIABLES 集合中</span><br><span class=\"line\">my_local = tf.get_variable(&quot;my_local&quot;, shape=(),collections=[tf.GraphKeys.LOCAL_VARIABLES])</span><br><span class=\"line\"># 或</span><br><span class=\"line\">my_non_trainable = tf.get_variable(&quot;my_non_trainable&quot;,</span><br><span class=\"line\">                                   shape=(),</span><br><span class=\"line\">                                   trainable=False)</span><br></pre></td></tr></table></figure>\n<p>可以定义自己的集合</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 将名为 my_local 的现有变量添加到名为 my_collection_name 的集合中</span><br><span class=\"line\">tf.add_to_collection(&quot;my_collection_name&quot;, my_local)</span><br><span class=\"line\"># 获取某个集合中的所有变量（或其他对象）的列表</span><br><span class=\"line\">tf.get_collection(&quot;my_collection_name&quot;)</span><br></pre></td></tr></table></figure>\n<h4 id=\"初始化变量\"><a href=\"#初始化变量\" class=\"headerlink\" title=\"初始化变量\"></a>初始化变量</h4><blockquote>\n<p>初始化器: tf.initializers（constant、zeros）</p>\n</blockquote>\n<p>要在训练开始前一次性初始化所有可训练变量，请调用<code>tf.global_variables_initializer()</code>。默认情况下，<code>tf.global_variables_initializer</code>不会指定变量的初始化顺序</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">v = tf.get_variable(&quot;v&quot;, shape=(), initializer=tf.zeros_initializer())</span><br><span class=\"line\">w = tf.get_variable(&quot;w&quot;, initializer=v.initialized_value() + 1)</span><br></pre></td></tr></table></figure>\n<h4 id=\"基本操作\"><a href=\"#基本操作\" class=\"headerlink\" title=\"基本操作\"></a>基本操作</h4><p>要为变量赋值，请使用 assign、assign_add 方法以及 tf.Variable 类中的友元。</p>\n<p>共享变量两种方式：</p>\n<ul>\n<li>显式传递 <code>tf.Variable</code> 对象</li>\n<li>在 <code>tf.variable_scope</code> 对象内隐式封装 tf.Variable 对象。</li>\n</ul>\n<p>变量作用域允许您在调用隐式创建和使用变量的函数时控制变量重用。作用域还允许您以分层和可理解的方式命名变量。</p>\n<h3 id=\"图和会话\"><a href=\"#图和会话\" class=\"headerlink\" title=\"图和会话\"></a>图和会话</h3><h4 id=\"tf-Graph\"><a href=\"#tf-Graph\" class=\"headerlink\" title=\"tf.Graph\"></a>tf.Graph</h4><ul>\n<li>图结构：图的节点和边缘，表示各个操作组合在一起的方式，但不规定它们的使用方式。</li>\n<li>图集合：TensorFlow 提供了一种在<code>tf.Graph</code>中存储元数据集合的通用机制。<code>tf.add_to_collection</code> 函数允许您将对象列表与一个键关联（其中 tf.GraphKeys 定义了部分标准键），<code>tf.get_collection</code> 允许您查询与某个键关联的所有对象。</li>\n</ul>\n<p>大多数 TensorFlow 程序都以数据流图构建阶段开始。在此阶段，您会调用 TensorFlow API 函数，这些函数可构建新的 <code>tf.Operation（节点）</code>和 <code>tf.Tensor（边缘</code> 对象并将它们添加到 tf.Graph 实例中。</p>\n<p>类张量类型:</p>\n<ul>\n<li>tf.Tensor</li>\n<li>tf.Variable</li>\n<li>numpy.ndarray</li>\n<li>list（以及类似于张量的对象的列表）</li>\n<li>标量 Python 类型：bool、float、int、str</li>\n</ul>\n<blockquote>\n<p>注意：在 TensorFlow API 中调用大多数函数时，只是将操作和张量添加到默认图中，并不会执行实际的计算。您应编写这些函数，直到拥有表示整个计算（例如执行梯度下降法的一步）的 tf.Tensor 或 tf.Operation，然后将该对象传递给 tf.Session 以执行计算。</p>\n</blockquote>\n<h4 id=\"tf-Sessoin\"><a href=\"#tf-Sessoin\" class=\"headerlink\" title=\"tf.Sessoin\"></a>tf.Sessoin</h4><p><code>tf.Session</code> 拥有物理资源（例如 GPU 和网络连接），因此通常（在 with 代码块中）用作上下文管理器，并在您退出代码块时自动关闭会话</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Create a default in-process session.</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">  <span class=\"comment\"># ...</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a remote session.</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session(<span class=\"string\">\"grpc://example.org:2222\"</span>):</span><br><span class=\"line\">  <span class=\"comment\"># ...</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>tf.Session.init <ul>\n<li>target： 如果将此参数留空（默认设置），会话将仅使用本地机器中的设备。也可以指定 grpc:// 网址，以便指定 TensorFlow 服务器的地址，这使得会话可以访问该服务器控制的机器上的所有设备。</li>\n<li>graph：默认情况下，新的 tf.Session 将绑定到当前的默认图，并且仅能够在当前的默认图中运行操作。如果您在程序中使用了多个图，则可以在构建会话时指定明确的 <code>tf.Graph</code>。</li>\n<li>config：此参数允许您指定一个控制会话行为的<code>tf.ConfigProto</code></li>\n</ul>\n</li>\n<li><code>tf.Session.run</code>：运行 <code>tf.Operation</code> 或评估 <code>tf.Tensor</code> 的主要机制<ul>\n<li><code>tf.Session.run</code> 要求您指定一组 fetch，这些 fetch 可确定返回值，并且可能是 <code>tf.Operation</code>、<code>tf.Tensor</code> 或<code>类张量类型</code></li>\n<li><code>tf.Session.run</code> 也可以选择接受 Feed 字典，该字典是从 <code>tf.Tensor</code> 对象（通常是 tf.placeholder 张量）到在执行时会被替换为这些张量的值（通常是 Python 标量、列表或 NumPy 数组）的映射</li>\n<li><code>tf.Session.run</code> 也接受可选的 options 参数（允许您指定与调用有关的选项）和可选的 run_metadata 参数（允许您收集与执行有关的元数据）</li>\n</ul>\n</li>\n</ul>\n"},{"title":"Yarn 概述","date":"2017-02-16T12:15:59.000Z","_content":"### 名词介绍\nResourceManager：简称RM，是YARN资源控制框架的中心模块，负责集群中所有的资源的统一管理和分配，它接收来自NM（NodeManager）的汇报，建立AM，并将资源派送给AM（ApplicationMaster）。\nNodeManager：简称NM，NodeManager是ResourceManager在每台机器上的代理，负责容器的管理，并监控他们的资源使用情况（CPU、内存、磁盘及网络等），以及向ResourceManager提供这些资源使用报告。\nApplicationMaster：简称AM，YARN中每个应用都会启动一个AM，负责向RM申请资源，请求NM启动container，并告诉container要做什么事情。\nContainer：资源容器。YARN中所有的应用都是在container之上运行的。AM也是在container上运行的，不过AM的container是RM申请的。\nApache Hadoop YARN（Yet Another Resource Negotiator，另一个资源协调者）：是一种新的Hadoop资源管理器，它是一个通用资源管理系统。\n\n![yarn.png](http://upload-images.jianshu.io/upload_images/1419542-0aad7c3fd732d90a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n### Yarn主要架构\n#### ResourceManager（RM）\nResourceManager是一个全局的资源管理器，负责整个系统的资源管理和分配。它主要由两个组件构成： 调度器 （Scheduler）和 应用程序管理器 （Applications Manager，ASM）。\n* 调度器（Scheduler）：调度器根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。\n* 应用程序管理器：应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动它等。\n\n####  ApplicationMaster（AM）\n用户提交的每个应用程序均包含一个AM，主要功能包括：\n* 与RM调度器协商以获取资源（以Container表示）\n* 将得到的任务进一步分配给内部的任务\n* 与NM通信以启动/停止任务\n* 监控所有任务运行状态，并在任务失败时重新为任务申请资源以重启任务\n\n#### NodeManager（NM）\nNM是每个节点上的资源和任务管理器。\n* 它定时地向RM汇报本节点的资源使用情况和Container运行状态；\n* 它接受并处理来自AM的Container启动/停止等各种请求。\n\n#### Container\nContainer是YARN中的资源抽象，它封装了某个节点上的多维资源，如CPU、内存、磁盘、网络等。当AM向RM申请资源时，RM向AM返回的资源便是用Container表示的。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。Container是一个动态资源划分单位，是根据应用程序的需求自动生成的。目前，YARN仅支持CPU和内存两种资源。\n\n### YARN工作流程\n![yarn-progress-20170216.png](http://upload-images.jianshu.io/upload_images/1419542-4577d88af297c5f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n1、用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。\n2、ResourceManager为该应用程序分配第一个Container，并与对应的NodeManager通信，要求它在这个Container中启动应用程序的ApplicationMaster。\n3、ApplicationMaster首先向ResourceManager注册，这样用户就可以直接通过ResourceManager查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。\n4、ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。\n5、一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务。\n6、NodeManager为任务设置好运行环境（包括环境变量、JAR包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。\n7、各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。\n8、应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。","source":"_posts/Yarn-概述.md","raw":"---\ntitle: Yarn 概述\ndate: 2017-02-16 20:15:59\ntags: [yarn,hadoop]\ncategories: [Big data]\n---\n### 名词介绍\nResourceManager：简称RM，是YARN资源控制框架的中心模块，负责集群中所有的资源的统一管理和分配，它接收来自NM（NodeManager）的汇报，建立AM，并将资源派送给AM（ApplicationMaster）。\nNodeManager：简称NM，NodeManager是ResourceManager在每台机器上的代理，负责容器的管理，并监控他们的资源使用情况（CPU、内存、磁盘及网络等），以及向ResourceManager提供这些资源使用报告。\nApplicationMaster：简称AM，YARN中每个应用都会启动一个AM，负责向RM申请资源，请求NM启动container，并告诉container要做什么事情。\nContainer：资源容器。YARN中所有的应用都是在container之上运行的。AM也是在container上运行的，不过AM的container是RM申请的。\nApache Hadoop YARN（Yet Another Resource Negotiator，另一个资源协调者）：是一种新的Hadoop资源管理器，它是一个通用资源管理系统。\n\n![yarn.png](http://upload-images.jianshu.io/upload_images/1419542-0aad7c3fd732d90a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n### Yarn主要架构\n#### ResourceManager（RM）\nResourceManager是一个全局的资源管理器，负责整个系统的资源管理和分配。它主要由两个组件构成： 调度器 （Scheduler）和 应用程序管理器 （Applications Manager，ASM）。\n* 调度器（Scheduler）：调度器根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。\n* 应用程序管理器：应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动它等。\n\n####  ApplicationMaster（AM）\n用户提交的每个应用程序均包含一个AM，主要功能包括：\n* 与RM调度器协商以获取资源（以Container表示）\n* 将得到的任务进一步分配给内部的任务\n* 与NM通信以启动/停止任务\n* 监控所有任务运行状态，并在任务失败时重新为任务申请资源以重启任务\n\n#### NodeManager（NM）\nNM是每个节点上的资源和任务管理器。\n* 它定时地向RM汇报本节点的资源使用情况和Container运行状态；\n* 它接受并处理来自AM的Container启动/停止等各种请求。\n\n#### Container\nContainer是YARN中的资源抽象，它封装了某个节点上的多维资源，如CPU、内存、磁盘、网络等。当AM向RM申请资源时，RM向AM返回的资源便是用Container表示的。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。Container是一个动态资源划分单位，是根据应用程序的需求自动生成的。目前，YARN仅支持CPU和内存两种资源。\n\n### YARN工作流程\n![yarn-progress-20170216.png](http://upload-images.jianshu.io/upload_images/1419542-4577d88af297c5f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n1、用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。\n2、ResourceManager为该应用程序分配第一个Container，并与对应的NodeManager通信，要求它在这个Container中启动应用程序的ApplicationMaster。\n3、ApplicationMaster首先向ResourceManager注册，这样用户就可以直接通过ResourceManager查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。\n4、ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。\n5、一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务。\n6、NodeManager为任务设置好运行环境（包括环境变量、JAR包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。\n7、各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。\n8、应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。","slug":"Yarn-概述","published":1,"updated":"2018-09-03T12:29:46.720Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmo9un3b000o9q0ve240l4z5","content":"<h3 id=\"名词介绍\"><a href=\"#名词介绍\" class=\"headerlink\" title=\"名词介绍\"></a>名词介绍</h3><p>ResourceManager：简称RM，是YARN资源控制框架的中心模块，负责集群中所有的资源的统一管理和分配，它接收来自NM（NodeManager）的汇报，建立AM，并将资源派送给AM（ApplicationMaster）。<br>NodeManager：简称NM，NodeManager是ResourceManager在每台机器上的代理，负责容器的管理，并监控他们的资源使用情况（CPU、内存、磁盘及网络等），以及向ResourceManager提供这些资源使用报告。<br>ApplicationMaster：简称AM，YARN中每个应用都会启动一个AM，负责向RM申请资源，请求NM启动container，并告诉container要做什么事情。<br>Container：资源容器。YARN中所有的应用都是在container之上运行的。AM也是在container上运行的，不过AM的container是RM申请的。<br>Apache Hadoop YARN（Yet Another Resource Negotiator，另一个资源协调者）：是一种新的Hadoop资源管理器，它是一个通用资源管理系统。</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-0aad7c3fd732d90a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"yarn.png\"></p>\n<h3 id=\"Yarn主要架构\"><a href=\"#Yarn主要架构\" class=\"headerlink\" title=\"Yarn主要架构\"></a>Yarn主要架构</h3><h4 id=\"ResourceManager（RM）\"><a href=\"#ResourceManager（RM）\" class=\"headerlink\" title=\"ResourceManager（RM）\"></a>ResourceManager（RM）</h4><p>ResourceManager是一个全局的资源管理器，负责整个系统的资源管理和分配。它主要由两个组件构成： 调度器 （Scheduler）和 应用程序管理器 （Applications Manager，ASM）。</p>\n<ul>\n<li>调度器（Scheduler）：调度器根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。</li>\n<li>应用程序管理器：应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动它等。</li>\n</ul>\n<h4 id=\"ApplicationMaster（AM）\"><a href=\"#ApplicationMaster（AM）\" class=\"headerlink\" title=\"ApplicationMaster（AM）\"></a>ApplicationMaster（AM）</h4><p>用户提交的每个应用程序均包含一个AM，主要功能包括：</p>\n<ul>\n<li>与RM调度器协商以获取资源（以Container表示）</li>\n<li>将得到的任务进一步分配给内部的任务</li>\n<li>与NM通信以启动/停止任务</li>\n<li>监控所有任务运行状态，并在任务失败时重新为任务申请资源以重启任务</li>\n</ul>\n<h4 id=\"NodeManager（NM）\"><a href=\"#NodeManager（NM）\" class=\"headerlink\" title=\"NodeManager（NM）\"></a>NodeManager（NM）</h4><p>NM是每个节点上的资源和任务管理器。</p>\n<ul>\n<li>它定时地向RM汇报本节点的资源使用情况和Container运行状态；</li>\n<li>它接受并处理来自AM的Container启动/停止等各种请求。</li>\n</ul>\n<h4 id=\"Container\"><a href=\"#Container\" class=\"headerlink\" title=\"Container\"></a>Container</h4><p>Container是YARN中的资源抽象，它封装了某个节点上的多维资源，如CPU、内存、磁盘、网络等。当AM向RM申请资源时，RM向AM返回的资源便是用Container表示的。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。Container是一个动态资源划分单位，是根据应用程序的需求自动生成的。目前，YARN仅支持CPU和内存两种资源。</p>\n<h3 id=\"YARN工作流程\"><a href=\"#YARN工作流程\" class=\"headerlink\" title=\"YARN工作流程\"></a>YARN工作流程</h3><p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-4577d88af297c5f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"yarn-progress-20170216.png\"></p>\n<p>1、用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。<br>2、ResourceManager为该应用程序分配第一个Container，并与对应的NodeManager通信，要求它在这个Container中启动应用程序的ApplicationMaster。<br>3、ApplicationMaster首先向ResourceManager注册，这样用户就可以直接通过ResourceManager查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。<br>4、ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。<br>5、一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务。<br>6、NodeManager为任务设置好运行环境（包括环境变量、JAR包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。<br>7、各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。<br>8、应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"名词介绍\"><a href=\"#名词介绍\" class=\"headerlink\" title=\"名词介绍\"></a>名词介绍</h3><p>ResourceManager：简称RM，是YARN资源控制框架的中心模块，负责集群中所有的资源的统一管理和分配，它接收来自NM（NodeManager）的汇报，建立AM，并将资源派送给AM（ApplicationMaster）。<br>NodeManager：简称NM，NodeManager是ResourceManager在每台机器上的代理，负责容器的管理，并监控他们的资源使用情况（CPU、内存、磁盘及网络等），以及向ResourceManager提供这些资源使用报告。<br>ApplicationMaster：简称AM，YARN中每个应用都会启动一个AM，负责向RM申请资源，请求NM启动container，并告诉container要做什么事情。<br>Container：资源容器。YARN中所有的应用都是在container之上运行的。AM也是在container上运行的，不过AM的container是RM申请的。<br>Apache Hadoop YARN（Yet Another Resource Negotiator，另一个资源协调者）：是一种新的Hadoop资源管理器，它是一个通用资源管理系统。</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-0aad7c3fd732d90a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"yarn.png\"></p>\n<h3 id=\"Yarn主要架构\"><a href=\"#Yarn主要架构\" class=\"headerlink\" title=\"Yarn主要架构\"></a>Yarn主要架构</h3><h4 id=\"ResourceManager（RM）\"><a href=\"#ResourceManager（RM）\" class=\"headerlink\" title=\"ResourceManager（RM）\"></a>ResourceManager（RM）</h4><p>ResourceManager是一个全局的资源管理器，负责整个系统的资源管理和分配。它主要由两个组件构成： 调度器 （Scheduler）和 应用程序管理器 （Applications Manager，ASM）。</p>\n<ul>\n<li>调度器（Scheduler）：调度器根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。</li>\n<li>应用程序管理器：应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动它等。</li>\n</ul>\n<h4 id=\"ApplicationMaster（AM）\"><a href=\"#ApplicationMaster（AM）\" class=\"headerlink\" title=\"ApplicationMaster（AM）\"></a>ApplicationMaster（AM）</h4><p>用户提交的每个应用程序均包含一个AM，主要功能包括：</p>\n<ul>\n<li>与RM调度器协商以获取资源（以Container表示）</li>\n<li>将得到的任务进一步分配给内部的任务</li>\n<li>与NM通信以启动/停止任务</li>\n<li>监控所有任务运行状态，并在任务失败时重新为任务申请资源以重启任务</li>\n</ul>\n<h4 id=\"NodeManager（NM）\"><a href=\"#NodeManager（NM）\" class=\"headerlink\" title=\"NodeManager（NM）\"></a>NodeManager（NM）</h4><p>NM是每个节点上的资源和任务管理器。</p>\n<ul>\n<li>它定时地向RM汇报本节点的资源使用情况和Container运行状态；</li>\n<li>它接受并处理来自AM的Container启动/停止等各种请求。</li>\n</ul>\n<h4 id=\"Container\"><a href=\"#Container\" class=\"headerlink\" title=\"Container\"></a>Container</h4><p>Container是YARN中的资源抽象，它封装了某个节点上的多维资源，如CPU、内存、磁盘、网络等。当AM向RM申请资源时，RM向AM返回的资源便是用Container表示的。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。Container是一个动态资源划分单位，是根据应用程序的需求自动生成的。目前，YARN仅支持CPU和内存两种资源。</p>\n<h3 id=\"YARN工作流程\"><a href=\"#YARN工作流程\" class=\"headerlink\" title=\"YARN工作流程\"></a>YARN工作流程</h3><p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-4577d88af297c5f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"yarn-progress-20170216.png\"></p>\n<p>1、用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。<br>2、ResourceManager为该应用程序分配第一个Container，并与对应的NodeManager通信，要求它在这个Container中启动应用程序的ApplicationMaster。<br>3、ApplicationMaster首先向ResourceManager注册，这样用户就可以直接通过ResourceManager查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。<br>4、ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。<br>5、一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务。<br>6、NodeManager为任务设置好运行环境（包括环境变量、JAR包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。<br>7、各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。<br>8、应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。</p>\n"},{"title":"go-ethereum-简单搭建私有链","date":"2017-12-05T12:34:24.000Z","_content":"\n### Geth\n> https://ethereum.github.io/go-ethereum/install/\n\n#### 安装 geth：\n访问[https://geth.ethereum.org/downloads/](https://geth.ethereum.org/downloads/)，下载Geth for macOS。\n![F674D81F-4D30-4C90-9D2C-5888F42F688C.png](http://upload-images.jianshu.io/upload_images/1419542-1cd247330ce95842.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600)\n给geth做一个软连接到/usr/local/bin目录下，然后在命令行输入：geth version  显示如下边上安装成功\n![image.png](http://upload-images.jianshu.io/upload_images/1419542-d6d5d014aeb2a3bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/400)\n使用homebrew安装：\n```\nbrew tap ethereum/ethereum\nbrew install ethereum\n```\n\n#### Geth工具介绍：\n* Geth工具是Go Ethereum, 是以太坊的官方客户端（Go语言实现）\n* Geth的命令行中包含了大多数的以太坊的命令，包括账户新建，账户之间的以太币转移，挖矿，获取余额，部署以太坊合约等\n\n### 配置私链节点\n新建文件夹，命名随意，在此文件夹下创建genesis.json文件和data文件夹\ngenesis.json内容如下\n```\n{\n  \"config\": {\n        \"chainId\": 0,\n        \"homesteadBlock\": 0,\n        \"eip155Block\": 0,\n        \"eip158Block\": 0\n    },\n  \"alloc\"      : {},\n  \"coinbase\"   : \"0x0000000000000000000000000000000000000000\",\n  \"difficulty\" : \"0x20000\",\n  \"extraData\"  : \"\",\n  \"gasLimit\"   : \"0x2fefd8\",\n  \"nonce\"      : \"0x0000000000000042\",\n  \"mixhash\"    : \"0x0000000000000000000000000000000000000000000000000000000000000000\",\n  \"parentHash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\",\n  \"timestamp\"  : \"0x00\"\n}\n```\n![创世块.png](http://upload-images.jianshu.io/upload_images/1419542-6403c3c435533892.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n#### 初始化：\n在命令行下进入刚才创建的文件夹，输入如下命令：\n`geth --datadir ./data/00 init genesis.json`\n各参数代表的含义如下：\n* init 表示初始化区块，后面跟着创世块的配置文件genesis.json\n* datadir 数据存放的位置\n```\nprivatechain\n├── data\n│   ├── geth\n│   │   └── chaindata\n│   │       ├── 000002.log\n│   │       ├── CURRENT\n│   │       ├── LOCK\n│   │       ├── LOG\n│   │       └── MANIFEST-000003\n│   └── keystore\n└── genesis.json\n```\n\n\n#### 启动节点：\n`geth --datadir ./data/00 --networkid 15 console`\n各参数代表的含义如下：\n* networkid 设置当前区块链的网络ID，用于区分不同的网络，1表示公链\n* console 表示启动命令行模式，可以在Geth中执行命令\n![启动节点.png](http://upload-images.jianshu.io/upload_images/1419542-c1ac395ce5bdd206.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n#### 控制台\n* 创建账号：`personal.newAccount()`或者 `personal.newAccount(\"123456\")`\n* 查看节点信息:`admin.nodeInfo`\n* 挖矿\n  *  开始挖矿 `miner.start()`\n  * 停止挖矿 `miner.stop()`\n* 查看账号：`eth.accounts`\n* 查看账号余额：`eth.getBalance(\"账号名称（eth.accounts[0]）\")`\n\n","source":"_posts/go-ethereum-简单搭建私有链.md","raw":"---\ntitle: go-ethereum-简单搭建私有链\ndate: 2017-12-05 20:34:24\ntags: [以太坊,区块链]\ncategories: [区块链]\n---\n\n### Geth\n> https://ethereum.github.io/go-ethereum/install/\n\n#### 安装 geth：\n访问[https://geth.ethereum.org/downloads/](https://geth.ethereum.org/downloads/)，下载Geth for macOS。\n![F674D81F-4D30-4C90-9D2C-5888F42F688C.png](http://upload-images.jianshu.io/upload_images/1419542-1cd247330ce95842.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600)\n给geth做一个软连接到/usr/local/bin目录下，然后在命令行输入：geth version  显示如下边上安装成功\n![image.png](http://upload-images.jianshu.io/upload_images/1419542-d6d5d014aeb2a3bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/400)\n使用homebrew安装：\n```\nbrew tap ethereum/ethereum\nbrew install ethereum\n```\n\n#### Geth工具介绍：\n* Geth工具是Go Ethereum, 是以太坊的官方客户端（Go语言实现）\n* Geth的命令行中包含了大多数的以太坊的命令，包括账户新建，账户之间的以太币转移，挖矿，获取余额，部署以太坊合约等\n\n### 配置私链节点\n新建文件夹，命名随意，在此文件夹下创建genesis.json文件和data文件夹\ngenesis.json内容如下\n```\n{\n  \"config\": {\n        \"chainId\": 0,\n        \"homesteadBlock\": 0,\n        \"eip155Block\": 0,\n        \"eip158Block\": 0\n    },\n  \"alloc\"      : {},\n  \"coinbase\"   : \"0x0000000000000000000000000000000000000000\",\n  \"difficulty\" : \"0x20000\",\n  \"extraData\"  : \"\",\n  \"gasLimit\"   : \"0x2fefd8\",\n  \"nonce\"      : \"0x0000000000000042\",\n  \"mixhash\"    : \"0x0000000000000000000000000000000000000000000000000000000000000000\",\n  \"parentHash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\",\n  \"timestamp\"  : \"0x00\"\n}\n```\n![创世块.png](http://upload-images.jianshu.io/upload_images/1419542-6403c3c435533892.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n#### 初始化：\n在命令行下进入刚才创建的文件夹，输入如下命令：\n`geth --datadir ./data/00 init genesis.json`\n各参数代表的含义如下：\n* init 表示初始化区块，后面跟着创世块的配置文件genesis.json\n* datadir 数据存放的位置\n```\nprivatechain\n├── data\n│   ├── geth\n│   │   └── chaindata\n│   │       ├── 000002.log\n│   │       ├── CURRENT\n│   │       ├── LOCK\n│   │       ├── LOG\n│   │       └── MANIFEST-000003\n│   └── keystore\n└── genesis.json\n```\n\n\n#### 启动节点：\n`geth --datadir ./data/00 --networkid 15 console`\n各参数代表的含义如下：\n* networkid 设置当前区块链的网络ID，用于区分不同的网络，1表示公链\n* console 表示启动命令行模式，可以在Geth中执行命令\n![启动节点.png](http://upload-images.jianshu.io/upload_images/1419542-c1ac395ce5bdd206.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n#### 控制台\n* 创建账号：`personal.newAccount()`或者 `personal.newAccount(\"123456\")`\n* 查看节点信息:`admin.nodeInfo`\n* 挖矿\n  *  开始挖矿 `miner.start()`\n  * 停止挖矿 `miner.stop()`\n* 查看账号：`eth.accounts`\n* 查看账号余额：`eth.getBalance(\"账号名称（eth.accounts[0]）\")`\n\n","slug":"go-ethereum-简单搭建私有链","published":1,"updated":"2018-09-03T12:29:46.721Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmo9un3c000s9q0vvmjpmxpr","content":"<h3 id=\"Geth\"><a href=\"#Geth\" class=\"headerlink\" title=\"Geth\"></a>Geth</h3><blockquote>\n<p><a href=\"https://ethereum.github.io/go-ethereum/install/\" target=\"_blank\" rel=\"noopener\">https://ethereum.github.io/go-ethereum/install/</a></p>\n</blockquote>\n<h4 id=\"安装-geth：\"><a href=\"#安装-geth：\" class=\"headerlink\" title=\"安装 geth：\"></a>安装 geth：</h4><p>访问<a href=\"https://geth.ethereum.org/downloads/\" target=\"_blank\" rel=\"noopener\">https://geth.ethereum.org/downloads/</a>，下载Geth for macOS。<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-1cd247330ce95842.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600\" alt=\"F674D81F-4D30-4C90-9D2C-5888F42F688C.png\"><br>给geth做一个软连接到/usr/local/bin目录下，然后在命令行输入：geth version  显示如下边上安装成功<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-d6d5d014aeb2a3bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/400\" alt=\"image.png\"><br>使用homebrew安装：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brew tap ethereum/ethereum</span><br><span class=\"line\">brew install ethereum</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"Geth工具介绍：\"><a href=\"#Geth工具介绍：\" class=\"headerlink\" title=\"Geth工具介绍：\"></a>Geth工具介绍：</h4><ul>\n<li>Geth工具是Go Ethereum, 是以太坊的官方客户端（Go语言实现）</li>\n<li>Geth的命令行中包含了大多数的以太坊的命令，包括账户新建，账户之间的以太币转移，挖矿，获取余额，部署以太坊合约等</li>\n</ul>\n<h3 id=\"配置私链节点\"><a href=\"#配置私链节点\" class=\"headerlink\" title=\"配置私链节点\"></a>配置私链节点</h3><p>新建文件夹，命名随意，在此文件夹下创建genesis.json文件和data文件夹<br>genesis.json内容如下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;config&quot;: &#123;</span><br><span class=\"line\">        &quot;chainId&quot;: 0,</span><br><span class=\"line\">        &quot;homesteadBlock&quot;: 0,</span><br><span class=\"line\">        &quot;eip155Block&quot;: 0,</span><br><span class=\"line\">        &quot;eip158Block&quot;: 0</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">  &quot;alloc&quot;      : &#123;&#125;,</span><br><span class=\"line\">  &quot;coinbase&quot;   : &quot;0x0000000000000000000000000000000000000000&quot;,</span><br><span class=\"line\">  &quot;difficulty&quot; : &quot;0x20000&quot;,</span><br><span class=\"line\">  &quot;extraData&quot;  : &quot;&quot;,</span><br><span class=\"line\">  &quot;gasLimit&quot;   : &quot;0x2fefd8&quot;,</span><br><span class=\"line\">  &quot;nonce&quot;      : &quot;0x0000000000000042&quot;,</span><br><span class=\"line\">  &quot;mixhash&quot;    : &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;,</span><br><span class=\"line\">  &quot;parentHash&quot; : &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;,</span><br><span class=\"line\">  &quot;timestamp&quot;  : &quot;0x00&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-6403c3c435533892.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"创世块.png\"></p>\n<h4 id=\"初始化：\"><a href=\"#初始化：\" class=\"headerlink\" title=\"初始化：\"></a>初始化：</h4><p>在命令行下进入刚才创建的文件夹，输入如下命令：<br><code>geth --datadir ./data/00 init genesis.json</code><br>各参数代表的含义如下：</p>\n<ul>\n<li>init 表示初始化区块，后面跟着创世块的配置文件genesis.json</li>\n<li>datadir 数据存放的位置<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">privatechain</span><br><span class=\"line\">├── data</span><br><span class=\"line\">│   ├── geth</span><br><span class=\"line\">│   │   └── chaindata</span><br><span class=\"line\">│   │       ├── 000002.log</span><br><span class=\"line\">│   │       ├── CURRENT</span><br><span class=\"line\">│   │       ├── LOCK</span><br><span class=\"line\">│   │       ├── LOG</span><br><span class=\"line\">│   │       └── MANIFEST-000003</span><br><span class=\"line\">│   └── keystore</span><br><span class=\"line\">└── genesis.json</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"启动节点：\"><a href=\"#启动节点：\" class=\"headerlink\" title=\"启动节点：\"></a>启动节点：</h4><p><code>geth --datadir ./data/00 --networkid 15 console</code><br>各参数代表的含义如下：</p>\n<ul>\n<li>networkid 设置当前区块链的网络ID，用于区分不同的网络，1表示公链</li>\n<li>console 表示启动命令行模式，可以在Geth中执行命令<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-c1ac395ce5bdd206.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"启动节点.png\"></li>\n</ul>\n<h4 id=\"控制台\"><a href=\"#控制台\" class=\"headerlink\" title=\"控制台\"></a>控制台</h4><ul>\n<li>创建账号：<code>personal.newAccount()</code>或者 <code>personal.newAccount(&quot;123456&quot;)</code></li>\n<li>查看节点信息:<code>admin.nodeInfo</code></li>\n<li>挖矿<ul>\n<li>开始挖矿 <code>miner.start()</code></li>\n<li>停止挖矿 <code>miner.stop()</code></li>\n</ul>\n</li>\n<li>查看账号：<code>eth.accounts</code></li>\n<li>查看账号余额：<code>eth.getBalance(&quot;账号名称（eth.accounts[0]）&quot;)</code></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Geth\"><a href=\"#Geth\" class=\"headerlink\" title=\"Geth\"></a>Geth</h3><blockquote>\n<p><a href=\"https://ethereum.github.io/go-ethereum/install/\" target=\"_blank\" rel=\"noopener\">https://ethereum.github.io/go-ethereum/install/</a></p>\n</blockquote>\n<h4 id=\"安装-geth：\"><a href=\"#安装-geth：\" class=\"headerlink\" title=\"安装 geth：\"></a>安装 geth：</h4><p>访问<a href=\"https://geth.ethereum.org/downloads/\" target=\"_blank\" rel=\"noopener\">https://geth.ethereum.org/downloads/</a>，下载Geth for macOS。<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-1cd247330ce95842.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600\" alt=\"F674D81F-4D30-4C90-9D2C-5888F42F688C.png\"><br>给geth做一个软连接到/usr/local/bin目录下，然后在命令行输入：geth version  显示如下边上安装成功<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-d6d5d014aeb2a3bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/400\" alt=\"image.png\"><br>使用homebrew安装：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brew tap ethereum/ethereum</span><br><span class=\"line\">brew install ethereum</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"Geth工具介绍：\"><a href=\"#Geth工具介绍：\" class=\"headerlink\" title=\"Geth工具介绍：\"></a>Geth工具介绍：</h4><ul>\n<li>Geth工具是Go Ethereum, 是以太坊的官方客户端（Go语言实现）</li>\n<li>Geth的命令行中包含了大多数的以太坊的命令，包括账户新建，账户之间的以太币转移，挖矿，获取余额，部署以太坊合约等</li>\n</ul>\n<h3 id=\"配置私链节点\"><a href=\"#配置私链节点\" class=\"headerlink\" title=\"配置私链节点\"></a>配置私链节点</h3><p>新建文件夹，命名随意，在此文件夹下创建genesis.json文件和data文件夹<br>genesis.json内容如下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;config&quot;: &#123;</span><br><span class=\"line\">        &quot;chainId&quot;: 0,</span><br><span class=\"line\">        &quot;homesteadBlock&quot;: 0,</span><br><span class=\"line\">        &quot;eip155Block&quot;: 0,</span><br><span class=\"line\">        &quot;eip158Block&quot;: 0</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">  &quot;alloc&quot;      : &#123;&#125;,</span><br><span class=\"line\">  &quot;coinbase&quot;   : &quot;0x0000000000000000000000000000000000000000&quot;,</span><br><span class=\"line\">  &quot;difficulty&quot; : &quot;0x20000&quot;,</span><br><span class=\"line\">  &quot;extraData&quot;  : &quot;&quot;,</span><br><span class=\"line\">  &quot;gasLimit&quot;   : &quot;0x2fefd8&quot;,</span><br><span class=\"line\">  &quot;nonce&quot;      : &quot;0x0000000000000042&quot;,</span><br><span class=\"line\">  &quot;mixhash&quot;    : &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;,</span><br><span class=\"line\">  &quot;parentHash&quot; : &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;,</span><br><span class=\"line\">  &quot;timestamp&quot;  : &quot;0x00&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-6403c3c435533892.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"创世块.png\"></p>\n<h4 id=\"初始化：\"><a href=\"#初始化：\" class=\"headerlink\" title=\"初始化：\"></a>初始化：</h4><p>在命令行下进入刚才创建的文件夹，输入如下命令：<br><code>geth --datadir ./data/00 init genesis.json</code><br>各参数代表的含义如下：</p>\n<ul>\n<li>init 表示初始化区块，后面跟着创世块的配置文件genesis.json</li>\n<li>datadir 数据存放的位置<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">privatechain</span><br><span class=\"line\">├── data</span><br><span class=\"line\">│   ├── geth</span><br><span class=\"line\">│   │   └── chaindata</span><br><span class=\"line\">│   │       ├── 000002.log</span><br><span class=\"line\">│   │       ├── CURRENT</span><br><span class=\"line\">│   │       ├── LOCK</span><br><span class=\"line\">│   │       ├── LOG</span><br><span class=\"line\">│   │       └── MANIFEST-000003</span><br><span class=\"line\">│   └── keystore</span><br><span class=\"line\">└── genesis.json</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"启动节点：\"><a href=\"#启动节点：\" class=\"headerlink\" title=\"启动节点：\"></a>启动节点：</h4><p><code>geth --datadir ./data/00 --networkid 15 console</code><br>各参数代表的含义如下：</p>\n<ul>\n<li>networkid 设置当前区块链的网络ID，用于区分不同的网络，1表示公链</li>\n<li>console 表示启动命令行模式，可以在Geth中执行命令<br><img src=\"http://upload-images.jianshu.io/upload_images/1419542-c1ac395ce5bdd206.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"启动节点.png\"></li>\n</ul>\n<h4 id=\"控制台\"><a href=\"#控制台\" class=\"headerlink\" title=\"控制台\"></a>控制台</h4><ul>\n<li>创建账号：<code>personal.newAccount()</code>或者 <code>personal.newAccount(&quot;123456&quot;)</code></li>\n<li>查看节点信息:<code>admin.nodeInfo</code></li>\n<li>挖矿<ul>\n<li>开始挖矿 <code>miner.start()</code></li>\n<li>停止挖矿 <code>miner.stop()</code></li>\n</ul>\n</li>\n<li>查看账号：<code>eth.accounts</code></li>\n<li>查看账号余额：<code>eth.getBalance(&quot;账号名称（eth.accounts[0]）&quot;)</code></li>\n</ul>\n"},{"title":"Spring-Boot 入门学习","date":"2017-01-25T06:03:40.000Z","_content":"> Spring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can \"just run\". We take an opinionated view of the Spring platform and third-party libraries so you can get started with minimum fuss. Most Spring Boot applications need very little Spring configuration.\n> 简言之：方便创建一个最小规模的Spring工程，且它只需要很少的Spring配置\n\n### 特征\n* Create stand-alone Spring applications\n* Embed（内置、嵌入） Tomcat, Jetty or Undertow directly (no need to deploy WAR files)\n* Provide opinionated 'starter' POMs to simplify your Maven configuration\n* Automatically configure Spring whenever possible\n* Provide production-ready features such as metrics, health checks and externalized configuration（提供产品化的功能）\n* Absolutely no code generation and no requirement for XML configuration\n\n\n### Spring-Boot工程简单搭建\n> Spring-boot文档：http://docs.spring.io/spring-boot/docs/current/reference/html/\n> 具体代码详见：https://github.com/yany8060/SpringDemo\n\n#### pom.xml详情（本工程以maven方式搭建）：\n官方建议引入父工程\n```\n<properties> \n\t<java.version>1.7</java.version>\n\t<spring.boot.version>1.4.3.RELEASE</spring.boot.version>\n</properties>\n\n\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-parent</artifactId>\n\t<version>${spring.boot.version}</version>\n\t<type>pom</type>\n\t<scope>import</scope>\n</dependency>\n```\n\n在子工程中引入自己所需要的依赖（版本号有父工程管理）：\n```\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-test</artifactId>\n    <scope>test</scope>\n</dependency>\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-web</artifactId>\n</dependency>\n\n```\n并添加maven编译插件：\n```\n<plugin>\n\t<groupId>org.apache.maven.plugins</groupId>\n\t<artifactId>maven-compiler-plugin</artifactId>\n</plugin>\n```\n更多SpringBoot Maven插件详见：http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/maven-plugin/index.html\n\n#### 创建一个启动入口（应用类）\n我们创建一个Application类：\n```java\n@EnableAutoConfiguration\n@ComponentScan(basePackages = \"com.yany\")\n@Configuration\npublic class Application {\n    public static void main(String[] args) {\n        SpringApplication.run(Application.class);\n    }\n\n}\n```\n`@EnableAutoConfiguration`\n开启自动配置\n这个注解告诉Spring Boot根据添加的jar依赖猜测你想如何配置Spring\n`@ComponentScan`\nSpring原注解，扫描包加载bean\n`@Configuration`\n标注一个类为配置类\n\n我们再创建一个Controller层：\n```java\n@RestController\npublic class Example {\n\n    @RequestMapping(value = \"/hello\", method = {RequestMethod.GET})\n    public String test() {\n        return \"Hello world\";\n    }\n\n}\n```\n`@RestController`\n相当于同时添加@Controller和@ResponseBody注解。\n\n这时一个基本的Spring-Boot的工程就创建完了，里面包含一个了Mapping映射，可通过访问：http://localhost:8080/SpringBoot/hello 来得到返回值\n\n#### 启动\n以main方法方式启动Application类，\n\n在浏览器中输入：http://localhost:8080/SpringBoot/hello\n得到返回：Hello world\n![](/img/work/14853239880359.jpg)\n\n\n具体输入日志如下：\n```\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n :: Spring Boot ::        (v1.4.3.RELEASE)\n\n2017-01-25 13:55:36.298  INFO 30221 --- [           main] com.yany.Application                     : Starting Application on yanyongdeMacBook-Pro.local with PID 30221 (/Users/yanyong/GitHub/YanY/SpringDemo/SpringBoot/target/classes started by yanyong in /Users/yanyong/GitHub/YanY/SpringDemo)\n2017-01-25 13:55:36.301  INFO 30221 --- [           main] com.yany.Application                     : No active profile set, falling back to default profiles: default\n2017-01-25 13:55:36.373  INFO 30221 --- [           main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d8b20a0: startup date [Wed Jan 25 13:55:36 CST 2017]; root of context hierarchy\n2017-01-25 13:55:37.264  WARN 30221 --- [           main] o.m.s.mapper.ClassPathMapperScanner      : No MyBatis mapper was found in '[com.yany]' package. Please check your configuration.\n2017-01-25 13:55:37.570  INFO 30221 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$baf0e866] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)\n2017-01-25 13:55:37.997  INFO 30221 --- [           main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)\n2017-01-25 13:55:38.009  INFO 30221 --- [           main] o.apache.catalina.core.StandardService   : Starting service Tomcat\n2017-01-25 13:55:38.010  INFO 30221 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.6\n2017-01-25 13:55:38.136  INFO 30221 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext\n2017-01-25 13:55:38.136  INFO 30221 --- [ost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1767 ms\n2017-01-25 13:55:38.298  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]\n2017-01-25 13:55:38.302  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]\n2017-01-25 13:55:38.302  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]\n2017-01-25 13:55:38.303  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]\n2017-01-25 13:55:38.303  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]\n2017-01-25 13:55:38.613  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d8b20a0: startup date [Wed Jan 25 13:55:36 CST 2017]; root of context hierarchy\n2017-01-25 13:55:38.674  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped \"{[/hello],methods=[GET]}\" onto public java.lang.String com.yany.controller.Example.test()\n2017-01-25 13:55:38.678  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped \"{[/error]}\" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)\n2017-01-25 13:55:38.678  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped \"{[/error],produces=[text/html]}\" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)\n2017-01-25 13:55:38.712  INFO 30221 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]\n2017-01-25 13:55:38.712  INFO 30221 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]\n2017-01-25 13:55:38.752  INFO 30221 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]\n2017-01-25 13:55:39.333  INFO 30221 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup\n2017-01-25 13:55:39.385  INFO 30221 --- [           main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)\n2017-01-25 13:55:39.388  INFO 30221 --- [           main] com.yany.Application                     : Started Application in 3.752 seconds (JVM running for 4.078)\n\n```\n\n\n","source":"_posts/Spring-Boot-入门学习.md","raw":"---\ntitle: Spring-Boot 入门学习\ndate: 2017-01-25 14:03:40\ntags: [spring-boot,spring]\ncategories: [java]\n---\n> Spring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can \"just run\". We take an opinionated view of the Spring platform and third-party libraries so you can get started with minimum fuss. Most Spring Boot applications need very little Spring configuration.\n> 简言之：方便创建一个最小规模的Spring工程，且它只需要很少的Spring配置\n\n### 特征\n* Create stand-alone Spring applications\n* Embed（内置、嵌入） Tomcat, Jetty or Undertow directly (no need to deploy WAR files)\n* Provide opinionated 'starter' POMs to simplify your Maven configuration\n* Automatically configure Spring whenever possible\n* Provide production-ready features such as metrics, health checks and externalized configuration（提供产品化的功能）\n* Absolutely no code generation and no requirement for XML configuration\n\n\n### Spring-Boot工程简单搭建\n> Spring-boot文档：http://docs.spring.io/spring-boot/docs/current/reference/html/\n> 具体代码详见：https://github.com/yany8060/SpringDemo\n\n#### pom.xml详情（本工程以maven方式搭建）：\n官方建议引入父工程\n```\n<properties> \n\t<java.version>1.7</java.version>\n\t<spring.boot.version>1.4.3.RELEASE</spring.boot.version>\n</properties>\n\n\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-parent</artifactId>\n\t<version>${spring.boot.version}</version>\n\t<type>pom</type>\n\t<scope>import</scope>\n</dependency>\n```\n\n在子工程中引入自己所需要的依赖（版本号有父工程管理）：\n```\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-test</artifactId>\n    <scope>test</scope>\n</dependency>\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-web</artifactId>\n</dependency>\n\n```\n并添加maven编译插件：\n```\n<plugin>\n\t<groupId>org.apache.maven.plugins</groupId>\n\t<artifactId>maven-compiler-plugin</artifactId>\n</plugin>\n```\n更多SpringBoot Maven插件详见：http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/maven-plugin/index.html\n\n#### 创建一个启动入口（应用类）\n我们创建一个Application类：\n```java\n@EnableAutoConfiguration\n@ComponentScan(basePackages = \"com.yany\")\n@Configuration\npublic class Application {\n    public static void main(String[] args) {\n        SpringApplication.run(Application.class);\n    }\n\n}\n```\n`@EnableAutoConfiguration`\n开启自动配置\n这个注解告诉Spring Boot根据添加的jar依赖猜测你想如何配置Spring\n`@ComponentScan`\nSpring原注解，扫描包加载bean\n`@Configuration`\n标注一个类为配置类\n\n我们再创建一个Controller层：\n```java\n@RestController\npublic class Example {\n\n    @RequestMapping(value = \"/hello\", method = {RequestMethod.GET})\n    public String test() {\n        return \"Hello world\";\n    }\n\n}\n```\n`@RestController`\n相当于同时添加@Controller和@ResponseBody注解。\n\n这时一个基本的Spring-Boot的工程就创建完了，里面包含一个了Mapping映射，可通过访问：http://localhost:8080/SpringBoot/hello 来得到返回值\n\n#### 启动\n以main方法方式启动Application类，\n\n在浏览器中输入：http://localhost:8080/SpringBoot/hello\n得到返回：Hello world\n![](/img/work/14853239880359.jpg)\n\n\n具体输入日志如下：\n```\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n :: Spring Boot ::        (v1.4.3.RELEASE)\n\n2017-01-25 13:55:36.298  INFO 30221 --- [           main] com.yany.Application                     : Starting Application on yanyongdeMacBook-Pro.local with PID 30221 (/Users/yanyong/GitHub/YanY/SpringDemo/SpringBoot/target/classes started by yanyong in /Users/yanyong/GitHub/YanY/SpringDemo)\n2017-01-25 13:55:36.301  INFO 30221 --- [           main] com.yany.Application                     : No active profile set, falling back to default profiles: default\n2017-01-25 13:55:36.373  INFO 30221 --- [           main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d8b20a0: startup date [Wed Jan 25 13:55:36 CST 2017]; root of context hierarchy\n2017-01-25 13:55:37.264  WARN 30221 --- [           main] o.m.s.mapper.ClassPathMapperScanner      : No MyBatis mapper was found in '[com.yany]' package. Please check your configuration.\n2017-01-25 13:55:37.570  INFO 30221 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$baf0e866] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)\n2017-01-25 13:55:37.997  INFO 30221 --- [           main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)\n2017-01-25 13:55:38.009  INFO 30221 --- [           main] o.apache.catalina.core.StandardService   : Starting service Tomcat\n2017-01-25 13:55:38.010  INFO 30221 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.6\n2017-01-25 13:55:38.136  INFO 30221 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext\n2017-01-25 13:55:38.136  INFO 30221 --- [ost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1767 ms\n2017-01-25 13:55:38.298  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]\n2017-01-25 13:55:38.302  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]\n2017-01-25 13:55:38.302  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]\n2017-01-25 13:55:38.303  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]\n2017-01-25 13:55:38.303  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]\n2017-01-25 13:55:38.613  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d8b20a0: startup date [Wed Jan 25 13:55:36 CST 2017]; root of context hierarchy\n2017-01-25 13:55:38.674  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped \"{[/hello],methods=[GET]}\" onto public java.lang.String com.yany.controller.Example.test()\n2017-01-25 13:55:38.678  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped \"{[/error]}\" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)\n2017-01-25 13:55:38.678  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped \"{[/error],produces=[text/html]}\" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)\n2017-01-25 13:55:38.712  INFO 30221 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]\n2017-01-25 13:55:38.712  INFO 30221 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]\n2017-01-25 13:55:38.752  INFO 30221 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]\n2017-01-25 13:55:39.333  INFO 30221 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup\n2017-01-25 13:55:39.385  INFO 30221 --- [           main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)\n2017-01-25 13:55:39.388  INFO 30221 --- [           main] com.yany.Application                     : Started Application in 3.752 seconds (JVM running for 4.078)\n\n```\n\n\n","slug":"Spring-Boot-入门学习","published":1,"updated":"2018-09-03T12:29:46.718Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmo9un7y001x9q0vcm7lwo35","content":"<blockquote>\n<p>Spring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can “just run”. We take an opinionated view of the Spring platform and third-party libraries so you can get started with minimum fuss. Most Spring Boot applications need very little Spring configuration.<br>简言之：方便创建一个最小规模的Spring工程，且它只需要很少的Spring配置</p>\n</blockquote>\n<h3 id=\"特征\"><a href=\"#特征\" class=\"headerlink\" title=\"特征\"></a>特征</h3><ul>\n<li>Create stand-alone Spring applications</li>\n<li>Embed（内置、嵌入） Tomcat, Jetty or Undertow directly (no need to deploy WAR files)</li>\n<li>Provide opinionated ‘starter’ POMs to simplify your Maven configuration</li>\n<li>Automatically configure Spring whenever possible</li>\n<li>Provide production-ready features such as metrics, health checks and externalized configuration（提供产品化的功能）</li>\n<li>Absolutely no code generation and no requirement for XML configuration</li>\n</ul>\n<h3 id=\"Spring-Boot工程简单搭建\"><a href=\"#Spring-Boot工程简单搭建\" class=\"headerlink\" title=\"Spring-Boot工程简单搭建\"></a>Spring-Boot工程简单搭建</h3><blockquote>\n<p>Spring-boot文档：<a href=\"http://docs.spring.io/spring-boot/docs/current/reference/html/\" target=\"_blank\" rel=\"noopener\">http://docs.spring.io/spring-boot/docs/current/reference/html/</a><br>具体代码详见：<a href=\"https://github.com/yany8060/SpringDemo\" target=\"_blank\" rel=\"noopener\">https://github.com/yany8060/SpringDemo</a></p>\n</blockquote>\n<h4 id=\"pom-xml详情（本工程以maven方式搭建）：\"><a href=\"#pom-xml详情（本工程以maven方式搭建）：\" class=\"headerlink\" title=\"pom.xml详情（本工程以maven方式搭建）：\"></a>pom.xml详情（本工程以maven方式搭建）：</h4><p>官方建议引入父工程<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;properties&gt; </span><br><span class=\"line\">\t&lt;java.version&gt;1.7&lt;/java.version&gt;</span><br><span class=\"line\">\t&lt;spring.boot.version&gt;1.4.3.RELEASE&lt;/spring.boot.version&gt;</span><br><span class=\"line\">&lt;/properties&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class=\"line\">\t&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</span><br><span class=\"line\">\t&lt;version&gt;$&#123;spring.boot.version&#125;&lt;/version&gt;</span><br><span class=\"line\">\t&lt;type&gt;pom&lt;/type&gt;</span><br><span class=\"line\">\t&lt;scope&gt;import&lt;/scope&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p>\n<p>在子工程中引入自己所需要的依赖（版本号有父工程管理）：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;scope&gt;test&lt;/scope&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class=\"line\">\t&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p>\n<p>并添加maven编译插件：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;plugin&gt;</span><br><span class=\"line\">\t&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class=\"line\">\t&lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;</span><br><span class=\"line\">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure></p>\n<p>更多SpringBoot Maven插件详见：<a href=\"http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/maven-plugin/index.html\" target=\"_blank\" rel=\"noopener\">http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/maven-plugin/index.html</a></p>\n<h4 id=\"创建一个启动入口（应用类）\"><a href=\"#创建一个启动入口（应用类）\" class=\"headerlink\" title=\"创建一个启动入口（应用类）\"></a>创建一个启动入口（应用类）</h4><p>我们创建一个Application类：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@EnableAutoConfiguration</span></span><br><span class=\"line\"><span class=\"meta\">@ComponentScan</span>(basePackages = <span class=\"string\">\"com.yany\"</span>)</span><br><span class=\"line\"><span class=\"meta\">@Configuration</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Application</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        SpringApplication.run(Application.class);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><code>@EnableAutoConfiguration</code><br>开启自动配置<br>这个注解告诉Spring Boot根据添加的jar依赖猜测你想如何配置Spring<br><code>@ComponentScan</code><br>Spring原注解，扫描包加载bean<br><code>@Configuration</code><br>标注一个类为配置类</p>\n<p>我们再创建一个Controller层：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@RestController</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Example</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@RequestMapping</span>(value = <span class=\"string\">\"/hello\"</span>, method = &#123;RequestMethod.GET&#125;)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">test</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">\"Hello world\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><code>@RestController</code><br>相当于同时添加@Controller和@ResponseBody注解。</p>\n<p>这时一个基本的Spring-Boot的工程就创建完了，里面包含一个了Mapping映射，可通过访问：<a href=\"http://localhost:8080/SpringBoot/hello\" target=\"_blank\" rel=\"noopener\">http://localhost:8080/SpringBoot/hello</a> 来得到返回值</p>\n<h4 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h4><p>以main方法方式启动Application类，</p>\n<p>在浏览器中输入：<a href=\"http://localhost:8080/SpringBoot/hello\" target=\"_blank\" rel=\"noopener\">http://localhost:8080/SpringBoot/hello</a><br>得到返回：Hello world<br><img src=\"/img/work/14853239880359.jpg\" alt=\"\"></p>\n<p>具体输入日志如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  .   ____          _            __ _ _</span><br><span class=\"line\"> /\\\\ / ___&apos;_ __ _ _(_)_ __  __ _ \\ \\ \\ \\</span><br><span class=\"line\">( ( )\\___ | &apos;_ | &apos;_| | &apos;_ \\/ _` | \\ \\ \\ \\</span><br><span class=\"line\"> \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )</span><br><span class=\"line\">  &apos;  |____| .__|_| |_|_| |_\\__, | / / / /</span><br><span class=\"line\"> =========|_|==============|___/=/_/_/_/</span><br><span class=\"line\"> :: Spring Boot ::        (v1.4.3.RELEASE)</span><br><span class=\"line\"></span><br><span class=\"line\">2017-01-25 13:55:36.298  INFO 30221 --- [           main] com.yany.Application                     : Starting Application on yanyongdeMacBook-Pro.local with PID 30221 (/Users/yanyong/GitHub/YanY/SpringDemo/SpringBoot/target/classes started by yanyong in /Users/yanyong/GitHub/YanY/SpringDemo)</span><br><span class=\"line\">2017-01-25 13:55:36.301  INFO 30221 --- [           main] com.yany.Application                     : No active profile set, falling back to default profiles: default</span><br><span class=\"line\">2017-01-25 13:55:36.373  INFO 30221 --- [           main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d8b20a0: startup date [Wed Jan 25 13:55:36 CST 2017]; root of context hierarchy</span><br><span class=\"line\">2017-01-25 13:55:37.264  WARN 30221 --- [           main] o.m.s.mapper.ClassPathMapperScanner      : No MyBatis mapper was found in &apos;[com.yany]&apos; package. Please check your configuration.</span><br><span class=\"line\">2017-01-25 13:55:37.570  INFO 30221 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean &apos;org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration&apos; of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$baf0e866] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)</span><br><span class=\"line\">2017-01-25 13:55:37.997  INFO 30221 --- [           main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)</span><br><span class=\"line\">2017-01-25 13:55:38.009  INFO 30221 --- [           main] o.apache.catalina.core.StandardService   : Starting service Tomcat</span><br><span class=\"line\">2017-01-25 13:55:38.010  INFO 30221 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.6</span><br><span class=\"line\">2017-01-25 13:55:38.136  INFO 30221 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext</span><br><span class=\"line\">2017-01-25 13:55:38.136  INFO 30221 --- [ost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1767 ms</span><br><span class=\"line\">2017-01-25 13:55:38.298  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: &apos;dispatcherServlet&apos; to [/]</span><br><span class=\"line\">2017-01-25 13:55:38.302  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: &apos;characterEncodingFilter&apos; to: [/*]</span><br><span class=\"line\">2017-01-25 13:55:38.302  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: &apos;hiddenHttpMethodFilter&apos; to: [/*]</span><br><span class=\"line\">2017-01-25 13:55:38.303  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: &apos;httpPutFormContentFilter&apos; to: [/*]</span><br><span class=\"line\">2017-01-25 13:55:38.303  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: &apos;requestContextFilter&apos; to: [/*]</span><br><span class=\"line\">2017-01-25 13:55:38.613  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d8b20a0: startup date [Wed Jan 25 13:55:36 CST 2017]; root of context hierarchy</span><br><span class=\"line\">2017-01-25 13:55:38.674  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;&#123;[/hello],methods=[GET]&#125;&quot; onto public java.lang.String com.yany.controller.Example.test()</span><br><span class=\"line\">2017-01-25 13:55:38.678  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;&#123;[/error]&#125;&quot; onto public org.springframework.http.ResponseEntity&lt;java.util.Map&lt;java.lang.String, java.lang.Object&gt;&gt; org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)</span><br><span class=\"line\">2017-01-25 13:55:38.678  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;&#123;[/error],produces=[text/html]&#125;&quot; onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)</span><br><span class=\"line\">2017-01-25 13:55:38.712  INFO 30221 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]</span><br><span class=\"line\">2017-01-25 13:55:38.712  INFO 30221 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]</span><br><span class=\"line\">2017-01-25 13:55:38.752  INFO 30221 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]</span><br><span class=\"line\">2017-01-25 13:55:39.333  INFO 30221 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup</span><br><span class=\"line\">2017-01-25 13:55:39.385  INFO 30221 --- [           main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)</span><br><span class=\"line\">2017-01-25 13:55:39.388  INFO 30221 --- [           main] com.yany.Application                     : Started Application in 3.752 seconds (JVM running for 4.078)</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>Spring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can “just run”. We take an opinionated view of the Spring platform and third-party libraries so you can get started with minimum fuss. Most Spring Boot applications need very little Spring configuration.<br>简言之：方便创建一个最小规模的Spring工程，且它只需要很少的Spring配置</p>\n</blockquote>\n<h3 id=\"特征\"><a href=\"#特征\" class=\"headerlink\" title=\"特征\"></a>特征</h3><ul>\n<li>Create stand-alone Spring applications</li>\n<li>Embed（内置、嵌入） Tomcat, Jetty or Undertow directly (no need to deploy WAR files)</li>\n<li>Provide opinionated ‘starter’ POMs to simplify your Maven configuration</li>\n<li>Automatically configure Spring whenever possible</li>\n<li>Provide production-ready features such as metrics, health checks and externalized configuration（提供产品化的功能）</li>\n<li>Absolutely no code generation and no requirement for XML configuration</li>\n</ul>\n<h3 id=\"Spring-Boot工程简单搭建\"><a href=\"#Spring-Boot工程简单搭建\" class=\"headerlink\" title=\"Spring-Boot工程简单搭建\"></a>Spring-Boot工程简单搭建</h3><blockquote>\n<p>Spring-boot文档：<a href=\"http://docs.spring.io/spring-boot/docs/current/reference/html/\" target=\"_blank\" rel=\"noopener\">http://docs.spring.io/spring-boot/docs/current/reference/html/</a><br>具体代码详见：<a href=\"https://github.com/yany8060/SpringDemo\" target=\"_blank\" rel=\"noopener\">https://github.com/yany8060/SpringDemo</a></p>\n</blockquote>\n<h4 id=\"pom-xml详情（本工程以maven方式搭建）：\"><a href=\"#pom-xml详情（本工程以maven方式搭建）：\" class=\"headerlink\" title=\"pom.xml详情（本工程以maven方式搭建）：\"></a>pom.xml详情（本工程以maven方式搭建）：</h4><p>官方建议引入父工程<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;properties&gt; </span><br><span class=\"line\">\t&lt;java.version&gt;1.7&lt;/java.version&gt;</span><br><span class=\"line\">\t&lt;spring.boot.version&gt;1.4.3.RELEASE&lt;/spring.boot.version&gt;</span><br><span class=\"line\">&lt;/properties&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class=\"line\">\t&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</span><br><span class=\"line\">\t&lt;version&gt;$&#123;spring.boot.version&#125;&lt;/version&gt;</span><br><span class=\"line\">\t&lt;type&gt;pom&lt;/type&gt;</span><br><span class=\"line\">\t&lt;scope&gt;import&lt;/scope&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p>\n<p>在子工程中引入自己所需要的依赖（版本号有父工程管理）：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;scope&gt;test&lt;/scope&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class=\"line\">\t&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p>\n<p>并添加maven编译插件：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;plugin&gt;</span><br><span class=\"line\">\t&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class=\"line\">\t&lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;</span><br><span class=\"line\">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure></p>\n<p>更多SpringBoot Maven插件详见：<a href=\"http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/maven-plugin/index.html\" target=\"_blank\" rel=\"noopener\">http://docs.spring.io/spring-boot/docs/1.4.3.RELEASE/maven-plugin/index.html</a></p>\n<h4 id=\"创建一个启动入口（应用类）\"><a href=\"#创建一个启动入口（应用类）\" class=\"headerlink\" title=\"创建一个启动入口（应用类）\"></a>创建一个启动入口（应用类）</h4><p>我们创建一个Application类：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@EnableAutoConfiguration</span></span><br><span class=\"line\"><span class=\"meta\">@ComponentScan</span>(basePackages = <span class=\"string\">\"com.yany\"</span>)</span><br><span class=\"line\"><span class=\"meta\">@Configuration</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Application</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        SpringApplication.run(Application.class);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><code>@EnableAutoConfiguration</code><br>开启自动配置<br>这个注解告诉Spring Boot根据添加的jar依赖猜测你想如何配置Spring<br><code>@ComponentScan</code><br>Spring原注解，扫描包加载bean<br><code>@Configuration</code><br>标注一个类为配置类</p>\n<p>我们再创建一个Controller层：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@RestController</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Example</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@RequestMapping</span>(value = <span class=\"string\">\"/hello\"</span>, method = &#123;RequestMethod.GET&#125;)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">test</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">\"Hello world\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><code>@RestController</code><br>相当于同时添加@Controller和@ResponseBody注解。</p>\n<p>这时一个基本的Spring-Boot的工程就创建完了，里面包含一个了Mapping映射，可通过访问：<a href=\"http://localhost:8080/SpringBoot/hello\" target=\"_blank\" rel=\"noopener\">http://localhost:8080/SpringBoot/hello</a> 来得到返回值</p>\n<h4 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h4><p>以main方法方式启动Application类，</p>\n<p>在浏览器中输入：<a href=\"http://localhost:8080/SpringBoot/hello\" target=\"_blank\" rel=\"noopener\">http://localhost:8080/SpringBoot/hello</a><br>得到返回：Hello world<br><img src=\"/img/work/14853239880359.jpg\" alt=\"\"></p>\n<p>具体输入日志如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  .   ____          _            __ _ _</span><br><span class=\"line\"> /\\\\ / ___&apos;_ __ _ _(_)_ __  __ _ \\ \\ \\ \\</span><br><span class=\"line\">( ( )\\___ | &apos;_ | &apos;_| | &apos;_ \\/ _` | \\ \\ \\ \\</span><br><span class=\"line\"> \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )</span><br><span class=\"line\">  &apos;  |____| .__|_| |_|_| |_\\__, | / / / /</span><br><span class=\"line\"> =========|_|==============|___/=/_/_/_/</span><br><span class=\"line\"> :: Spring Boot ::        (v1.4.3.RELEASE)</span><br><span class=\"line\"></span><br><span class=\"line\">2017-01-25 13:55:36.298  INFO 30221 --- [           main] com.yany.Application                     : Starting Application on yanyongdeMacBook-Pro.local with PID 30221 (/Users/yanyong/GitHub/YanY/SpringDemo/SpringBoot/target/classes started by yanyong in /Users/yanyong/GitHub/YanY/SpringDemo)</span><br><span class=\"line\">2017-01-25 13:55:36.301  INFO 30221 --- [           main] com.yany.Application                     : No active profile set, falling back to default profiles: default</span><br><span class=\"line\">2017-01-25 13:55:36.373  INFO 30221 --- [           main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d8b20a0: startup date [Wed Jan 25 13:55:36 CST 2017]; root of context hierarchy</span><br><span class=\"line\">2017-01-25 13:55:37.264  WARN 30221 --- [           main] o.m.s.mapper.ClassPathMapperScanner      : No MyBatis mapper was found in &apos;[com.yany]&apos; package. Please check your configuration.</span><br><span class=\"line\">2017-01-25 13:55:37.570  INFO 30221 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean &apos;org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration&apos; of type [class org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$baf0e866] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)</span><br><span class=\"line\">2017-01-25 13:55:37.997  INFO 30221 --- [           main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)</span><br><span class=\"line\">2017-01-25 13:55:38.009  INFO 30221 --- [           main] o.apache.catalina.core.StandardService   : Starting service Tomcat</span><br><span class=\"line\">2017-01-25 13:55:38.010  INFO 30221 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.6</span><br><span class=\"line\">2017-01-25 13:55:38.136  INFO 30221 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext</span><br><span class=\"line\">2017-01-25 13:55:38.136  INFO 30221 --- [ost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1767 ms</span><br><span class=\"line\">2017-01-25 13:55:38.298  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: &apos;dispatcherServlet&apos; to [/]</span><br><span class=\"line\">2017-01-25 13:55:38.302  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: &apos;characterEncodingFilter&apos; to: [/*]</span><br><span class=\"line\">2017-01-25 13:55:38.302  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: &apos;hiddenHttpMethodFilter&apos; to: [/*]</span><br><span class=\"line\">2017-01-25 13:55:38.303  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: &apos;httpPutFormContentFilter&apos; to: [/*]</span><br><span class=\"line\">2017-01-25 13:55:38.303  INFO 30221 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: &apos;requestContextFilter&apos; to: [/*]</span><br><span class=\"line\">2017-01-25 13:55:38.613  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d8b20a0: startup date [Wed Jan 25 13:55:36 CST 2017]; root of context hierarchy</span><br><span class=\"line\">2017-01-25 13:55:38.674  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;&#123;[/hello],methods=[GET]&#125;&quot; onto public java.lang.String com.yany.controller.Example.test()</span><br><span class=\"line\">2017-01-25 13:55:38.678  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;&#123;[/error]&#125;&quot; onto public org.springframework.http.ResponseEntity&lt;java.util.Map&lt;java.lang.String, java.lang.Object&gt;&gt; org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)</span><br><span class=\"line\">2017-01-25 13:55:38.678  INFO 30221 --- [           main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;&#123;[/error],produces=[text/html]&#125;&quot; onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)</span><br><span class=\"line\">2017-01-25 13:55:38.712  INFO 30221 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]</span><br><span class=\"line\">2017-01-25 13:55:38.712  INFO 30221 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]</span><br><span class=\"line\">2017-01-25 13:55:38.752  INFO 30221 --- [           main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]</span><br><span class=\"line\">2017-01-25 13:55:39.333  INFO 30221 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup</span><br><span class=\"line\">2017-01-25 13:55:39.385  INFO 30221 --- [           main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)</span><br><span class=\"line\">2017-01-25 13:55:39.388  INFO 30221 --- [           main] com.yany.Application                     : Started Application in 3.752 seconds (JVM running for 4.078)</span><br></pre></td></tr></table></figure></p>\n"},{"title":"Spring-boot MyBatis配置-1","date":"2017-02-04T03:08:22.000Z","_content":"> 本例使用mysql作为数据库，使用druid作为数据库连接池\n> 主要有单数据源和多数据源实例\n> 多数据源中又分为：1. 分包形式 2. aop形式 3. 注解形式\n\n### 项目目录结构\n![catalog.png](http://upload-images.jianshu.io/upload_images/1419542-fa4ab411fc0cd9a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/324)\n\n[comment]: <> ( ![](/img/work/catalog.png) )\n\n### MyBatis配置实现\n> springBoot相比于原来的Spring的模式就是减少xml配置，将它们用java代码实现。\n\n1. DataSource的bean，主要配置数据来源\n2. SqlSessionFactoryBean的bean，引用 datasource，MyBatis配置，sql的xml扫描，以及各个插件的添加\n3. MapperScannerConfigurer的bean的，主要设置基本扫描包，引用SqlSessionFactoryBean\n4. DataSourceTransactionManager的bean，主要用设置事务\n\n### 添加maven依赖\n```\n        <!-- aop -->        \n        <dependency>\n            <groupId>org.aspectj</groupId>\n            <artifactId>aspectjweaver</artifactId>\n            <version>1.8.4</version>\n        </dependency>\n        <!-- dataSource start -->\n        <dependency>\n            <groupId>org.mybatis.spring.boot</groupId>\n            <artifactId>mybatis-spring-boot-starter</artifactId>\n            <version>1.2.0</version>\n        </dependency>\n        <dependency>\n            <groupId>mysql</groupId>\n            <artifactId>mysql-connector-java</artifactId>\n            <version>5.1.38</version>\n        </dependency>\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>druid</artifactId>\n            <version>1.0.20</version>\n        </dependency>\n        <dependency>\n            <groupId>com.github.pagehelper</groupId>\n            <artifactId>pagehelper</artifactId>\n            <version>5.0.0</version>\n        </dependency>\n        <!-- dataSource end -->\n```\n\n### 单数据源\n#### 基本配置\n在application.yml中添加datasource配置：\n```\nspring:\n  application:\n    name: SpringBoot\n  datasource:\n    url: jdbc:mysql://localhost:3306/YanYPro?useUnicode=true&characterEncoding=UTF-8&&useSSL=false\n    username: root\n    password: *****\n    driver-class-name: com.mysql.jdbc.Driver\n    # 使用druid数据源\n    type: com.alibaba.druid.pool.DruidDataSource\n    # 初始化大小，最小，最大\n    initialSize: 5\n    minIdle: 5\n    maxActive: 20\n    # 配置获取连接等待超时的时间\n    maxWait: 60000\n    # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒\n    timeBetweenEvictionRunsMillis: 60000\n    # 配置一个连接在池中最小生存的时间，单位是毫秒\n    minEvictableIdleTimeMillis: 300000\n    validationQuery: SELECT 1 FROM DUAL\n    testWhileIdle: true\n    testOnBorrow: false\n    testOnReturn: false\n    # 打开PSCache，并且指定每个连接上PSCache的大小\n    poolPreparedStatements: true\n    maxPoolPreparedStatementPerConnectionSize: 20\n    # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙\n    filters: stat,wall,log4j\n    # 通过connectProperties属性来打开mergeSql功能；慢SQL记录\n    connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000\n    # 合并多个DruidDataSource的监控数据\n    useGlobalDataSourceStat: true\n```\n配置mybatis-config:\n以下只是实例，可自定义添加一些别的配置\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?><!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n<configuration>\n    <!-- 全局参数 -->\n    <settings>\n        <!-- 使全局的映射器启用或禁用缓存。 -->\n        <setting name=\"cacheEnabled\" value=\"true\"/>\n        <!-- 全局启用或禁用延迟加载。当禁用时，所有关联对象都会即时加载。 -->\n        <setting name=\"lazyLoadingEnabled\" value=\"true\"/>\n        <!-- 当启用时，有延迟加载属性的对象在被调用时将会完全加载任意属性。否则，每种属性将会按需要加载。 -->\n        <setting name=\"aggressiveLazyLoading\" value=\"true\"/>\n        <!-- 是否允许单条sql 返回多个数据集  (取决于驱动的兼容性) default:true -->\n        <setting name=\"multipleResultSetsEnabled\" value=\"true\"/>\n        <!-- 是否可以使用列的别名 (取决于驱动的兼容性) default:true -->\n        <setting name=\"useColumnLabel\" value=\"true\"/>\n        <!-- 允许JDBC 生成主键。需要驱动器支持。如果设为了true，这个设置将强制使用被生成的主键，有一些驱动器不兼容不过仍然可以执行。  default:false  -->\n        <setting name=\"useGeneratedKeys\" value=\"true\"/>\n        <!-- 指定 MyBatis 如何自动映射 数据基表的列 NONE：不隐射　PARTIAL:部分  FULL:全部  -->\n        <setting name=\"autoMappingBehavior\" value=\"PARTIAL\"/>\n        <!-- 这是默认的执行类型  （SIMPLE: 简单； REUSE: 执行器可能重复使用prepared statements语句；BATCH: 执行器可以重复执行语句和批量更新）  -->\n        <setting name=\"defaultExecutorType\" value=\"SIMPLE\"/>\n        <!-- 使用驼峰命名法转换字段。 -->\n        <setting name=\"mapUnderscoreToCamelCase\" value=\"true\"/>\n        <!-- 设置本地缓存范围 session:就会有数据的共享  statement:语句范围 (这样就不会有数据的共享 ) defalut:session -->\n        <setting name=\"localCacheScope\" value=\"SESSION\"/>\n        <!-- 设置但JDBC类型为空时,某些驱动程序 要指定值,default:OTHER，插入空值时不需要指定类型 -->\n        <setting name=\"jdbcTypeForNull\" value=\"NULL\"/>\n    </settings>\n</configuration>\n```\n#### 代码实现\n##### SingleMyBatisConfig的类实现\n继承EnvironmentAware并实现setEnvironment，为了获取默认配置文件application.yml的元素。\n```java\n@Configuration\npublic class SingleMyBatisConfig implements EnvironmentAware{\n  private final static Logger logger = LoggerFactory.getLogger(SingleMyBatisConfig.class);\n    private static String MYBATIS_CONFIG = \"mybatis-config.xml\";\n    //mybatis mapper resource 路径\n    private static String MAPPER_PATH = \"classpath:/com/yany/mapper/single/**.xml\";\n    \n    private RelaxedPropertyResolver propertyResolver;\n    @Override\n    public void setEnvironment(Environment environment) {\n        this.propertyResolver = new RelaxedPropertyResolver(environment, \"spring.datasource.\");\n    }\n\n  .......\n}\n```\n添加@Bean(name = \"singleDataSource\")，设置实现DataSource的bean\n```java\n    /**\n     * @return\n     * @Primary 优先方案，被注解的实现，优先被注入\n     */\n    @Primary\n    @Bean(name = \"singleDataSource\")\n    public DataSource singleDataSource() {\n        logger.info(\"datasource url:{}\", propertyResolver.getProperty(\"url\"));\n\n        DruidDataSource datasource = new DruidDataSource();\n        datasource.setUrl(propertyResolver.getProperty(\"url\"));\n        datasource.setDriverClassName(propertyResolver.getProperty(\"driver-class-name\"));\n        datasource.setUsername(propertyResolver.getProperty(\"username\"));\n        datasource.setPassword(propertyResolver.getProperty(\"password\"));\n\n\n        datasource.setInitialSize(Integer.valueOf(propertyResolver.getProperty(\"initialSize\")));\n        datasource.setMinIdle(Integer.valueOf(propertyResolver.getProperty(\"minIdle\")));\n        datasource.setMaxWait(Long.valueOf(propertyResolver.getProperty(\"maxWait\")));\n        datasource.setMaxActive(Integer.valueOf(propertyResolver.getProperty(\"maxActive\")));\n        datasource.setTimeBetweenEvictionRunsMillis(Long.valueOf(propertyResolver.getProperty(\"timeBetweenEvictionRunsMillis\")));\n        datasource.setMinEvictableIdleTimeMillis(Long.valueOf(propertyResolver.getProperty(\"minEvictableIdleTimeMillis\")));\n        datasource.setValidationQuery(propertyResolver.getProperty(\"validationQuery\"));\n        datasource.setTestWhileIdle(Boolean.parseBoolean(propertyResolver.getProperty(\"testWhileIdle\")));\n        datasource.setTestOnBorrow(Boolean.parseBoolean(propertyResolver.getProperty(\"testOnBorrow\")));\n        datasource.setTestOnReturn(Boolean.parseBoolean(propertyResolver.getProperty(\"testOnReturn\")));\n        datasource.setPoolPreparedStatements(Boolean.parseBoolean(propertyResolver.getProperty(\"poolPreparedStatements\")));\n        datasource.setMaxPoolPreparedStatementPerConnectionSize(Integer.valueOf(propertyResolver.getProperty(\"maxPoolPreparedStatementPerConnectionSize\")));\n\n        try {\n            datasource.setFilters(propertyResolver.getProperty(\"filters\"));\n        } catch (SQLException e) {\n            e.printStackTrace();\n        }\n        return datasource;\n\n    }\n```\n添加@Bean(name = \"singleSqlSessionFactory\")，设置实现SqlSessionFactoryBean\n```java\n/**\n     * 创建sqlSessionFactory实例\n     *\n     * @return\n     */\n    @Bean(name = \"singleSqlSessionFactory\")\n    @Primary\n    public SqlSessionFactoryBean createSqlSessionFactoryBean(@Qualifier(\"singleDataSource\") DataSource singleDataSource) throws IOException {\n        SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();\n        //设置mybatis configuration 扫描路径\n        sqlSessionFactoryBean.setConfigLocation(new ClassPathResource(MYBATIS_CONFIG));\n        sqlSessionFactoryBean.setDataSource(singleDataSource);\n\n        PathMatchingResourcePatternResolver pathMatchingResourcePatternResolver = new PathMatchingResourcePatternResolver();\n        sqlSessionFactoryBean.setMapperLocations(pathMatchingResourcePatternResolver.getResources(MAPPER_PATH));\n        return sqlSessionFactoryBean;\n    }\n```\n添加@Bean(name = \"singleTransactionManager\")，设置实现事务DataSourceTransactionManager\n```java\n    /**\n     * 配置事务管理器\n     */\n    @Bean(name = \"singleTransactionManager\")\n    @Primary\n    public DataSourceTransactionManager transactionManager(@Qualifier(\"singleDataSource\") DataSource singleDataSource) throws Exception {\n        return new DataSourceTransactionManager(singleDataSource);\n    }\n```\n以上SingleMyBatisConfig的配置完成，上面主要配置了数据源、SqlSessionFactoryBean、事务（DataSourceTransactionManager）。还差一个MapperScannerConfigurer的配置。\n\n#### MapperScannerConfig\n本来主要集中实现各个数据源的MapperScannerConfigurer\n```java\n@Configuration\npublic class MapperScannerConfig {\n\n    /**\n     * 单数据源配置\n     *\n     * @return\n     */\n    @Bean\n    public MapperScannerConfigurer createSingleMapperScannerConfigurer() {\n        System.out.println(\"singleDataSource\");\n        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();\n        mapperScannerConfigurer.setBasePackage(\"com.yany.dao.single\");\n        mapperScannerConfigurer.setSqlSessionFactoryBeanName(\"singleSqlSessionFactory\");\n        return mapperScannerConfigurer;\n    }\n}\n```\n\n以上即为单数据源使用配置，而具体的dao层的编写以及sql的xml编写详情见：https://github.com/yany8060/SpringDemo.git\ncom.yany.dao.single中编写单属于的到接口\ncom.yany.mapper.single中编写对应的sql的xml\n\n****\n由于贴了比较多的代码，在下一篇多数据中中将直接类比这篇中的代码\n详情请见：https://github.com/yany8060/SpringDemo.git\n博客：http://yany8060.xyz\n","source":"_posts/Spring-boot-MyBatis配置-1.md","raw":"---\ntitle: Spring-boot MyBatis配置-1\ndate: 2017-02-04 11:08:22\ntags: [spring-boot,spring]\ncategories: [java]\n---\n> 本例使用mysql作为数据库，使用druid作为数据库连接池\n> 主要有单数据源和多数据源实例\n> 多数据源中又分为：1. 分包形式 2. aop形式 3. 注解形式\n\n### 项目目录结构\n![catalog.png](http://upload-images.jianshu.io/upload_images/1419542-fa4ab411fc0cd9a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/324)\n\n[comment]: <> ( ![](/img/work/catalog.png) )\n\n### MyBatis配置实现\n> springBoot相比于原来的Spring的模式就是减少xml配置，将它们用java代码实现。\n\n1. DataSource的bean，主要配置数据来源\n2. SqlSessionFactoryBean的bean，引用 datasource，MyBatis配置，sql的xml扫描，以及各个插件的添加\n3. MapperScannerConfigurer的bean的，主要设置基本扫描包，引用SqlSessionFactoryBean\n4. DataSourceTransactionManager的bean，主要用设置事务\n\n### 添加maven依赖\n```\n        <!-- aop -->        \n        <dependency>\n            <groupId>org.aspectj</groupId>\n            <artifactId>aspectjweaver</artifactId>\n            <version>1.8.4</version>\n        </dependency>\n        <!-- dataSource start -->\n        <dependency>\n            <groupId>org.mybatis.spring.boot</groupId>\n            <artifactId>mybatis-spring-boot-starter</artifactId>\n            <version>1.2.0</version>\n        </dependency>\n        <dependency>\n            <groupId>mysql</groupId>\n            <artifactId>mysql-connector-java</artifactId>\n            <version>5.1.38</version>\n        </dependency>\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>druid</artifactId>\n            <version>1.0.20</version>\n        </dependency>\n        <dependency>\n            <groupId>com.github.pagehelper</groupId>\n            <artifactId>pagehelper</artifactId>\n            <version>5.0.0</version>\n        </dependency>\n        <!-- dataSource end -->\n```\n\n### 单数据源\n#### 基本配置\n在application.yml中添加datasource配置：\n```\nspring:\n  application:\n    name: SpringBoot\n  datasource:\n    url: jdbc:mysql://localhost:3306/YanYPro?useUnicode=true&characterEncoding=UTF-8&&useSSL=false\n    username: root\n    password: *****\n    driver-class-name: com.mysql.jdbc.Driver\n    # 使用druid数据源\n    type: com.alibaba.druid.pool.DruidDataSource\n    # 初始化大小，最小，最大\n    initialSize: 5\n    minIdle: 5\n    maxActive: 20\n    # 配置获取连接等待超时的时间\n    maxWait: 60000\n    # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒\n    timeBetweenEvictionRunsMillis: 60000\n    # 配置一个连接在池中最小生存的时间，单位是毫秒\n    minEvictableIdleTimeMillis: 300000\n    validationQuery: SELECT 1 FROM DUAL\n    testWhileIdle: true\n    testOnBorrow: false\n    testOnReturn: false\n    # 打开PSCache，并且指定每个连接上PSCache的大小\n    poolPreparedStatements: true\n    maxPoolPreparedStatementPerConnectionSize: 20\n    # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙\n    filters: stat,wall,log4j\n    # 通过connectProperties属性来打开mergeSql功能；慢SQL记录\n    connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000\n    # 合并多个DruidDataSource的监控数据\n    useGlobalDataSourceStat: true\n```\n配置mybatis-config:\n以下只是实例，可自定义添加一些别的配置\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?><!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n<configuration>\n    <!-- 全局参数 -->\n    <settings>\n        <!-- 使全局的映射器启用或禁用缓存。 -->\n        <setting name=\"cacheEnabled\" value=\"true\"/>\n        <!-- 全局启用或禁用延迟加载。当禁用时，所有关联对象都会即时加载。 -->\n        <setting name=\"lazyLoadingEnabled\" value=\"true\"/>\n        <!-- 当启用时，有延迟加载属性的对象在被调用时将会完全加载任意属性。否则，每种属性将会按需要加载。 -->\n        <setting name=\"aggressiveLazyLoading\" value=\"true\"/>\n        <!-- 是否允许单条sql 返回多个数据集  (取决于驱动的兼容性) default:true -->\n        <setting name=\"multipleResultSetsEnabled\" value=\"true\"/>\n        <!-- 是否可以使用列的别名 (取决于驱动的兼容性) default:true -->\n        <setting name=\"useColumnLabel\" value=\"true\"/>\n        <!-- 允许JDBC 生成主键。需要驱动器支持。如果设为了true，这个设置将强制使用被生成的主键，有一些驱动器不兼容不过仍然可以执行。  default:false  -->\n        <setting name=\"useGeneratedKeys\" value=\"true\"/>\n        <!-- 指定 MyBatis 如何自动映射 数据基表的列 NONE：不隐射　PARTIAL:部分  FULL:全部  -->\n        <setting name=\"autoMappingBehavior\" value=\"PARTIAL\"/>\n        <!-- 这是默认的执行类型  （SIMPLE: 简单； REUSE: 执行器可能重复使用prepared statements语句；BATCH: 执行器可以重复执行语句和批量更新）  -->\n        <setting name=\"defaultExecutorType\" value=\"SIMPLE\"/>\n        <!-- 使用驼峰命名法转换字段。 -->\n        <setting name=\"mapUnderscoreToCamelCase\" value=\"true\"/>\n        <!-- 设置本地缓存范围 session:就会有数据的共享  statement:语句范围 (这样就不会有数据的共享 ) defalut:session -->\n        <setting name=\"localCacheScope\" value=\"SESSION\"/>\n        <!-- 设置但JDBC类型为空时,某些驱动程序 要指定值,default:OTHER，插入空值时不需要指定类型 -->\n        <setting name=\"jdbcTypeForNull\" value=\"NULL\"/>\n    </settings>\n</configuration>\n```\n#### 代码实现\n##### SingleMyBatisConfig的类实现\n继承EnvironmentAware并实现setEnvironment，为了获取默认配置文件application.yml的元素。\n```java\n@Configuration\npublic class SingleMyBatisConfig implements EnvironmentAware{\n  private final static Logger logger = LoggerFactory.getLogger(SingleMyBatisConfig.class);\n    private static String MYBATIS_CONFIG = \"mybatis-config.xml\";\n    //mybatis mapper resource 路径\n    private static String MAPPER_PATH = \"classpath:/com/yany/mapper/single/**.xml\";\n    \n    private RelaxedPropertyResolver propertyResolver;\n    @Override\n    public void setEnvironment(Environment environment) {\n        this.propertyResolver = new RelaxedPropertyResolver(environment, \"spring.datasource.\");\n    }\n\n  .......\n}\n```\n添加@Bean(name = \"singleDataSource\")，设置实现DataSource的bean\n```java\n    /**\n     * @return\n     * @Primary 优先方案，被注解的实现，优先被注入\n     */\n    @Primary\n    @Bean(name = \"singleDataSource\")\n    public DataSource singleDataSource() {\n        logger.info(\"datasource url:{}\", propertyResolver.getProperty(\"url\"));\n\n        DruidDataSource datasource = new DruidDataSource();\n        datasource.setUrl(propertyResolver.getProperty(\"url\"));\n        datasource.setDriverClassName(propertyResolver.getProperty(\"driver-class-name\"));\n        datasource.setUsername(propertyResolver.getProperty(\"username\"));\n        datasource.setPassword(propertyResolver.getProperty(\"password\"));\n\n\n        datasource.setInitialSize(Integer.valueOf(propertyResolver.getProperty(\"initialSize\")));\n        datasource.setMinIdle(Integer.valueOf(propertyResolver.getProperty(\"minIdle\")));\n        datasource.setMaxWait(Long.valueOf(propertyResolver.getProperty(\"maxWait\")));\n        datasource.setMaxActive(Integer.valueOf(propertyResolver.getProperty(\"maxActive\")));\n        datasource.setTimeBetweenEvictionRunsMillis(Long.valueOf(propertyResolver.getProperty(\"timeBetweenEvictionRunsMillis\")));\n        datasource.setMinEvictableIdleTimeMillis(Long.valueOf(propertyResolver.getProperty(\"minEvictableIdleTimeMillis\")));\n        datasource.setValidationQuery(propertyResolver.getProperty(\"validationQuery\"));\n        datasource.setTestWhileIdle(Boolean.parseBoolean(propertyResolver.getProperty(\"testWhileIdle\")));\n        datasource.setTestOnBorrow(Boolean.parseBoolean(propertyResolver.getProperty(\"testOnBorrow\")));\n        datasource.setTestOnReturn(Boolean.parseBoolean(propertyResolver.getProperty(\"testOnReturn\")));\n        datasource.setPoolPreparedStatements(Boolean.parseBoolean(propertyResolver.getProperty(\"poolPreparedStatements\")));\n        datasource.setMaxPoolPreparedStatementPerConnectionSize(Integer.valueOf(propertyResolver.getProperty(\"maxPoolPreparedStatementPerConnectionSize\")));\n\n        try {\n            datasource.setFilters(propertyResolver.getProperty(\"filters\"));\n        } catch (SQLException e) {\n            e.printStackTrace();\n        }\n        return datasource;\n\n    }\n```\n添加@Bean(name = \"singleSqlSessionFactory\")，设置实现SqlSessionFactoryBean\n```java\n/**\n     * 创建sqlSessionFactory实例\n     *\n     * @return\n     */\n    @Bean(name = \"singleSqlSessionFactory\")\n    @Primary\n    public SqlSessionFactoryBean createSqlSessionFactoryBean(@Qualifier(\"singleDataSource\") DataSource singleDataSource) throws IOException {\n        SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();\n        //设置mybatis configuration 扫描路径\n        sqlSessionFactoryBean.setConfigLocation(new ClassPathResource(MYBATIS_CONFIG));\n        sqlSessionFactoryBean.setDataSource(singleDataSource);\n\n        PathMatchingResourcePatternResolver pathMatchingResourcePatternResolver = new PathMatchingResourcePatternResolver();\n        sqlSessionFactoryBean.setMapperLocations(pathMatchingResourcePatternResolver.getResources(MAPPER_PATH));\n        return sqlSessionFactoryBean;\n    }\n```\n添加@Bean(name = \"singleTransactionManager\")，设置实现事务DataSourceTransactionManager\n```java\n    /**\n     * 配置事务管理器\n     */\n    @Bean(name = \"singleTransactionManager\")\n    @Primary\n    public DataSourceTransactionManager transactionManager(@Qualifier(\"singleDataSource\") DataSource singleDataSource) throws Exception {\n        return new DataSourceTransactionManager(singleDataSource);\n    }\n```\n以上SingleMyBatisConfig的配置完成，上面主要配置了数据源、SqlSessionFactoryBean、事务（DataSourceTransactionManager）。还差一个MapperScannerConfigurer的配置。\n\n#### MapperScannerConfig\n本来主要集中实现各个数据源的MapperScannerConfigurer\n```java\n@Configuration\npublic class MapperScannerConfig {\n\n    /**\n     * 单数据源配置\n     *\n     * @return\n     */\n    @Bean\n    public MapperScannerConfigurer createSingleMapperScannerConfigurer() {\n        System.out.println(\"singleDataSource\");\n        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();\n        mapperScannerConfigurer.setBasePackage(\"com.yany.dao.single\");\n        mapperScannerConfigurer.setSqlSessionFactoryBeanName(\"singleSqlSessionFactory\");\n        return mapperScannerConfigurer;\n    }\n}\n```\n\n以上即为单数据源使用配置，而具体的dao层的编写以及sql的xml编写详情见：https://github.com/yany8060/SpringDemo.git\ncom.yany.dao.single中编写单属于的到接口\ncom.yany.mapper.single中编写对应的sql的xml\n\n****\n由于贴了比较多的代码，在下一篇多数据中中将直接类比这篇中的代码\n详情请见：https://github.com/yany8060/SpringDemo.git\n博客：http://yany8060.xyz\n","slug":"Spring-boot-MyBatis配置-1","published":1,"updated":"2018-09-03T12:29:46.719Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjmo9un7z001z9q0vflabgdc6","content":"<blockquote>\n<p>本例使用mysql作为数据库，使用druid作为数据库连接池<br>主要有单数据源和多数据源实例<br>多数据源中又分为：1. 分包形式 2. aop形式 3. 注解形式</p>\n</blockquote>\n<h3 id=\"项目目录结构\"><a href=\"#项目目录结构\" class=\"headerlink\" title=\"项目目录结构\"></a>项目目录结构</h3><p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-fa4ab411fc0cd9a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/324\" alt=\"catalog.png\"></p>\n<p>[comment]: &lt;&gt; ( <img src=\"/img/work/catalog.png\" alt=\"\"> )</p>\n<h3 id=\"MyBatis配置实现\"><a href=\"#MyBatis配置实现\" class=\"headerlink\" title=\"MyBatis配置实现\"></a>MyBatis配置实现</h3><blockquote>\n<p>springBoot相比于原来的Spring的模式就是减少xml配置，将它们用java代码实现。</p>\n</blockquote>\n<ol>\n<li>DataSource的bean，主要配置数据来源</li>\n<li>SqlSessionFactoryBean的bean，引用 datasource，MyBatis配置，sql的xml扫描，以及各个插件的添加</li>\n<li>MapperScannerConfigurer的bean的，主要设置基本扫描包，引用SqlSessionFactoryBean</li>\n<li>DataSourceTransactionManager的bean，主要用设置事务</li>\n</ol>\n<h3 id=\"添加maven依赖\"><a href=\"#添加maven依赖\" class=\"headerlink\" title=\"添加maven依赖\"></a>添加maven依赖</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!-- aop --&gt;        </span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;org.aspectj&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;version&gt;1.8.4&lt;/version&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;!-- dataSource start --&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;version&gt;1.2.0&lt;/version&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;mysql&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;version&gt;5.1.38&lt;/version&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;druid&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;version&gt;1.0.20&lt;/version&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;pagehelper&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;version&gt;5.0.0&lt;/version&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;!-- dataSource end --&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"单数据源\"><a href=\"#单数据源\" class=\"headerlink\" title=\"单数据源\"></a>单数据源</h3><h4 id=\"基本配置\"><a href=\"#基本配置\" class=\"headerlink\" title=\"基本配置\"></a>基本配置</h4><p>在application.yml中添加datasource配置：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">spring:</span><br><span class=\"line\">  application:</span><br><span class=\"line\">    name: SpringBoot</span><br><span class=\"line\">  datasource:</span><br><span class=\"line\">    url: jdbc:mysql://localhost:3306/YanYPro?useUnicode=true&amp;characterEncoding=UTF-8&amp;&amp;useSSL=false</span><br><span class=\"line\">    username: root</span><br><span class=\"line\">    password: *****</span><br><span class=\"line\">    driver-class-name: com.mysql.jdbc.Driver</span><br><span class=\"line\">    # 使用druid数据源</span><br><span class=\"line\">    type: com.alibaba.druid.pool.DruidDataSource</span><br><span class=\"line\">    # 初始化大小，最小，最大</span><br><span class=\"line\">    initialSize: 5</span><br><span class=\"line\">    minIdle: 5</span><br><span class=\"line\">    maxActive: 20</span><br><span class=\"line\">    # 配置获取连接等待超时的时间</span><br><span class=\"line\">    maxWait: 60000</span><br><span class=\"line\">    # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒</span><br><span class=\"line\">    timeBetweenEvictionRunsMillis: 60000</span><br><span class=\"line\">    # 配置一个连接在池中最小生存的时间，单位是毫秒</span><br><span class=\"line\">    minEvictableIdleTimeMillis: 300000</span><br><span class=\"line\">    validationQuery: SELECT 1 FROM DUAL</span><br><span class=\"line\">    testWhileIdle: true</span><br><span class=\"line\">    testOnBorrow: false</span><br><span class=\"line\">    testOnReturn: false</span><br><span class=\"line\">    # 打开PSCache，并且指定每个连接上PSCache的大小</span><br><span class=\"line\">    poolPreparedStatements: true</span><br><span class=\"line\">    maxPoolPreparedStatementPerConnectionSize: 20</span><br><span class=\"line\">    # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，&apos;wall&apos;用于防火墙</span><br><span class=\"line\">    filters: stat,wall,log4j</span><br><span class=\"line\">    # 通过connectProperties属性来打开mergeSql功能；慢SQL记录</span><br><span class=\"line\">    connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000</span><br><span class=\"line\">    # 合并多个DruidDataSource的监控数据</span><br><span class=\"line\">    useGlobalDataSourceStat: true</span><br></pre></td></tr></table></figure></p>\n<p>配置mybatis-config:<br>以下只是实例，可自定义添加一些别的配置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;</span><br><span class=\"line\">        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;</span><br><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">    &lt;!-- 全局参数 --&gt;</span><br><span class=\"line\">    &lt;settings&gt;</span><br><span class=\"line\">        &lt;!-- 使全局的映射器启用或禁用缓存。 --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 全局启用或禁用延迟加载。当禁用时，所有关联对象都会即时加载。 --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 当启用时，有延迟加载属性的对象在被调用时将会完全加载任意属性。否则，每种属性将会按需要加载。 --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;aggressiveLazyLoading&quot; value=&quot;true&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 是否允许单条sql 返回多个数据集  (取决于驱动的兼容性) default:true --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;multipleResultSetsEnabled&quot; value=&quot;true&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 是否可以使用列的别名 (取决于驱动的兼容性) default:true --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;useColumnLabel&quot; value=&quot;true&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 允许JDBC 生成主键。需要驱动器支持。如果设为了true，这个设置将强制使用被生成的主键，有一些驱动器不兼容不过仍然可以执行。  default:false  --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;useGeneratedKeys&quot; value=&quot;true&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 指定 MyBatis 如何自动映射 数据基表的列 NONE：不隐射　PARTIAL:部分  FULL:全部  --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;autoMappingBehavior&quot; value=&quot;PARTIAL&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 这是默认的执行类型  （SIMPLE: 简单； REUSE: 执行器可能重复使用prepared statements语句；BATCH: 执行器可以重复执行语句和批量更新）  --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;defaultExecutorType&quot; value=&quot;SIMPLE&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 使用驼峰命名法转换字段。 --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 设置本地缓存范围 session:就会有数据的共享  statement:语句范围 (这样就不会有数据的共享 ) defalut:session --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;localCacheScope&quot; value=&quot;SESSION&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 设置但JDBC类型为空时,某些驱动程序 要指定值,default:OTHER，插入空值时不需要指定类型 --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;jdbcTypeForNull&quot; value=&quot;NULL&quot;/&gt;</span><br><span class=\"line\">    &lt;/settings&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h4><h5 id=\"SingleMyBatisConfig的类实现\"><a href=\"#SingleMyBatisConfig的类实现\" class=\"headerlink\" title=\"SingleMyBatisConfig的类实现\"></a>SingleMyBatisConfig的类实现</h5><p>继承EnvironmentAware并实现setEnvironment，为了获取默认配置文件application.yml的元素。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Configuration</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SingleMyBatisConfig</span> <span class=\"keyword\">implements</span> <span class=\"title\">EnvironmentAware</span></span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> Logger logger = LoggerFactory.getLogger(SingleMyBatisConfig.class);</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> String MYBATIS_CONFIG = <span class=\"string\">\"mybatis-config.xml\"</span>;</span><br><span class=\"line\">    <span class=\"comment\">//mybatis mapper resource 路径</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> String MAPPER_PATH = <span class=\"string\">\"classpath:/com/yany/mapper/single/**.xml\"</span>;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">private</span> RelaxedPropertyResolver propertyResolver;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setEnvironment</span><span class=\"params\">(Environment environment)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.propertyResolver = <span class=\"keyword\">new</span> RelaxedPropertyResolver(environment, <span class=\"string\">\"spring.datasource.\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  .......</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>添加@Bean(name = “singleDataSource”)，设置实现DataSource的bean<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Primary</span> 优先方案，被注解的实现，优先被注入</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"meta\">@Primary</span></span><br><span class=\"line\"><span class=\"meta\">@Bean</span>(name = <span class=\"string\">\"singleDataSource\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> DataSource <span class=\"title\">singleDataSource</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    logger.info(<span class=\"string\">\"datasource url:&#123;&#125;\"</span>, propertyResolver.getProperty(<span class=\"string\">\"url\"</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">    DruidDataSource datasource = <span class=\"keyword\">new</span> DruidDataSource();</span><br><span class=\"line\">    datasource.setUrl(propertyResolver.getProperty(<span class=\"string\">\"url\"</span>));</span><br><span class=\"line\">    datasource.setDriverClassName(propertyResolver.getProperty(<span class=\"string\">\"driver-class-name\"</span>));</span><br><span class=\"line\">    datasource.setUsername(propertyResolver.getProperty(<span class=\"string\">\"username\"</span>));</span><br><span class=\"line\">    datasource.setPassword(propertyResolver.getProperty(<span class=\"string\">\"password\"</span>));</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    datasource.setInitialSize(Integer.valueOf(propertyResolver.getProperty(<span class=\"string\">\"initialSize\"</span>)));</span><br><span class=\"line\">    datasource.setMinIdle(Integer.valueOf(propertyResolver.getProperty(<span class=\"string\">\"minIdle\"</span>)));</span><br><span class=\"line\">    datasource.setMaxWait(Long.valueOf(propertyResolver.getProperty(<span class=\"string\">\"maxWait\"</span>)));</span><br><span class=\"line\">    datasource.setMaxActive(Integer.valueOf(propertyResolver.getProperty(<span class=\"string\">\"maxActive\"</span>)));</span><br><span class=\"line\">    datasource.setTimeBetweenEvictionRunsMillis(Long.valueOf(propertyResolver.getProperty(<span class=\"string\">\"timeBetweenEvictionRunsMillis\"</span>)));</span><br><span class=\"line\">    datasource.setMinEvictableIdleTimeMillis(Long.valueOf(propertyResolver.getProperty(<span class=\"string\">\"minEvictableIdleTimeMillis\"</span>)));</span><br><span class=\"line\">    datasource.setValidationQuery(propertyResolver.getProperty(<span class=\"string\">\"validationQuery\"</span>));</span><br><span class=\"line\">    datasource.setTestWhileIdle(Boolean.parseBoolean(propertyResolver.getProperty(<span class=\"string\">\"testWhileIdle\"</span>)));</span><br><span class=\"line\">    datasource.setTestOnBorrow(Boolean.parseBoolean(propertyResolver.getProperty(<span class=\"string\">\"testOnBorrow\"</span>)));</span><br><span class=\"line\">    datasource.setTestOnReturn(Boolean.parseBoolean(propertyResolver.getProperty(<span class=\"string\">\"testOnReturn\"</span>)));</span><br><span class=\"line\">    datasource.setPoolPreparedStatements(Boolean.parseBoolean(propertyResolver.getProperty(<span class=\"string\">\"poolPreparedStatements\"</span>)));</span><br><span class=\"line\">    datasource.setMaxPoolPreparedStatementPerConnectionSize(Integer.valueOf(propertyResolver.getProperty(<span class=\"string\">\"maxPoolPreparedStatementPerConnectionSize\"</span>)));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        datasource.setFilters(propertyResolver.getProperty(<span class=\"string\">\"filters\"</span>));</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (SQLException e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> datasource;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>添加@Bean(name = “singleSqlSessionFactory”)，设置实现SqlSessionFactoryBean<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 创建sqlSessionFactory实例</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Bean</span>(name = <span class=\"string\">\"singleSqlSessionFactory\"</span>)</span><br><span class=\"line\">    <span class=\"meta\">@Primary</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> SqlSessionFactoryBean <span class=\"title\">createSqlSessionFactoryBean</span><span class=\"params\">(@Qualifier(<span class=\"string\">\"singleDataSource\"</span>)</span> DataSource singleDataSource) <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">        SqlSessionFactoryBean sqlSessionFactoryBean = <span class=\"keyword\">new</span> SqlSessionFactoryBean();</span><br><span class=\"line\">        <span class=\"comment\">//设置mybatis configuration 扫描路径</span></span><br><span class=\"line\">        sqlSessionFactoryBean.setConfigLocation(<span class=\"keyword\">new</span> ClassPathResource(MYBATIS_CONFIG));</span><br><span class=\"line\">        sqlSessionFactoryBean.setDataSource(singleDataSource);</span><br><span class=\"line\"></span><br><span class=\"line\">        PathMatchingResourcePatternResolver pathMatchingResourcePatternResolver = <span class=\"keyword\">new</span> PathMatchingResourcePatternResolver();</span><br><span class=\"line\">        sqlSessionFactoryBean.setMapperLocations(pathMatchingResourcePatternResolver.getResources(MAPPER_PATH));</span><br><span class=\"line\">        <span class=\"keyword\">return</span> sqlSessionFactoryBean;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<p>添加@Bean(name = “singleTransactionManager”)，设置实现事务DataSourceTransactionManager<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 配置事务管理器</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"meta\">@Bean</span>(name = <span class=\"string\">\"singleTransactionManager\"</span>)</span><br><span class=\"line\"><span class=\"meta\">@Primary</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> DataSourceTransactionManager <span class=\"title\">transactionManager</span><span class=\"params\">(@Qualifier(<span class=\"string\">\"singleDataSource\"</span>)</span> DataSource singleDataSource) <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> DataSourceTransactionManager(singleDataSource);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>以上SingleMyBatisConfig的配置完成，上面主要配置了数据源、SqlSessionFactoryBean、事务（DataSourceTransactionManager）。还差一个MapperScannerConfigurer的配置。</p>\n<h4 id=\"MapperScannerConfig\"><a href=\"#MapperScannerConfig\" class=\"headerlink\" title=\"MapperScannerConfig\"></a>MapperScannerConfig</h4><p>本来主要集中实现各个数据源的MapperScannerConfigurer<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Configuration</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MapperScannerConfig</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 单数据源配置</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Bean</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> MapperScannerConfigurer <span class=\"title\">createSingleMapperScannerConfigurer</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"singleDataSource\"</span>);</span><br><span class=\"line\">        MapperScannerConfigurer mapperScannerConfigurer = <span class=\"keyword\">new</span> MapperScannerConfigurer();</span><br><span class=\"line\">        mapperScannerConfigurer.setBasePackage(<span class=\"string\">\"com.yany.dao.single\"</span>);</span><br><span class=\"line\">        mapperScannerConfigurer.setSqlSessionFactoryBeanName(<span class=\"string\">\"singleSqlSessionFactory\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> mapperScannerConfigurer;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>以上即为单数据源使用配置，而具体的dao层的编写以及sql的xml编写详情见：<a href=\"https://github.com/yany8060/SpringDemo.git\" target=\"_blank\" rel=\"noopener\">https://github.com/yany8060/SpringDemo.git</a><br>com.yany.dao.single中编写单属于的到接口<br>com.yany.mapper.single中编写对应的sql的xml</p>\n<hr>\n<p>由于贴了比较多的代码，在下一篇多数据中中将直接类比这篇中的代码<br>详情请见：<a href=\"https://github.com/yany8060/SpringDemo.git\" target=\"_blank\" rel=\"noopener\">https://github.com/yany8060/SpringDemo.git</a><br>博客：<a href=\"http://yany8060.xyz\" target=\"_blank\" rel=\"noopener\">http://yany8060.xyz</a></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>本例使用mysql作为数据库，使用druid作为数据库连接池<br>主要有单数据源和多数据源实例<br>多数据源中又分为：1. 分包形式 2. aop形式 3. 注解形式</p>\n</blockquote>\n<h3 id=\"项目目录结构\"><a href=\"#项目目录结构\" class=\"headerlink\" title=\"项目目录结构\"></a>项目目录结构</h3><p><img src=\"http://upload-images.jianshu.io/upload_images/1419542-fa4ab411fc0cd9a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/324\" alt=\"catalog.png\"></p>\n<p>[comment]: &lt;&gt; ( <img src=\"/img/work/catalog.png\" alt=\"\"> )</p>\n<h3 id=\"MyBatis配置实现\"><a href=\"#MyBatis配置实现\" class=\"headerlink\" title=\"MyBatis配置实现\"></a>MyBatis配置实现</h3><blockquote>\n<p>springBoot相比于原来的Spring的模式就是减少xml配置，将它们用java代码实现。</p>\n</blockquote>\n<ol>\n<li>DataSource的bean，主要配置数据来源</li>\n<li>SqlSessionFactoryBean的bean，引用 datasource，MyBatis配置，sql的xml扫描，以及各个插件的添加</li>\n<li>MapperScannerConfigurer的bean的，主要设置基本扫描包，引用SqlSessionFactoryBean</li>\n<li>DataSourceTransactionManager的bean，主要用设置事务</li>\n</ol>\n<h3 id=\"添加maven依赖\"><a href=\"#添加maven依赖\" class=\"headerlink\" title=\"添加maven依赖\"></a>添加maven依赖</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!-- aop --&gt;        </span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;org.aspectj&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;version&gt;1.8.4&lt;/version&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;!-- dataSource start --&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;version&gt;1.2.0&lt;/version&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;mysql&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;version&gt;5.1.38&lt;/version&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;druid&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;version&gt;1.0.20&lt;/version&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;pagehelper&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;version&gt;5.0.0&lt;/version&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;!-- dataSource end --&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"单数据源\"><a href=\"#单数据源\" class=\"headerlink\" title=\"单数据源\"></a>单数据源</h3><h4 id=\"基本配置\"><a href=\"#基本配置\" class=\"headerlink\" title=\"基本配置\"></a>基本配置</h4><p>在application.yml中添加datasource配置：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">spring:</span><br><span class=\"line\">  application:</span><br><span class=\"line\">    name: SpringBoot</span><br><span class=\"line\">  datasource:</span><br><span class=\"line\">    url: jdbc:mysql://localhost:3306/YanYPro?useUnicode=true&amp;characterEncoding=UTF-8&amp;&amp;useSSL=false</span><br><span class=\"line\">    username: root</span><br><span class=\"line\">    password: *****</span><br><span class=\"line\">    driver-class-name: com.mysql.jdbc.Driver</span><br><span class=\"line\">    # 使用druid数据源</span><br><span class=\"line\">    type: com.alibaba.druid.pool.DruidDataSource</span><br><span class=\"line\">    # 初始化大小，最小，最大</span><br><span class=\"line\">    initialSize: 5</span><br><span class=\"line\">    minIdle: 5</span><br><span class=\"line\">    maxActive: 20</span><br><span class=\"line\">    # 配置获取连接等待超时的时间</span><br><span class=\"line\">    maxWait: 60000</span><br><span class=\"line\">    # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒</span><br><span class=\"line\">    timeBetweenEvictionRunsMillis: 60000</span><br><span class=\"line\">    # 配置一个连接在池中最小生存的时间，单位是毫秒</span><br><span class=\"line\">    minEvictableIdleTimeMillis: 300000</span><br><span class=\"line\">    validationQuery: SELECT 1 FROM DUAL</span><br><span class=\"line\">    testWhileIdle: true</span><br><span class=\"line\">    testOnBorrow: false</span><br><span class=\"line\">    testOnReturn: false</span><br><span class=\"line\">    # 打开PSCache，并且指定每个连接上PSCache的大小</span><br><span class=\"line\">    poolPreparedStatements: true</span><br><span class=\"line\">    maxPoolPreparedStatementPerConnectionSize: 20</span><br><span class=\"line\">    # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，&apos;wall&apos;用于防火墙</span><br><span class=\"line\">    filters: stat,wall,log4j</span><br><span class=\"line\">    # 通过connectProperties属性来打开mergeSql功能；慢SQL记录</span><br><span class=\"line\">    connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000</span><br><span class=\"line\">    # 合并多个DruidDataSource的监控数据</span><br><span class=\"line\">    useGlobalDataSourceStat: true</span><br></pre></td></tr></table></figure></p>\n<p>配置mybatis-config:<br>以下只是实例，可自定义添加一些别的配置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;</span><br><span class=\"line\">        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;</span><br><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">    &lt;!-- 全局参数 --&gt;</span><br><span class=\"line\">    &lt;settings&gt;</span><br><span class=\"line\">        &lt;!-- 使全局的映射器启用或禁用缓存。 --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 全局启用或禁用延迟加载。当禁用时，所有关联对象都会即时加载。 --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 当启用时，有延迟加载属性的对象在被调用时将会完全加载任意属性。否则，每种属性将会按需要加载。 --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;aggressiveLazyLoading&quot; value=&quot;true&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 是否允许单条sql 返回多个数据集  (取决于驱动的兼容性) default:true --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;multipleResultSetsEnabled&quot; value=&quot;true&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 是否可以使用列的别名 (取决于驱动的兼容性) default:true --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;useColumnLabel&quot; value=&quot;true&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 允许JDBC 生成主键。需要驱动器支持。如果设为了true，这个设置将强制使用被生成的主键，有一些驱动器不兼容不过仍然可以执行。  default:false  --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;useGeneratedKeys&quot; value=&quot;true&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 指定 MyBatis 如何自动映射 数据基表的列 NONE：不隐射　PARTIAL:部分  FULL:全部  --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;autoMappingBehavior&quot; value=&quot;PARTIAL&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 这是默认的执行类型  （SIMPLE: 简单； REUSE: 执行器可能重复使用prepared statements语句；BATCH: 执行器可以重复执行语句和批量更新）  --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;defaultExecutorType&quot; value=&quot;SIMPLE&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 使用驼峰命名法转换字段。 --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 设置本地缓存范围 session:就会有数据的共享  statement:语句范围 (这样就不会有数据的共享 ) defalut:session --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;localCacheScope&quot; value=&quot;SESSION&quot;/&gt;</span><br><span class=\"line\">        &lt;!-- 设置但JDBC类型为空时,某些驱动程序 要指定值,default:OTHER，插入空值时不需要指定类型 --&gt;</span><br><span class=\"line\">        &lt;setting name=&quot;jdbcTypeForNull&quot; value=&quot;NULL&quot;/&gt;</span><br><span class=\"line\">    &lt;/settings&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h4><h5 id=\"SingleMyBatisConfig的类实现\"><a href=\"#SingleMyBatisConfig的类实现\" class=\"headerlink\" title=\"SingleMyBatisConfig的类实现\"></a>SingleMyBatisConfig的类实现</h5><p>继承EnvironmentAware并实现setEnvironment，为了获取默认配置文件application.yml的元素。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Configuration</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SingleMyBatisConfig</span> <span class=\"keyword\">implements</span> <span class=\"title\">EnvironmentAware</span></span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> Logger logger = LoggerFactory.getLogger(SingleMyBatisConfig.class);</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> String MYBATIS_CONFIG = <span class=\"string\">\"mybatis-config.xml\"</span>;</span><br><span class=\"line\">    <span class=\"comment\">//mybatis mapper resource 路径</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> String MAPPER_PATH = <span class=\"string\">\"classpath:/com/yany/mapper/single/**.xml\"</span>;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">private</span> RelaxedPropertyResolver propertyResolver;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setEnvironment</span><span class=\"params\">(Environment environment)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.propertyResolver = <span class=\"keyword\">new</span> RelaxedPropertyResolver(environment, <span class=\"string\">\"spring.datasource.\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  .......</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>添加@Bean(name = “singleDataSource”)，设置实现DataSource的bean<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Primary</span> 优先方案，被注解的实现，优先被注入</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"meta\">@Primary</span></span><br><span class=\"line\"><span class=\"meta\">@Bean</span>(name = <span class=\"string\">\"singleDataSource\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> DataSource <span class=\"title\">singleDataSource</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    logger.info(<span class=\"string\">\"datasource url:&#123;&#125;\"</span>, propertyResolver.getProperty(<span class=\"string\">\"url\"</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">    DruidDataSource datasource = <span class=\"keyword\">new</span> DruidDataSource();</span><br><span class=\"line\">    datasource.setUrl(propertyResolver.getProperty(<span class=\"string\">\"url\"</span>));</span><br><span class=\"line\">    datasource.setDriverClassName(propertyResolver.getProperty(<span class=\"string\">\"driver-class-name\"</span>));</span><br><span class=\"line\">    datasource.setUsername(propertyResolver.getProperty(<span class=\"string\">\"username\"</span>));</span><br><span class=\"line\">    datasource.setPassword(propertyResolver.getProperty(<span class=\"string\">\"password\"</span>));</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    datasource.setInitialSize(Integer.valueOf(propertyResolver.getProperty(<span class=\"string\">\"initialSize\"</span>)));</span><br><span class=\"line\">    datasource.setMinIdle(Integer.valueOf(propertyResolver.getProperty(<span class=\"string\">\"minIdle\"</span>)));</span><br><span class=\"line\">    datasource.setMaxWait(Long.valueOf(propertyResolver.getProperty(<span class=\"string\">\"maxWait\"</span>)));</span><br><span class=\"line\">    datasource.setMaxActive(Integer.valueOf(propertyResolver.getProperty(<span class=\"string\">\"maxActive\"</span>)));</span><br><span class=\"line\">    datasource.setTimeBetweenEvictionRunsMillis(Long.valueOf(propertyResolver.getProperty(<span class=\"string\">\"timeBetweenEvictionRunsMillis\"</span>)));</span><br><span class=\"line\">    datasource.setMinEvictableIdleTimeMillis(Long.valueOf(propertyResolver.getProperty(<span class=\"string\">\"minEvictableIdleTimeMillis\"</span>)));</span><br><span class=\"line\">    datasource.setValidationQuery(propertyResolver.getProperty(<span class=\"string\">\"validationQuery\"</span>));</span><br><span class=\"line\">    datasource.setTestWhileIdle(Boolean.parseBoolean(propertyResolver.getProperty(<span class=\"string\">\"testWhileIdle\"</span>)));</span><br><span class=\"line\">    datasource.setTestOnBorrow(Boolean.parseBoolean(propertyResolver.getProperty(<span class=\"string\">\"testOnBorrow\"</span>)));</span><br><span class=\"line\">    datasource.setTestOnReturn(Boolean.parseBoolean(propertyResolver.getProperty(<span class=\"string\">\"testOnReturn\"</span>)));</span><br><span class=\"line\">    datasource.setPoolPreparedStatements(Boolean.parseBoolean(propertyResolver.getProperty(<span class=\"string\">\"poolPreparedStatements\"</span>)));</span><br><span class=\"line\">    datasource.setMaxPoolPreparedStatementPerConnectionSize(Integer.valueOf(propertyResolver.getProperty(<span class=\"string\">\"maxPoolPreparedStatementPerConnectionSize\"</span>)));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        datasource.setFilters(propertyResolver.getProperty(<span class=\"string\">\"filters\"</span>));</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (SQLException e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> datasource;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>添加@Bean(name = “singleSqlSessionFactory”)，设置实现SqlSessionFactoryBean<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 创建sqlSessionFactory实例</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Bean</span>(name = <span class=\"string\">\"singleSqlSessionFactory\"</span>)</span><br><span class=\"line\">    <span class=\"meta\">@Primary</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> SqlSessionFactoryBean <span class=\"title\">createSqlSessionFactoryBean</span><span class=\"params\">(@Qualifier(<span class=\"string\">\"singleDataSource\"</span>)</span> DataSource singleDataSource) <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">        SqlSessionFactoryBean sqlSessionFactoryBean = <span class=\"keyword\">new</span> SqlSessionFactoryBean();</span><br><span class=\"line\">        <span class=\"comment\">//设置mybatis configuration 扫描路径</span></span><br><span class=\"line\">        sqlSessionFactoryBean.setConfigLocation(<span class=\"keyword\">new</span> ClassPathResource(MYBATIS_CONFIG));</span><br><span class=\"line\">        sqlSessionFactoryBean.setDataSource(singleDataSource);</span><br><span class=\"line\"></span><br><span class=\"line\">        PathMatchingResourcePatternResolver pathMatchingResourcePatternResolver = <span class=\"keyword\">new</span> PathMatchingResourcePatternResolver();</span><br><span class=\"line\">        sqlSessionFactoryBean.setMapperLocations(pathMatchingResourcePatternResolver.getResources(MAPPER_PATH));</span><br><span class=\"line\">        <span class=\"keyword\">return</span> sqlSessionFactoryBean;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<p>添加@Bean(name = “singleTransactionManager”)，设置实现事务DataSourceTransactionManager<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 配置事务管理器</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"meta\">@Bean</span>(name = <span class=\"string\">\"singleTransactionManager\"</span>)</span><br><span class=\"line\"><span class=\"meta\">@Primary</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> DataSourceTransactionManager <span class=\"title\">transactionManager</span><span class=\"params\">(@Qualifier(<span class=\"string\">\"singleDataSource\"</span>)</span> DataSource singleDataSource) <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> DataSourceTransactionManager(singleDataSource);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>以上SingleMyBatisConfig的配置完成，上面主要配置了数据源、SqlSessionFactoryBean、事务（DataSourceTransactionManager）。还差一个MapperScannerConfigurer的配置。</p>\n<h4 id=\"MapperScannerConfig\"><a href=\"#MapperScannerConfig\" class=\"headerlink\" title=\"MapperScannerConfig\"></a>MapperScannerConfig</h4><p>本来主要集中实现各个数据源的MapperScannerConfigurer<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Configuration</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MapperScannerConfig</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 单数据源配置</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Bean</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> MapperScannerConfigurer <span class=\"title\">createSingleMapperScannerConfigurer</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"singleDataSource\"</span>);</span><br><span class=\"line\">        MapperScannerConfigurer mapperScannerConfigurer = <span class=\"keyword\">new</span> MapperScannerConfigurer();</span><br><span class=\"line\">        mapperScannerConfigurer.setBasePackage(<span class=\"string\">\"com.yany.dao.single\"</span>);</span><br><span class=\"line\">        mapperScannerConfigurer.setSqlSessionFactoryBeanName(<span class=\"string\">\"singleSqlSessionFactory\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> mapperScannerConfigurer;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>以上即为单数据源使用配置，而具体的dao层的编写以及sql的xml编写详情见：<a href=\"https://github.com/yany8060/SpringDemo.git\" target=\"_blank\" rel=\"noopener\">https://github.com/yany8060/SpringDemo.git</a><br>com.yany.dao.single中编写单属于的到接口<br>com.yany.mapper.single中编写对应的sql的xml</p>\n<hr>\n<p>由于贴了比较多的代码，在下一篇多数据中中将直接类比这篇中的代码<br>详情请见：<a href=\"https://github.com/yany8060/SpringDemo.git\" target=\"_blank\" rel=\"noopener\">https://github.com/yany8060/SpringDemo.git</a><br>博客：<a href=\"http://yany8060.xyz\" target=\"_blank\" rel=\"noopener\">http://yany8060.xyz</a></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cjmo9un2k00009q0v9xlyzc9n","category_id":"cjmo9un2r00049q0vkjf4sqtx","_id":"cjmo9un33000f9q0vbs8o2l3k"},{"post_id":"cjmo9un2o00029q0vs1ijco55","category_id":"cjmo9un2r00049q0vkjf4sqtx","_id":"cjmo9un36000l9q0vd8wjvwl6"},{"post_id":"cjmo9un2t00069q0v917hd7kl","category_id":"cjmo9un2r00049q0vkjf4sqtx","_id":"cjmo9un3c000p9q0vbbxm4vwn"},{"post_id":"cjmo9un35000j9q0vg8h0c32y","category_id":"cjmo9un2r00049q0vkjf4sqtx","_id":"cjmo9un3d000t9q0v1ytyyfyr"},{"post_id":"cjmo9un2u00079q0vs0bqhb31","category_id":"cjmo9un36000k9q0vzc3t51jb","_id":"cjmo9un3d000v9q0vy3molqjl"},{"post_id":"cjmo9un2z000c9q0vu8cy5b12","category_id":"cjmo9un3c000q9q0v13fly64j","_id":"cjmo9un3e00119q0vvvgc1cbb"},{"post_id":"cjmo9un31000d9q0vizz2jax0","category_id":"cjmo9un3c000q9q0v13fly64j","_id":"cjmo9un3f00159q0v1em9pagk"},{"post_id":"cjmo9un34000i9q0ve480517c","category_id":"cjmo9un3c000q9q0v13fly64j","_id":"cjmo9un3g00189q0vu9ybknkl"},{"post_id":"cjmo9un3a000n9q0vz7zq5hka","category_id":"cjmo9un3f00149q0v42gps8rd","_id":"cjmo9un3g001c9q0v0lubdcqc"},{"post_id":"cjmo9un3b000o9q0ve240l4z5","category_id":"cjmo9un3g00199q0vvecg67po","_id":"cjmo9un3h001f9q0vm4oq5qbx"},{"post_id":"cjmo9un3c000s9q0vvmjpmxpr","category_id":"cjmo9un3g001d9q0vy4jjr9z3","_id":"cjmo9un3h001i9q0vjotcgkt4"},{"post_id":"cjmo9un7y001x9q0vcm7lwo35","category_id":"cjmo9un2r00049q0vkjf4sqtx","_id":"cjmo9un8200229q0vvl91c1de"},{"post_id":"cjmo9un7z001z9q0vflabgdc6","category_id":"cjmo9un2r00049q0vkjf4sqtx","_id":"cjmo9un8300249q0v7h4lho9k"}],"PostTag":[{"post_id":"cjmo9un2k00009q0v9xlyzc9n","tag_id":"cjmo9un2t00059q0vp4kesxa7","_id":"cjmo9un2z000b9q0vjk4cgy1w"},{"post_id":"cjmo9un2o00029q0vs1ijco55","tag_id":"cjmo9un2t00059q0vp4kesxa7","_id":"cjmo9un33000h9q0vj87lvfyu"},{"post_id":"cjmo9un2t00069q0v917hd7kl","tag_id":"cjmo9un33000g9q0v6lr9n36n","_id":"cjmo9un3d000u9q0vogr84clv"},{"post_id":"cjmo9un2t00069q0v917hd7kl","tag_id":"cjmo9un37000m9q0vzrir5fhz","_id":"cjmo9un3e000w9q0v8meyel6u"},{"post_id":"cjmo9un2u00079q0vs0bqhb31","tag_id":"cjmo9un3c000r9q0vg0e067e1","_id":"cjmo9un3e000z9q0vk6b549vf"},{"post_id":"cjmo9un2w00089q0v24hkiy7p","tag_id":"cjmo9un3e000y9q0vou4346wo","_id":"cjmo9un3f00139q0vo2in0y3c"},{"post_id":"cjmo9un2z000c9q0vu8cy5b12","tag_id":"cjmo9un3f00129q0vcmsvgf2g","_id":"cjmo9un3g00179q0ve2hf6alb"},{"post_id":"cjmo9un31000d9q0vizz2jax0","tag_id":"cjmo9un3f00129q0vcmsvgf2g","_id":"cjmo9un3g001b9q0vrq35efhe"},{"post_id":"cjmo9un34000i9q0ve480517c","tag_id":"cjmo9un3g001a9q0v05gg59km","_id":"cjmo9un3h001h9q0v523beytz"},{"post_id":"cjmo9un34000i9q0ve480517c","tag_id":"cjmo9un3f00129q0vcmsvgf2g","_id":"cjmo9un3h001j9q0v5ctf2v5p"},{"post_id":"cjmo9un35000j9q0vg8h0c32y","tag_id":"cjmo9un3h001g9q0v9418ecku","_id":"cjmo9un3i001m9q0v9gagbctj"},{"post_id":"cjmo9un35000j9q0vg8h0c32y","tag_id":"cjmo9un3i001k9q0vehcu47ai","_id":"cjmo9un3i001n9q0vydh8o5m6"},{"post_id":"cjmo9un3a000n9q0vz7zq5hka","tag_id":"cjmo9un3i001l9q0v69oabcf8","_id":"cjmo9un3j001p9q0v06nhtoo4"},{"post_id":"cjmo9un3b000o9q0ve240l4z5","tag_id":"cjmo9un3i001o9q0v9zxoixsh","_id":"cjmo9un3k001s9q0vwvgvx2bv"},{"post_id":"cjmo9un3b000o9q0ve240l4z5","tag_id":"cjmo9un3j001q9q0vxdp17rmc","_id":"cjmo9un3k001t9q0v9hb99w6r"},{"post_id":"cjmo9un3c000s9q0vvmjpmxpr","tag_id":"cjmo9un3k001r9q0v3w4gzt85","_id":"cjmo9un3k001v9q0vnaie5zue"},{"post_id":"cjmo9un3c000s9q0vvmjpmxpr","tag_id":"cjmo9un3k001u9q0vkih7vr2l","_id":"cjmo9un3k001w9q0v3ht5jdnj"},{"post_id":"cjmo9un7y001x9q0vcm7lwo35","tag_id":"cjmo9un3h001g9q0v9418ecku","_id":"cjmo9un8100209q0vcyk2jdsi"},{"post_id":"cjmo9un7y001x9q0vcm7lwo35","tag_id":"cjmo9un3i001k9q0vehcu47ai","_id":"cjmo9un8200219q0vmifj84pq"},{"post_id":"cjmo9un7z001z9q0vflabgdc6","tag_id":"cjmo9un3h001g9q0v9418ecku","_id":"cjmo9un8300239q0vehqtyo91"},{"post_id":"cjmo9un7z001z9q0vflabgdc6","tag_id":"cjmo9un3i001k9q0vehcu47ai","_id":"cjmo9un8300259q0v4b5sg2uj"}],"Tag":[{"name":"java-nio","_id":"cjmo9un2t00059q0vp4kesxa7"},{"name":"java","_id":"cjmo9un33000g9q0v6lr9n36n"},{"name":"thread","_id":"cjmo9un37000m9q0vzrir5fhz"},{"name":"kafka","_id":"cjmo9un3c000r9q0vg0e067e1"},{"name":"rpc","_id":"cjmo9un3e000y9q0vou4346wo"},{"name":"spark","_id":"cjmo9un3f00129q0vcmsvgf2g"},{"name":"sparkstream","_id":"cjmo9un3g001a9q0v05gg59km"},{"name":"spring-boot","_id":"cjmo9un3h001g9q0v9418ecku"},{"name":"spring","_id":"cjmo9un3i001k9q0vehcu47ai"},{"name":"tensorflow","_id":"cjmo9un3i001l9q0v69oabcf8"},{"name":"yarn","_id":"cjmo9un3i001o9q0v9zxoixsh"},{"name":"hadoop","_id":"cjmo9un3j001q9q0vxdp17rmc"},{"name":"以太坊","_id":"cjmo9un3k001r9q0v3w4gzt85"},{"name":"区块链","_id":"cjmo9un3k001u9q0vkih7vr2l"}]}}